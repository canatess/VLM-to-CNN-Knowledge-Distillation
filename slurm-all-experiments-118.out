=== Loading Conda ===
=== Activating env: cmp722_distillation_env ===
=== Installing Python dependencies ===
Requirement already satisfied: pip in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (25.3)
Requirement already satisfied: transformers>=4.30.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (4.57.3)
Requirement already satisfied: timm>=0.9.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (1.0.22)
Requirement already satisfied: qwen-vl-utils in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (0.0.14)
Requirement already satisfied: accelerate>=0.20.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (1.12.0)
Requirement already satisfied: numpy>=1.24.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (2.2.6)
Requirement already satisfied: pandas>=2.0.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (2.3.3)
Requirement already satisfied: pillow>=10.0.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (12.0.0)
Requirement already satisfied: scikit-learn>=1.3.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (1.7.2)
Requirement already satisfied: pyyaml>=6.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (6.0.3)
Requirement already satisfied: tqdm>=4.65.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from -r requirements.txt (line 17)) (4.67.1)
Requirement already satisfied: matplotlib>=3.7.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from -r requirements.txt (line 20)) (3.10.8)
Requirement already satisfied: seaborn>=0.12.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from -r requirements.txt (line 21)) (0.13.2)
Requirement already satisfied: jupyter>=1.0.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from -r requirements.txt (line 24)) (1.1.1)
Requirement already satisfied: ipython>=8.12.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from -r requirements.txt (line 25)) (8.37.0)
Requirement already satisfied: filelock in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from transformers>=4.30.0->-r requirements.txt (line 4)) (3.20.1)
Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from transformers>=4.30.0->-r requirements.txt (line 4)) (0.36.0)
Requirement already satisfied: packaging>=20.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from transformers>=4.30.0->-r requirements.txt (line 4)) (25.0)
Requirement already satisfied: regex!=2019.12.17 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from transformers>=4.30.0->-r requirements.txt (line 4)) (2025.11.3)
Requirement already satisfied: requests in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from transformers>=4.30.0->-r requirements.txt (line 4)) (2.32.5)
Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from transformers>=4.30.0->-r requirements.txt (line 4)) (0.22.1)
Requirement already satisfied: safetensors>=0.4.3 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from transformers>=4.30.0->-r requirements.txt (line 4)) (0.7.0)
Requirement already satisfied: fsspec>=2023.5.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.30.0->-r requirements.txt (line 4)) (2025.12.0)
Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.30.0->-r requirements.txt (line 4)) (4.15.0)
Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.30.0->-r requirements.txt (line 4)) (1.2.0)
Requirement already satisfied: torch in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from timm>=0.9.0->-r requirements.txt (line 5)) (2.9.1)
Requirement already satisfied: torchvision in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from timm>=0.9.0->-r requirements.txt (line 5)) (0.24.1)
Requirement already satisfied: av in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from qwen-vl-utils->-r requirements.txt (line 6)) (16.0.1)
Requirement already satisfied: psutil in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from accelerate>=0.20.0->-r requirements.txt (line 7)) (7.2.0)
Requirement already satisfied: python-dateutil>=2.8.2 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from pandas>=2.0.0->-r requirements.txt (line 11)) (2.9.0.post0)
Requirement already satisfied: pytz>=2020.1 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from pandas>=2.0.0->-r requirements.txt (line 11)) (2025.2)
Requirement already satisfied: tzdata>=2022.7 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from pandas>=2.0.0->-r requirements.txt (line 11)) (2025.3)
Requirement already satisfied: scipy>=1.8.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 13)) (1.15.3)
Requirement already satisfied: joblib>=1.2.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 13)) (1.5.3)
Requirement already satisfied: threadpoolctl>=3.1.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 13)) (3.6.0)
Requirement already satisfied: contourpy>=1.0.1 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 20)) (1.3.2)
Requirement already satisfied: cycler>=0.10 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 20)) (0.12.1)
Requirement already satisfied: fonttools>=4.22.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 20)) (4.61.1)
Requirement already satisfied: kiwisolver>=1.3.1 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 20)) (1.4.9)
Requirement already satisfied: pyparsing>=3 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 20)) (3.3.1)
Requirement already satisfied: notebook in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jupyter>=1.0.0->-r requirements.txt (line 24)) (7.5.1)
Requirement already satisfied: jupyter-console in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jupyter>=1.0.0->-r requirements.txt (line 24)) (6.6.3)
Requirement already satisfied: nbconvert in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jupyter>=1.0.0->-r requirements.txt (line 24)) (7.16.6)
Requirement already satisfied: ipykernel in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jupyter>=1.0.0->-r requirements.txt (line 24)) (7.1.0)
Requirement already satisfied: ipywidgets in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jupyter>=1.0.0->-r requirements.txt (line 24)) (8.1.8)
Requirement already satisfied: jupyterlab in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jupyter>=1.0.0->-r requirements.txt (line 24)) (4.5.1)
Requirement already satisfied: decorator in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from ipython>=8.12.0->-r requirements.txt (line 25)) (5.2.1)
Requirement already satisfied: exceptiongroup in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from ipython>=8.12.0->-r requirements.txt (line 25)) (1.3.1)
Requirement already satisfied: jedi>=0.16 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from ipython>=8.12.0->-r requirements.txt (line 25)) (0.19.2)
Requirement already satisfied: matplotlib-inline in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from ipython>=8.12.0->-r requirements.txt (line 25)) (0.2.1)
Requirement already satisfied: pexpect>4.3 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from ipython>=8.12.0->-r requirements.txt (line 25)) (4.9.0)
Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from ipython>=8.12.0->-r requirements.txt (line 25)) (3.0.52)
Requirement already satisfied: pygments>=2.4.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from ipython>=8.12.0->-r requirements.txt (line 25)) (2.19.2)
Requirement already satisfied: stack_data in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from ipython>=8.12.0->-r requirements.txt (line 25)) (0.6.3)
Requirement already satisfied: traitlets>=5.13.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from ipython>=8.12.0->-r requirements.txt (line 25)) (5.14.3)
Requirement already satisfied: wcwidth in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=8.12.0->-r requirements.txt (line 25)) (0.2.14)
Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jedi>=0.16->ipython>=8.12.0->-r requirements.txt (line 25)) (0.8.5)
Requirement already satisfied: ptyprocess>=0.5 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from pexpect>4.3->ipython>=8.12.0->-r requirements.txt (line 25)) (0.7.0)
Requirement already satisfied: six>=1.5 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->-r requirements.txt (line 11)) (1.17.0)
Requirement already satisfied: sympy>=1.13.3 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch->timm>=0.9.0->-r requirements.txt (line 5)) (1.14.0)
Requirement already satisfied: networkx>=2.5.1 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch->timm>=0.9.0->-r requirements.txt (line 5)) (3.4.2)
Requirement already satisfied: jinja2 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch->timm>=0.9.0->-r requirements.txt (line 5)) (3.1.6)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch->timm>=0.9.0->-r requirements.txt (line 5)) (12.8.93)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch->timm>=0.9.0->-r requirements.txt (line 5)) (12.8.90)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch->timm>=0.9.0->-r requirements.txt (line 5)) (12.8.90)
Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch->timm>=0.9.0->-r requirements.txt (line 5)) (9.10.2.21)
Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch->timm>=0.9.0->-r requirements.txt (line 5)) (12.8.4.1)
Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch->timm>=0.9.0->-r requirements.txt (line 5)) (11.3.3.83)
Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch->timm>=0.9.0->-r requirements.txt (line 5)) (10.3.9.90)
Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch->timm>=0.9.0->-r requirements.txt (line 5)) (11.7.3.90)
Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch->timm>=0.9.0->-r requirements.txt (line 5)) (12.5.8.93)
Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch->timm>=0.9.0->-r requirements.txt (line 5)) (0.7.1)
Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch->timm>=0.9.0->-r requirements.txt (line 5)) (2.27.5)
Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch->timm>=0.9.0->-r requirements.txt (line 5)) (3.3.20)
Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch->timm>=0.9.0->-r requirements.txt (line 5)) (12.8.90)
Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch->timm>=0.9.0->-r requirements.txt (line 5)) (12.8.93)
Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch->timm>=0.9.0->-r requirements.txt (line 5)) (1.13.1.3)
Requirement already satisfied: triton==3.5.1 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch->timm>=0.9.0->-r requirements.txt (line 5)) (3.5.1)
Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from sympy>=1.13.3->torch->timm>=0.9.0->-r requirements.txt (line 5)) (1.3.0)
Requirement already satisfied: comm>=0.1.1 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 24)) (0.2.3)
Requirement already satisfied: debugpy>=1.6.5 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 24)) (1.8.19)
Requirement already satisfied: jupyter-client>=8.0.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 24)) (8.7.0)
Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 24)) (5.9.1)
Requirement already satisfied: nest-asyncio>=1.4 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 24)) (1.6.0)
Requirement already satisfied: pyzmq>=25 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 24)) (27.1.0)
Requirement already satisfied: tornado>=6.2 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 24)) (6.5.4)
Requirement already satisfied: platformdirs>=2.5 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 24)) (4.5.1)
Requirement already satisfied: widgetsnbextension~=4.0.14 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 24)) (4.0.15)
Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 24)) (3.0.16)
Requirement already satisfied: MarkupSafe>=2.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jinja2->torch->timm>=0.9.0->-r requirements.txt (line 5)) (3.0.3)
Requirement already satisfied: async-lru>=1.0.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (2.0.5)
Requirement already satisfied: httpx<1,>=0.25.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (0.28.1)
Requirement already satisfied: jupyter-lsp>=2.0.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (2.3.0)
Requirement already satisfied: jupyter-server<3,>=2.4.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (2.17.0)
Requirement already satisfied: jupyterlab-server<3,>=2.28.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (2.28.0)
Requirement already satisfied: notebook-shim>=0.2 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (0.2.4)
Requirement already satisfied: setuptools>=41.1.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (80.9.0)
Requirement already satisfied: tomli>=1.2.2 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (2.3.0)
Requirement already satisfied: anyio in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (4.12.0)
Requirement already satisfied: certifi in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (2025.11.12)
Requirement already satisfied: httpcore==1.* in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (1.0.9)
Requirement already satisfied: idna in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (3.11)
Requirement already satisfied: h11>=0.16 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (0.16.0)
Requirement already satisfied: argon2-cffi>=21.1 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (25.1.0)
Requirement already satisfied: jupyter-events>=0.11.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (0.12.0)
Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (0.5.3)
Requirement already satisfied: nbformat>=5.3.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (5.10.4)
Requirement already satisfied: overrides>=5.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (7.7.0)
Requirement already satisfied: prometheus-client>=0.9 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (0.23.1)
Requirement already satisfied: send2trash>=1.8.2 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (1.8.3)
Requirement already satisfied: terminado>=0.8.3 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (0.18.1)
Requirement already satisfied: websocket-client>=1.7 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (1.9.0)
Requirement already satisfied: babel>=2.10 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (2.17.0)
Requirement already satisfied: json5>=0.9.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (0.12.1)
Requirement already satisfied: jsonschema>=4.18.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (4.25.1)
Requirement already satisfied: argon2-cffi-bindings in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (25.1.0)
Requirement already satisfied: attrs>=22.2.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (25.4.0)
Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (2025.9.1)
Requirement already satisfied: referencing>=0.28.4 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (0.37.0)
Requirement already satisfied: rpds-py>=0.7.1 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (0.30.0)
Requirement already satisfied: python-json-logger>=2.0.4 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (4.0.0)
Requirement already satisfied: rfc3339-validator in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (0.1.4)
Requirement already satisfied: rfc3986-validator>=0.1.1 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (0.1.1)
Requirement already satisfied: fqdn in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (1.5.1)
Requirement already satisfied: isoduration in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (20.11.0)
Requirement already satisfied: jsonpointer>1.13 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (3.0.0)
Requirement already satisfied: rfc3987-syntax>=1.1.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (1.1.0)
Requirement already satisfied: uri-template in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (1.3.0)
Requirement already satisfied: webcolors>=24.6.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (25.10.0)
Requirement already satisfied: beautifulsoup4 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 24)) (4.14.3)
Requirement already satisfied: bleach!=5.0.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 24)) (6.3.0)
Requirement already satisfied: defusedxml in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 24)) (0.7.1)
Requirement already satisfied: jupyterlab-pygments in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 24)) (0.3.0)
Requirement already satisfied: mistune<4,>=2.0.3 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 24)) (3.2.0)
Requirement already satisfied: nbclient>=0.5.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 24)) (0.10.4)
Requirement already satisfied: pandocfilters>=1.4.1 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 24)) (1.5.1)
Requirement already satisfied: webencodings in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 24)) (0.5.1)
Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 24)) (1.4.0)
Requirement already satisfied: fastjsonschema>=2.15 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (2.21.2)
Requirement already satisfied: charset_normalizer<4,>=2 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from requests->transformers>=4.30.0->-r requirements.txt (line 4)) (3.4.4)
Requirement already satisfied: urllib3<3,>=1.21.1 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from requests->transformers>=4.30.0->-r requirements.txt (line 4)) (2.6.2)
Requirement already satisfied: lark>=1.2.2 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (1.3.1)
Requirement already satisfied: cffi>=1.0.1 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (2.0.0)
Requirement already satisfied: pycparser in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (2.23)
Requirement already satisfied: soupsieve>=1.6.1 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from beautifulsoup4->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 24)) (2.8.1)
Requirement already satisfied: arrow>=0.15.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 24)) (1.4.0)
Requirement already satisfied: executing>=1.2.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from stack_data->ipython>=8.12.0->-r requirements.txt (line 25)) (2.2.1)
Requirement already satisfied: asttokens>=2.1.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from stack_data->ipython>=8.12.0->-r requirements.txt (line 25)) (3.0.1)
Requirement already satisfied: pure-eval in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from stack_data->ipython>=8.12.0->-r requirements.txt (line 25)) (0.2.3)
Looking in indexes: https://download.pytorch.org/whl/cu121
Requirement already satisfied: torch in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (2.9.1)
Requirement already satisfied: torchvision in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (0.24.1)
Requirement already satisfied: filelock in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch) (3.20.1)
Requirement already satisfied: typing-extensions>=4.10.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch) (4.15.0)
Requirement already satisfied: sympy>=1.13.3 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch) (1.14.0)
Requirement already satisfied: networkx>=2.5.1 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch) (3.4.2)
Requirement already satisfied: jinja2 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch) (3.1.6)
Requirement already satisfied: fsspec>=0.8.5 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch) (2025.12.0)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch) (12.8.93)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch) (12.8.90)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch) (12.8.90)
Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch) (9.10.2.21)
Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch) (12.8.4.1)
Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch) (11.3.3.83)
Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch) (10.3.9.90)
Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch) (11.7.3.90)
Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch) (12.5.8.93)
Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch) (0.7.1)
Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch) (2.27.5)
Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch) (3.3.20)
Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch) (12.8.90)
Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch) (12.8.93)
Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch) (1.13.1.3)
Requirement already satisfied: triton==3.5.1 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torch) (3.5.1)
Requirement already satisfied: numpy in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torchvision) (2.2.6)
Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from torchvision) (12.0.0)
Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)
Requirement already satisfied: MarkupSafe>=2.0 in /home/emre/.conda/envs/cmp722_distillation_env/lib/python3.10/site-packages (from jinja2->torch) (3.0.3)
=== Running All Experiments ===

================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: resnet18_scratch
Student Architecture: resnet18
Distillation Type: none
Device: cuda
Seed: 42

Configuration saved to: outputs/resnet18_scratch/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: resnet18
  Total parameters: 11,279,112
  Trainable parameters: 11,279,112

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 5.2932
  Train Acc:  0.65%
  Val Loss:   5.1286
  Val Acc:    1.83%
  Val Top-5:  6.83%
  Val F1 (M): 0.21%
  Saved best model to outputs/resnet18_scratch/best_model.pth

Epoch 2/30
  Train Loss: 5.1066
  Train Acc:  1.54%
  Val Loss:   5.0130
  Val Acc:    3.00%
  Val Top-5:  8.17%
  Val F1 (M): 1.14%
  Saved best model to outputs/resnet18_scratch/best_model.pth

Epoch 3/30
  Train Loss: 4.9964
  Train Acc:  1.99%
  Val Loss:   4.9194
  Val Acc:    2.17%
  Val Top-5:  10.33%
  Val F1 (M): 0.91%

Epoch 4/30
  Train Loss: 4.8861
  Train Acc:  2.99%
  Val Loss:   4.8350
  Val Acc:    3.67%
  Val Top-5:  12.17%
  Val F1 (M): 1.84%
  Saved best model to outputs/resnet18_scratch/best_model.pth

Epoch 5/30
  Train Loss: 4.8017
  Train Acc:  2.98%
  Val Loss:   4.7843
  Val Acc:    4.33%
  Val Top-5:  15.17%
  Val F1 (M): 2.58%
  Saved best model to outputs/resnet18_scratch/best_model.pth

Epoch 6/30
  Train Loss: 4.7208
  Train Acc:  4.07%
  Val Loss:   4.6739
  Val Acc:    3.17%
  Val Top-5:  15.83%
  Val F1 (M): 1.36%

Epoch 7/30
  Train Loss: 4.6252
  Train Acc:  4.74%
  Val Loss:   4.6129
  Val Acc:    4.67%
  Val Top-5:  17.00%
  Val F1 (M): 2.27%
  Saved best model to outputs/resnet18_scratch/best_model.pth

Epoch 8/30
  Train Loss: 4.5219
  Train Acc:  5.75%
  Val Loss:   4.4438
  Val Acc:    6.33%
  Val Top-5:  21.83%
  Val F1 (M): 3.95%
  Saved best model to outputs/resnet18_scratch/best_model.pth

Epoch 9/30
  Train Loss: 4.4129
  Train Acc:  6.29%
  Val Loss:   4.4087
  Val Acc:    5.83%
  Val Top-5:  24.50%
  Val F1 (M): 4.06%

Epoch 10/30
  Train Loss: 4.3129
  Train Acc:  7.37%
  Val Loss:   4.2677
  Val Acc:    8.50%
  Val Top-5:  26.83%
  Val F1 (M): 5.75%
  Saved best model to outputs/resnet18_scratch/best_model.pth

Epoch 11/30
  Train Loss: 4.1989
  Train Acc:  9.24%
  Val Loss:   4.2141
  Val Acc:    10.00%
  Val Top-5:  25.83%
  Val F1 (M): 7.25%
  Saved best model to outputs/resnet18_scratch/best_model.pth

Epoch 12/30
  Train Loss: 4.0883
  Train Acc:  9.84%
  Val Loss:   4.1282
  Val Acc:    9.83%
  Val Top-5:  30.50%
  Val F1 (M): 7.45%

Epoch 13/30
  Train Loss: 3.9783
  Train Acc:  11.87%
  Val Loss:   4.0461
  Val Acc:    10.83%
  Val Top-5:  32.17%
  Val F1 (M): 7.90%
  Saved best model to outputs/resnet18_scratch/best_model.pth

Epoch 14/30
  Train Loss: 3.8793
  Train Acc:  12.46%
  Val Loss:   3.9713
  Val Acc:    12.00%
  Val Top-5:  31.00%
  Val F1 (M): 9.63%
  Saved best model to outputs/resnet18_scratch/best_model.pth

Epoch 15/30
  Train Loss: 3.7778
  Train Acc:  13.82%
  Val Loss:   3.8404
  Val Acc:    13.00%
  Val Top-5:  36.83%
  Val F1 (M): 10.63%
  Saved best model to outputs/resnet18_scratch/best_model.pth

Epoch 16/30
  Train Loss: 3.6966
  Train Acc:  15.49%
  Val Loss:   3.7572
  Val Acc:    13.00%
  Val Top-5:  38.33%
  Val F1 (M): 11.17%

Epoch 17/30
  Train Loss: 3.6073
  Train Acc:  16.76%
  Val Loss:   3.6810
  Val Acc:    13.33%
  Val Top-5:  40.17%
  Val F1 (M): 10.68%
  Saved best model to outputs/resnet18_scratch/best_model.pth

Epoch 18/30
  Train Loss: 3.5187
  Train Acc:  18.64%
  Val Loss:   3.7010
  Val Acc:    14.67%
  Val Top-5:  38.33%
  Val F1 (M): 12.95%
  Saved best model to outputs/resnet18_scratch/best_model.pth

Epoch 19/30
  Train Loss: 3.4407
  Train Acc:  19.79%
  Val Loss:   3.6427
  Val Acc:    15.33%
  Val Top-5:  40.67%
  Val F1 (M): 13.96%
  Saved best model to outputs/resnet18_scratch/best_model.pth

Epoch 20/30
  Train Loss: 3.3723
  Train Acc:  20.61%
  Val Loss:   3.5751
  Val Acc:    18.83%
  Val Top-5:  42.17%
  Val F1 (M): 16.57%
  Saved best model to outputs/resnet18_scratch/best_model.pth

Epoch 21/30
  Train Loss: 3.3029
  Train Acc:  22.34%
  Val Loss:   3.5890
  Val Acc:    17.83%
  Val Top-5:  42.00%
  Val F1 (M): 15.62%

Epoch 22/30
  Train Loss: 3.2502
  Train Acc:  23.79%
  Val Loss:   3.4994
  Val Acc:    18.50%
  Val Top-5:  44.33%
  Val F1 (M): 15.77%

Epoch 23/30
  Train Loss: 3.2127
  Train Acc:  24.93%
  Val Loss:   3.4659
  Val Acc:    18.50%
  Val Top-5:  45.83%
  Val F1 (M): 15.66%

Epoch 24/30
  Train Loss: 3.1649
  Train Acc:  25.78%
  Val Loss:   3.4674
  Val Acc:    18.83%
  Val Top-5:  46.00%
  Val F1 (M): 16.24%

Epoch 25/30
  Train Loss: 3.1373
  Train Acc:  26.02%
  Val Loss:   3.4346
  Val Acc:    19.33%
  Val Top-5:  46.83%
  Val F1 (M): 16.97%
  Saved best model to outputs/resnet18_scratch/best_model.pth

Epoch 26/30
  Train Loss: 3.1167
  Train Acc:  26.69%
  Val Loss:   3.4090
  Val Acc:    20.00%
  Val Top-5:  46.00%
  Val F1 (M): 17.18%
  Saved best model to outputs/resnet18_scratch/best_model.pth

Epoch 27/30
  Train Loss: 3.0842
  Train Acc:  27.06%
  Val Loss:   3.4053
  Val Acc:    20.50%
  Val Top-5:  46.33%
  Val F1 (M): 17.95%
  Saved best model to outputs/resnet18_scratch/best_model.pth

Epoch 28/30
  Train Loss: 3.0715
  Train Acc:  27.83%
  Val Loss:   3.4094
  Val Acc:    20.00%
  Val Top-5:  46.67%
  Val F1 (M): 17.11%

Epoch 29/30
  Train Loss: 3.0544
  Train Acc:  28.18%
  Val Loss:   3.4222
  Val Acc:    19.67%
  Val Top-5:  45.67%
  Val F1 (M): 16.76%

Epoch 30/30
  Train Loss: 3.0468
  Train Acc:  28.72%
  Val Loss:   3.4063
  Val Acc:    19.67%
  Val Top-5:  46.67%
  Val F1 (M): 17.00%
  Test Acc:   17.71%
  Test Top-5: 45.29%
  Test F1 (M):15.95%

============================================================
Training completed in 332.79s
Best validation accuracy: 20.50%
============================================================


Results saved to: outputs/resnet18_scratch
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: resnet18_transfer
Student Architecture: resnet18
Distillation Type: none
Device: cuda
Seed: 42

Configuration saved to: outputs/resnet18_transfer/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: resnet18
  Total parameters: 11,279,112
  Trainable parameters: 11,279,112

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 5.1672
  Train Acc:  2.47%
  Val Loss:   4.6367
  Val Acc:    15.67%
  Val Top-5:  36.83%
  Val F1 (M): 12.04%
  Saved best model to outputs/resnet18_transfer/best_model.pth

Epoch 2/30
  Train Loss: 4.0952
  Train Acc:  19.23%
  Val Loss:   3.2521
  Val Acc:    28.67%
  Val Top-5:  64.83%
  Val F1 (M): 22.24%
  Saved best model to outputs/resnet18_transfer/best_model.pth

Epoch 3/30
  Train Loss: 3.0411
  Train Acc:  35.21%
  Val Loss:   2.4965
  Val Acc:    41.67%
  Val Top-5:  77.17%
  Val F1 (M): 36.44%
  Saved best model to outputs/resnet18_transfer/best_model.pth

Epoch 4/30
  Train Loss: 2.3402
  Train Acc:  48.88%
  Val Loss:   2.1117
  Val Acc:    48.67%
  Val Top-5:  81.67%
  Val F1 (M): 44.73%
  Saved best model to outputs/resnet18_transfer/best_model.pth

Epoch 5/30
  Train Loss: 1.8672
  Train Acc:  58.76%
  Val Loss:   1.8084
  Val Acc:    56.00%
  Val Top-5:  85.00%
  Val F1 (M): 53.29%
  Saved best model to outputs/resnet18_transfer/best_model.pth

Epoch 6/30
  Train Loss: 1.5201
  Train Acc:  65.57%
  Val Loss:   1.5787
  Val Acc:    59.33%
  Val Top-5:  87.67%
  Val F1 (M): 57.03%
  Saved best model to outputs/resnet18_transfer/best_model.pth

Epoch 7/30
  Train Loss: 1.2582
  Train Acc:  71.71%
  Val Loss:   1.4485
  Val Acc:    61.33%
  Val Top-5:  89.33%
  Val F1 (M): 58.83%
  Saved best model to outputs/resnet18_transfer/best_model.pth

Epoch 8/30
  Train Loss: 1.0694
  Train Acc:  75.78%
  Val Loss:   1.3646
  Val Acc:    61.33%
  Val Top-5:  89.67%
  Val F1 (M): 59.32%

Epoch 9/30
  Train Loss: 0.9093
  Train Acc:  79.02%
  Val Loss:   1.3374
  Val Acc:    61.50%
  Val Top-5:  91.17%
  Val F1 (M): 59.75%
  Saved best model to outputs/resnet18_transfer/best_model.pth

Epoch 10/30
  Train Loss: 0.8006
  Train Acc:  81.44%
  Val Loss:   1.2445
  Val Acc:    63.50%
  Val Top-5:  91.50%
  Val F1 (M): 62.24%
  Saved best model to outputs/resnet18_transfer/best_model.pth

Epoch 11/30
  Train Loss: 0.6884
  Train Acc:  84.77%
  Val Loss:   1.2065
  Val Acc:    63.67%
  Val Top-5:  92.17%
  Val F1 (M): 62.66%
  Saved best model to outputs/resnet18_transfer/best_model.pth

Epoch 12/30
  Train Loss: 0.6102
  Train Acc:  86.76%
  Val Loss:   1.2136
  Val Acc:    62.83%
  Val Top-5:  92.33%
  Val F1 (M): 61.55%

Epoch 13/30
  Train Loss: 0.5364
  Train Acc:  88.62%
  Val Loss:   1.1762
  Val Acc:    65.17%
  Val Top-5:  91.83%
  Val F1 (M): 63.53%
  Saved best model to outputs/resnet18_transfer/best_model.pth

Epoch 14/30
  Train Loss: 0.4693
  Train Acc:  90.94%
  Val Loss:   1.1718
  Val Acc:    65.50%
  Val Top-5:  93.33%
  Val F1 (M): 64.25%
  Saved best model to outputs/resnet18_transfer/best_model.pth

Epoch 15/30
  Train Loss: 0.4236
  Train Acc:  91.80%
  Val Loss:   1.1551
  Val Acc:    65.83%
  Val Top-5:  91.67%
  Val F1 (M): 64.82%
  Saved best model to outputs/resnet18_transfer/best_model.pth

Epoch 16/30
  Train Loss: 0.3809
  Train Acc:  92.99%
  Val Loss:   1.1571
  Val Acc:    66.67%
  Val Top-5:  92.17%
  Val F1 (M): 65.68%
  Saved best model to outputs/resnet18_transfer/best_model.pth

Epoch 17/30
  Train Loss: 0.3511
  Train Acc:  93.64%
  Val Loss:   1.1560
  Val Acc:    66.00%
  Val Top-5:  92.33%
  Val F1 (M): 65.00%

Epoch 18/30
  Train Loss: 0.3209
  Train Acc:  93.92%
  Val Loss:   1.1460
  Val Acc:    65.33%
  Val Top-5:  93.50%
  Val F1 (M): 64.29%

Epoch 19/30
  Train Loss: 0.2872
  Train Acc:  95.50%
  Val Loss:   1.1327
  Val Acc:    66.50%
  Val Top-5:  92.83%
  Val F1 (M): 66.28%

Epoch 20/30
  Train Loss: 0.2681
  Train Acc:  95.85%
  Val Loss:   1.1532
  Val Acc:    65.50%
  Val Top-5:  91.83%
  Val F1 (M): 64.83%

Epoch 21/30
  Train Loss: 0.2493
  Train Acc:  96.52%
  Val Loss:   1.1445
  Val Acc:    65.67%
  Val Top-5:  91.83%
  Val F1 (M): 64.50%

Epoch 22/30
  Train Loss: 0.2362
  Train Acc:  96.74%
  Val Loss:   1.1432
  Val Acc:    66.67%
  Val Top-5:  92.17%
  Val F1 (M): 65.66%

Epoch 23/30
  Train Loss: 0.2252
  Train Acc:  97.25%
  Val Loss:   1.1369
  Val Acc:    65.17%
  Val Top-5:  92.33%
  Val F1 (M): 64.25%

Epoch 24/30
  Train Loss: 0.2150
  Train Acc:  97.15%
  Val Loss:   1.1352
  Val Acc:    65.50%
  Val Top-5:  92.83%
  Val F1 (M): 64.61%

Epoch 25/30
  Train Loss: 0.2212
  Train Acc:  96.95%
  Val Loss:   1.1377
  Val Acc:    66.33%
  Val Top-5:  93.17%
  Val F1 (M): 65.49%

Epoch 26/30
  Train Loss: 0.2062
  Train Acc:  97.53%
  Val Loss:   1.1341
  Val Acc:    66.83%
  Val Top-5:  93.00%
  Val F1 (M): 66.12%
  Saved best model to outputs/resnet18_transfer/best_model.pth

Epoch 27/30
  Train Loss: 0.2056
  Train Acc:  97.15%
  Val Loss:   1.1286
  Val Acc:    66.00%
  Val Top-5:  92.67%
  Val F1 (M): 65.21%

Epoch 28/30
  Train Loss: 0.1944
  Train Acc:  97.53%
  Val Loss:   1.1303
  Val Acc:    65.83%
  Val Top-5:  92.67%
  Val F1 (M): 65.06%

Epoch 29/30
  Train Loss: 0.1986
  Train Acc:  97.73%
  Val Loss:   1.1324
  Val Acc:    65.67%
  Val Top-5:  93.17%
  Val F1 (M): 64.69%

Epoch 30/30
  Train Loss: 0.1946
  Train Acc:  97.69%
  Val Loss:   1.1310
  Val Acc:    67.00%
  Val Top-5:  93.00%
  Val F1 (M): 66.15%
  Saved best model to outputs/resnet18_transfer/best_model.pth
  Test Acc:   70.69%
  Test Top-5: 91.75%
  Test F1 (M):70.74%

============================================================
Training completed in 331.02s
Best validation accuracy: 67.00%
============================================================


Results saved to: outputs/resnet18_transfer
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: resnet18_logit_kd
Student Architecture: resnet18
Distillation Type: logit
Device: cuda
Seed: 42

Configuration saved to: outputs/resnet18_logit_kd/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: resnet18
  Total parameters: 11,279,112
  Trainable parameters: 11,279,112

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01

Setting up knowledge distillation...
  Teacher: openai/clip-vit-base-patch32
  Distillation type: logit
  Alpha CE: 1.0
  Alpha KD: 1.0


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 11.5480
  Train Acc:  2.21%
  CE Loss:    4.9965
  KD Loss:    6.5515
  Val Loss:   4.1504
  Val Acc:    8.17%
  Val Top-5:  26.83%
  Val F1 (M): 3.91%
  Saved best model to outputs/resnet18_logit_kd/best_model.pth

Epoch 2/30
  Train Loss: 7.6524
  Train Acc:  12.20%
  CE Loss:    3.8351
  KD Loss:    3.8173
  Val Loss:   3.0794
  Val Acc:    22.33%
  Val Top-5:  56.50%
  Val F1 (M): 15.75%
  Saved best model to outputs/resnet18_logit_kd/best_model.pth

Epoch 3/30
  Train Loss: 5.7714
  Train Acc:  27.94%
  CE Loss:    3.0193
  KD Loss:    2.7521
  Val Loss:   2.4437
  Val Acc:    37.17%
  Val Top-5:  73.67%
  Val F1 (M): 33.26%
  Saved best model to outputs/resnet18_logit_kd/best_model.pth

Epoch 4/30
  Train Loss: 4.7853
  Train Acc:  39.99%
  CE Loss:    2.4896
  KD Loss:    2.2957
  Val Loss:   2.0517
  Val Acc:    46.83%
  Val Top-5:  82.83%
  Val F1 (M): 43.91%
  Saved best model to outputs/resnet18_logit_kd/best_model.pth

Epoch 5/30
  Train Loss: 4.1333
  Train Acc:  49.83%
  CE Loss:    2.1127
  KD Loss:    2.0206
  Val Loss:   1.7552
  Val Acc:    54.67%
  Val Top-5:  86.83%
  Val F1 (M): 51.46%
  Saved best model to outputs/resnet18_logit_kd/best_model.pth

Epoch 6/30
  Train Loss: 3.7772
  Train Acc:  56.94%
  CE Loss:    1.8801
  KD Loss:    1.8971
  Val Loss:   1.6364
  Val Acc:    57.50%
  Val Top-5:  89.67%
  Val F1 (M): 55.20%
  Saved best model to outputs/resnet18_logit_kd/best_model.pth

Epoch 7/30
  Train Loss: 3.4915
  Train Acc:  61.07%
  CE Loss:    1.7013
  KD Loss:    1.7902
  Val Loss:   1.5275
  Val Acc:    61.67%
  Val Top-5:  89.83%
  Val F1 (M): 60.22%
  Saved best model to outputs/resnet18_logit_kd/best_model.pth

Epoch 8/30
  Train Loss: 3.2706
  Train Acc:  65.81%
  CE Loss:    1.5439
  KD Loss:    1.7268
  Val Loss:   1.4439
  Val Acc:    61.67%
  Val Top-5:  91.00%
  Val F1 (M): 59.34%

Epoch 9/30
  Train Loss: 3.1262
  Train Acc:  68.84%
  CE Loss:    1.4353
  KD Loss:    1.6909
  Val Loss:   1.3745
  Val Acc:    65.00%
  Val Top-5:  91.00%
  Val F1 (M): 63.19%
  Saved best model to outputs/resnet18_logit_kd/best_model.pth

Epoch 10/30
  Train Loss: 2.9788
  Train Acc:  71.99%
  CE Loss:    1.3357
  KD Loss:    1.6431
  Val Loss:   1.3230
  Val Acc:    65.17%
  Val Top-5:  91.83%
  Val F1 (M): 63.73%
  Saved best model to outputs/resnet18_logit_kd/best_model.pth

Epoch 11/30
  Train Loss: 2.8690
  Train Acc:  74.39%
  CE Loss:    1.2480
  KD Loss:    1.6211
  Val Loss:   1.2652
  Val Acc:    66.67%
  Val Top-5:  91.17%
  Val F1 (M): 65.13%
  Saved best model to outputs/resnet18_logit_kd/best_model.pth

Epoch 12/30
  Train Loss: 2.7641
  Train Acc:  75.91%
  CE Loss:    1.1809
  KD Loss:    1.5832
  Val Loss:   1.2514
  Val Acc:    67.50%
  Val Top-5:  92.50%
  Val F1 (M): 65.84%
  Saved best model to outputs/resnet18_logit_kd/best_model.pth

Epoch 13/30
  Train Loss: 2.6910
  Train Acc:  77.68%
  CE Loss:    1.1229
  KD Loss:    1.5681
  Val Loss:   1.2033
  Val Acc:    68.50%
  Val Top-5:  92.67%
  Val F1 (M): 67.16%
  Saved best model to outputs/resnet18_logit_kd/best_model.pth

Epoch 14/30
  Train Loss: 2.6121
  Train Acc:  79.07%
  CE Loss:    1.0743
  KD Loss:    1.5378
  Val Loss:   1.1852
  Val Acc:    66.33%
  Val Top-5:  92.67%
  Val F1 (M): 64.73%

Epoch 15/30
  Train Loss: 2.5183
  Train Acc:  80.38%
  CE Loss:    1.0133
  KD Loss:    1.5050
  Val Loss:   1.1737
  Val Acc:    68.17%
  Val Top-5:  92.17%
  Val F1 (M): 66.58%

Epoch 16/30
  Train Loss: 2.4887
  Train Acc:  80.97%
  CE Loss:    0.9937
  KD Loss:    1.4951
  Val Loss:   1.1619
  Val Acc:    70.33%
  Val Top-5:  93.33%
  Val F1 (M): 69.24%
  Saved best model to outputs/resnet18_logit_kd/best_model.pth

Epoch 17/30
  Train Loss: 2.4320
  Train Acc:  82.12%
  CE Loss:    0.9543
  KD Loss:    1.4777
  Val Loss:   1.1350
  Val Acc:    69.83%
  Val Top-5:  93.17%
  Val F1 (M): 68.88%

Epoch 18/30
  Train Loss: 2.3856
  Train Acc:  83.24%
  CE Loss:    0.9147
  KD Loss:    1.4709
  Val Loss:   1.1129
  Val Acc:    70.50%
  Val Top-5:  94.00%
  Val F1 (M): 69.70%
  Saved best model to outputs/resnet18_logit_kd/best_model.pth

Epoch 19/30
  Train Loss: 2.3407
  Train Acc:  84.60%
  CE Loss:    0.8799
  KD Loss:    1.4608
  Val Loss:   1.1192
  Val Acc:    71.83%
  Val Top-5:  92.83%
  Val F1 (M): 70.55%
  Saved best model to outputs/resnet18_logit_kd/best_model.pth

Epoch 20/30
  Train Loss: 2.3244
  Train Acc:  84.23%
  CE Loss:    0.8676
  KD Loss:    1.4568
  Val Loss:   1.1103
  Val Acc:    71.50%
  Val Top-5:  93.00%
  Val F1 (M): 70.39%

Epoch 21/30
  Train Loss: 2.3101
  Train Acc:  84.84%
  CE Loss:    0.8531
  KD Loss:    1.4569
  Val Loss:   1.1071
  Val Acc:    70.83%
  Val Top-5:  92.83%
  Val F1 (M): 69.68%

Epoch 22/30
  Train Loss: 2.2495
  Train Acc:  85.99%
  CE Loss:    0.8286
  KD Loss:    1.4209
  Val Loss:   1.1067
  Val Acc:    71.00%
  Val Top-5:  93.17%
  Val F1 (M): 69.43%

Epoch 23/30
  Train Loss: 2.2514
  Train Acc:  85.96%
  CE Loss:    0.8190
  KD Loss:    1.4324
  Val Loss:   1.1053
  Val Acc:    72.50%
  Val Top-5:  93.50%
  Val F1 (M): 71.42%
  Saved best model to outputs/resnet18_logit_kd/best_model.pth

Epoch 24/30
  Train Loss: 2.2421
  Train Acc:  86.16%
  CE Loss:    0.8132
  KD Loss:    1.4289
  Val Loss:   1.1058
  Val Acc:    71.17%
  Val Top-5:  93.00%
  Val F1 (M): 69.92%

Epoch 25/30
  Train Loss: 2.2246
  Train Acc:  86.70%
  CE Loss:    0.7994
  KD Loss:    1.4252
  Val Loss:   1.0960
  Val Acc:    71.33%
  Val Top-5:  93.33%
  Val F1 (M): 69.94%

Epoch 26/30
  Train Loss: 2.2000
  Train Acc:  86.44%
  CE Loss:    0.7904
  KD Loss:    1.4096
  Val Loss:   1.1000
  Val Acc:    71.50%
  Val Top-5:  93.50%
  Val F1 (M): 70.41%

Epoch 27/30
  Train Loss: 2.2149
  Train Acc:  86.33%
  CE Loss:    0.7928
  KD Loss:    1.4221
  Val Loss:   1.0893
  Val Acc:    72.00%
  Val Top-5:  93.50%
  Val F1 (M): 71.01%

Epoch 28/30
  Train Loss: 2.2012
  Train Acc:  86.31%
  CE Loss:    0.7892
  KD Loss:    1.4120
  Val Loss:   1.0865
  Val Acc:    71.33%
  Val Top-5:  93.67%
  Val F1 (M): 70.00%

Epoch 29/30
  Train Loss: 2.2021
  Train Acc:  86.57%
  CE Loss:    0.7869
  KD Loss:    1.4151
  Val Loss:   1.0803
  Val Acc:    70.67%
  Val Top-5:  93.33%
  Val F1 (M): 69.52%

Epoch 30/30
  Train Loss: 2.1673
  Train Acc:  86.63%
  CE Loss:    0.7800
  KD Loss:    1.3873
  Val Loss:   1.0838
  Val Acc:    71.17%
  Val Top-5:  93.67%
  Val F1 (M): 69.94%
  Test Acc:   72.54%
  Test Top-5: 93.39%
  Test F1 (M):72.37%

============================================================
Training completed in 360.12s
Best validation accuracy: 72.50%
============================================================


Results saved to: outputs/resnet18_logit_kd
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: resnet18_attention_kd
Student Architecture: resnet18
Distillation Type: attention
Device: cuda
Seed: 42

Configuration saved to: outputs/resnet18_attention_kd/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: resnet18
  Total parameters: 11,279,112
  Trainable parameters: 11,279,112

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01

Setting up knowledge distillation...
  Teacher: openai/clip-vit-base-patch32
  Distillation type: attention
  Alpha CE: 1.0
  Alpha KD: 0.0
  Alpha Attention: 0.5
  Attention loss: mse


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 5.1598
  Train Acc:  3.65%
  CE Loss:    5.1598
  KD Loss:    7.8480
  Val Loss:   4.5970
  Val Acc:    14.83%
  Val Top-5:  39.00%
  Val F1 (M): 10.83%
  Saved best model to outputs/resnet18_attention_kd/best_model.pth

Epoch 2/30
  Train Loss: 4.0100
  Train Acc:  22.79%
  CE Loss:    4.0100
  KD Loss:    6.1818
  Val Loss:   3.1684
  Val Acc:    31.33%
  Val Top-5:  64.67%
  Val F1 (M): 24.87%
  Saved best model to outputs/resnet18_attention_kd/best_model.pth

Epoch 3/30
  Train Loss: 2.9453
  Train Acc:  41.85%
  CE Loss:    2.9453
  KD Loss:    4.9847
  Val Loss:   2.4791
  Val Acc:    41.83%
  Val Top-5:  76.83%
  Val F1 (M): 38.40%
  Saved best model to outputs/resnet18_attention_kd/best_model.pth

Epoch 4/30
  Train Loss: 2.2832
  Train Acc:  53.91%
  CE Loss:    2.2832
  KD Loss:    4.4711
  Val Loss:   2.0373
  Val Acc:    52.17%
  Val Top-5:  83.17%
  Val F1 (M): 49.01%
  Saved best model to outputs/resnet18_attention_kd/best_model.pth

Epoch 5/30
  Train Loss: 1.8044
  Train Acc:  63.67%
  CE Loss:    1.8044
  KD Loss:    4.2360
  Val Loss:   1.7212
  Val Acc:    56.33%
  Val Top-5:  87.67%
  Val F1 (M): 53.76%
  Saved best model to outputs/resnet18_attention_kd/best_model.pth

Epoch 6/30
  Train Loss: 1.4725
  Train Acc:  70.61%
  CE Loss:    1.4725
  KD Loss:    4.1999
  Val Loss:   1.5566
  Val Acc:    58.67%
  Val Top-5:  88.17%
  Val F1 (M): 57.10%
  Saved best model to outputs/resnet18_attention_kd/best_model.pth

Epoch 7/30
  Train Loss: 1.2293
  Train Acc:  75.67%
  CE Loss:    1.2293
  KD Loss:    4.1945
  Val Loss:   1.4406
  Val Acc:    60.17%
  Val Top-5:  88.83%
  Val F1 (M): 58.86%
  Saved best model to outputs/resnet18_attention_kd/best_model.pth

Epoch 8/30
  Train Loss: 1.0318
  Train Acc:  79.61%
  CE Loss:    1.0318
  KD Loss:    4.2933
  Val Loss:   1.3591
  Val Acc:    62.00%
  Val Top-5:  90.83%
  Val F1 (M): 60.14%
  Saved best model to outputs/resnet18_attention_kd/best_model.pth

Epoch 9/30
  Train Loss: 0.8859
  Train Acc:  82.48%
  CE Loss:    0.8859
  KD Loss:    4.3913
  Val Loss:   1.2913
  Val Acc:    61.17%
  Val Top-5:  90.33%
  Val F1 (M): 59.62%

Epoch 10/30
  Train Loss: 0.7733
  Train Acc:  85.68%
  CE Loss:    0.7733
  KD Loss:    4.4736
  Val Loss:   1.2322
  Val Acc:    63.00%
  Val Top-5:  91.33%
  Val F1 (M): 61.69%
  Saved best model to outputs/resnet18_attention_kd/best_model.pth

Epoch 11/30
  Train Loss: 0.6656
  Train Acc:  88.15%
  CE Loss:    0.6656
  KD Loss:    4.6180
  Val Loss:   1.1989
  Val Acc:    64.17%
  Val Top-5:  90.50%
  Val F1 (M): 62.44%
  Saved best model to outputs/resnet18_attention_kd/best_model.pth

Epoch 12/30
  Train Loss: 0.5817
  Train Acc:  89.86%
  CE Loss:    0.5817
  KD Loss:    4.6808
  Val Loss:   1.1895
  Val Acc:    64.00%
  Val Top-5:  91.83%
  Val F1 (M): 62.80%

Epoch 13/30
  Train Loss: 0.5194
  Train Acc:  91.22%
  CE Loss:    0.5194
  KD Loss:    4.8057
  Val Loss:   1.1503
  Val Acc:    65.50%
  Val Top-5:  92.00%
  Val F1 (M): 64.33%
  Saved best model to outputs/resnet18_attention_kd/best_model.pth

Epoch 14/30
  Train Loss: 0.4611
  Train Acc:  92.28%
  CE Loss:    0.4611
  KD Loss:    4.9119
  Val Loss:   1.1683
  Val Acc:    64.67%
  Val Top-5:  92.67%
  Val F1 (M): 63.18%

Epoch 15/30
  Train Loss: 0.4067
  Train Acc:  93.53%
  CE Loss:    0.4067
  KD Loss:    4.9901
  Val Loss:   1.1449
  Val Acc:    66.67%
  Val Top-5:  91.83%
  Val F1 (M): 65.32%
  Saved best model to outputs/resnet18_attention_kd/best_model.pth

Epoch 16/30
  Train Loss: 0.3630
  Train Acc:  94.62%
  CE Loss:    0.3630
  KD Loss:    5.0914
  Val Loss:   1.1331
  Val Acc:    65.50%
  Val Top-5:  93.33%
  Val F1 (M): 64.74%

Epoch 17/30
  Train Loss: 0.3299
  Train Acc:  95.11%
  CE Loss:    0.3299
  KD Loss:    5.1612
  Val Loss:   1.1436
  Val Acc:    66.50%
  Val Top-5:  91.33%
  Val F1 (M): 65.63%

Epoch 18/30
  Train Loss: 0.3037
  Train Acc:  95.89%
  CE Loss:    0.3037
  KD Loss:    5.2510
  Val Loss:   1.1244
  Val Acc:    66.50%
  Val Top-5:  92.50%
  Val F1 (M): 65.65%

Epoch 19/30
  Train Loss: 0.2764
  Train Acc:  96.06%
  CE Loss:    0.2764
  KD Loss:    5.3400
  Val Loss:   1.1033
  Val Acc:    67.50%
  Val Top-5:  92.83%
  Val F1 (M): 66.46%
  Saved best model to outputs/resnet18_attention_kd/best_model.pth

Epoch 20/30
  Train Loss: 0.2637
  Train Acc:  96.78%
  CE Loss:    0.2637
  KD Loss:    5.3994
  Val Loss:   1.1257
  Val Acc:    66.50%
  Val Top-5:  91.83%
  Val F1 (M): 65.42%

Epoch 21/30
  Train Loss: 0.2418
  Train Acc:  96.82%
  CE Loss:    0.2418
  KD Loss:    5.4596
  Val Loss:   1.1279
  Val Acc:    65.50%
  Val Top-5:  92.50%
  Val F1 (M): 64.41%

Epoch 22/30
  Train Loss: 0.2221
  Train Acc:  97.34%
  CE Loss:    0.2221
  KD Loss:    5.5070
  Val Loss:   1.1216
  Val Acc:    65.00%
  Val Top-5:  93.00%
  Val F1 (M): 64.00%

Epoch 23/30
  Train Loss: 0.2108
  Train Acc:  97.66%
  CE Loss:    0.2108
  KD Loss:    5.5493
  Val Loss:   1.1405
  Val Acc:    66.50%
  Val Top-5:  92.50%
  Val F1 (M): 65.88%

Epoch 24/30
  Train Loss: 0.2053
  Train Acc:  97.71%
  CE Loss:    0.2053
  KD Loss:    5.5609
  Val Loss:   1.1452
  Val Acc:    67.33%
  Val Top-5:  92.33%
  Val F1 (M): 66.44%

Epoch 25/30
  Train Loss: 0.1979
  Train Acc:  97.58%
  CE Loss:    0.1979
  KD Loss:    5.5842
  Val Loss:   1.1544
  Val Acc:    65.67%
  Val Top-5:  92.67%
  Val F1 (M): 64.91%

Epoch 26/30
  Train Loss: 0.1944
  Train Acc:  97.73%
  CE Loss:    0.1944
  KD Loss:    5.6174
  Val Loss:   1.1305
  Val Acc:    66.83%
  Val Top-5:  93.00%
  Val F1 (M): 65.89%

Epoch 27/30
  Train Loss: 0.1954
  Train Acc:  97.64%
  CE Loss:    0.1954
  KD Loss:    5.6066
  Val Loss:   1.1294
  Val Acc:    67.17%
  Val Top-5:  92.50%
  Val F1 (M): 66.20%

Epoch 28/30
  Train Loss: 0.1882
  Train Acc:  97.66%
  CE Loss:    0.1882
  KD Loss:    5.6156
  Val Loss:   1.1274
  Val Acc:    67.33%
  Val Top-5:  92.17%
  Val F1 (M): 66.15%

Epoch 29/30
  Train Loss: 0.1849
  Train Acc:  97.75%
  CE Loss:    0.1849
  KD Loss:    5.6474
  Val Loss:   1.1249
  Val Acc:    66.33%
  Val Top-5:  93.00%
  Val F1 (M): 65.61%

Epoch 30/30
  Train Loss: 0.1812
  Train Acc:  97.95%
  CE Loss:    0.1812
  KD Loss:    5.6188
  Val Loss:   1.1191
  Val Acc:    67.00%
  Val Top-5:  92.50%
  Val F1 (M): 66.38%
  Test Acc:   69.74%
  Test Top-5: 92.10%
  Test F1 (M):70.02%

============================================================
Training completed in 404.64s
Best validation accuracy: 67.50%
============================================================


Results saved to: outputs/resnet18_attention_kd
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: resnet18_combined_kd
Student Architecture: resnet18
Distillation Type: combined
Device: cuda
Seed: 42

Configuration saved to: outputs/resnet18_combined_kd/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: resnet18
  Total parameters: 11,279,112
  Trainable parameters: 11,279,112

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01

Setting up knowledge distillation...
  Teacher: openai/clip-vit-base-patch32
  Distillation type: combined
  Alpha CE: 1.0
  Alpha KD: 1.0
  Alpha Attention: 0.1
  Attention loss: mse


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 11.5480
  Train Acc:  2.21%
  CE Loss:    4.9965
  KD Loss:    6.5515
  Val Loss:   4.1536
  Val Acc:    8.00%
  Val Top-5:  26.50%
  Val F1 (M): 3.84%
  Saved best model to outputs/resnet18_combined_kd/best_model.pth

Epoch 2/30
  Train Loss: 7.6524
  Train Acc:  12.20%
  CE Loss:    3.8351
  KD Loss:    3.8173
  Val Loss:   3.0802
  Val Acc:    22.50%
  Val Top-5:  56.33%
  Val F1 (M): 15.73%
  Saved best model to outputs/resnet18_combined_kd/best_model.pth

Epoch 3/30
  Train Loss: 5.7714
  Train Acc:  27.94%
  CE Loss:    3.0193
  KD Loss:    2.7521
  Val Loss:   2.4427
  Val Acc:    36.33%
  Val Top-5:  73.50%
  Val F1 (M): 32.22%
  Saved best model to outputs/resnet18_combined_kd/best_model.pth

Epoch 4/30
  Train Loss: 4.7853
  Train Acc:  39.99%
  CE Loss:    2.4896
  KD Loss:    2.2957
  Val Loss:   2.0601
  Val Acc:    46.50%
  Val Top-5:  82.33%
  Val F1 (M): 43.63%
  Saved best model to outputs/resnet18_combined_kd/best_model.pth

Epoch 5/30
  Train Loss: 4.1333
  Train Acc:  49.83%
  CE Loss:    2.1127
  KD Loss:    2.0206
  Val Loss:   1.7595
  Val Acc:    54.17%
  Val Top-5:  86.83%
  Val F1 (M): 50.88%
  Saved best model to outputs/resnet18_combined_kd/best_model.pth

Epoch 6/30
  Train Loss: 3.7772
  Train Acc:  56.94%
  CE Loss:    1.8801
  KD Loss:    1.8971
  Val Loss:   1.6368
  Val Acc:    57.67%
  Val Top-5:  90.00%
  Val F1 (M): 55.27%
  Saved best model to outputs/resnet18_combined_kd/best_model.pth

Epoch 7/30
  Train Loss: 3.4915
  Train Acc:  61.07%
  CE Loss:    1.7013
  KD Loss:    1.7902
  Val Loss:   1.5329
  Val Acc:    61.17%
  Val Top-5:  89.67%
  Val F1 (M): 59.97%
  Saved best model to outputs/resnet18_combined_kd/best_model.pth

Epoch 8/30
  Train Loss: 3.2706
  Train Acc:  65.81%
  CE Loss:    1.5439
  KD Loss:    1.7268
  Val Loss:   1.4456
  Val Acc:    62.00%
  Val Top-5:  90.83%
  Val F1 (M): 59.43%
  Saved best model to outputs/resnet18_combined_kd/best_model.pth

Epoch 9/30
  Train Loss: 3.1262
  Train Acc:  68.84%
  CE Loss:    1.4353
  KD Loss:    1.6909
  Val Loss:   1.3783
  Val Acc:    64.50%
  Val Top-5:  91.17%
  Val F1 (M): 62.77%
  Saved best model to outputs/resnet18_combined_kd/best_model.pth

Epoch 10/30
  Train Loss: 2.9788
  Train Acc:  71.99%
  CE Loss:    1.3357
  KD Loss:    1.6431
  Val Loss:   1.3211
  Val Acc:    65.67%
  Val Top-5:  91.83%
  Val F1 (M): 64.20%
  Saved best model to outputs/resnet18_combined_kd/best_model.pth

Epoch 11/30
  Train Loss: 2.8690
  Train Acc:  74.39%
  CE Loss:    1.2480
  KD Loss:    1.6211
  Val Loss:   1.2670
  Val Acc:    66.00%
  Val Top-5:  91.17%
  Val F1 (M): 64.45%
  Saved best model to outputs/resnet18_combined_kd/best_model.pth

Epoch 12/30
  Train Loss: 2.7641
  Train Acc:  75.91%
  CE Loss:    1.1809
  KD Loss:    1.5832
  Val Loss:   1.2559
  Val Acc:    67.17%
  Val Top-5:  92.17%
  Val F1 (M): 65.44%
  Saved best model to outputs/resnet18_combined_kd/best_model.pth

Epoch 13/30
  Train Loss: 2.6910
  Train Acc:  77.68%
  CE Loss:    1.1229
  KD Loss:    1.5681
  Val Loss:   1.2086
  Val Acc:    68.33%
  Val Top-5:  92.67%
  Val F1 (M): 67.09%
  Saved best model to outputs/resnet18_combined_kd/best_model.pth

Epoch 14/30
  Train Loss: 2.6121
  Train Acc:  79.07%
  CE Loss:    1.0743
  KD Loss:    1.5378
  Val Loss:   1.1833
  Val Acc:    66.67%
  Val Top-5:  92.83%
  Val F1 (M): 65.13%

Epoch 15/30
  Train Loss: 2.5183
  Train Acc:  80.38%
  CE Loss:    1.0133
  KD Loss:    1.5050
  Val Loss:   1.1748
  Val Acc:    67.17%
  Val Top-5:  92.50%
  Val F1 (M): 65.64%

Epoch 16/30
  Train Loss: 2.4887
  Train Acc:  80.97%
  CE Loss:    0.9937
  KD Loss:    1.4951
  Val Loss:   1.1715
  Val Acc:    69.67%
  Val Top-5:  93.33%
  Val F1 (M): 68.44%
  Saved best model to outputs/resnet18_combined_kd/best_model.pth

Epoch 17/30
  Train Loss: 2.4320
  Train Acc:  82.12%
  CE Loss:    0.9543
  KD Loss:    1.4777
  Val Loss:   1.1382
  Val Acc:    69.33%
  Val Top-5:  93.33%
  Val F1 (M): 68.06%

Epoch 18/30
  Train Loss: 2.3856
  Train Acc:  83.24%
  CE Loss:    0.9147
  KD Loss:    1.4709
  Val Loss:   1.1163
  Val Acc:    70.17%
  Val Top-5:  93.83%
  Val F1 (M): 69.30%
  Saved best model to outputs/resnet18_combined_kd/best_model.pth

Epoch 19/30
  Train Loss: 2.3407
  Train Acc:  84.60%
  CE Loss:    0.8799
  KD Loss:    1.4608
  Val Loss:   1.1224
  Val Acc:    72.33%
  Val Top-5:  92.83%
  Val F1 (M): 71.13%
  Saved best model to outputs/resnet18_combined_kd/best_model.pth

Epoch 20/30
  Train Loss: 2.3244
  Train Acc:  84.23%
  CE Loss:    0.8676
  KD Loss:    1.4568
  Val Loss:   1.1142
  Val Acc:    70.83%
  Val Top-5:  93.00%
  Val F1 (M): 69.84%

Epoch 21/30
  Train Loss: 2.3101
  Train Acc:  84.84%
  CE Loss:    0.8531
  KD Loss:    1.4569
  Val Loss:   1.1084
  Val Acc:    70.67%
  Val Top-5:  92.50%
  Val F1 (M): 69.49%

Epoch 22/30
  Train Loss: 2.2495
  Train Acc:  85.99%
  CE Loss:    0.8286
  KD Loss:    1.4209
  Val Loss:   1.1114
  Val Acc:    71.17%
  Val Top-5:  93.17%
  Val F1 (M): 69.65%

Epoch 23/30
  Train Loss: 2.2514
  Train Acc:  85.96%
  CE Loss:    0.8190
  KD Loss:    1.4324
  Val Loss:   1.1108
  Val Acc:    71.83%
  Val Top-5:  93.33%
  Val F1 (M): 70.62%

Epoch 24/30
  Train Loss: 2.2421
  Train Acc:  86.16%
  CE Loss:    0.8132
  KD Loss:    1.4289
  Val Loss:   1.1161
  Val Acc:    70.67%
  Val Top-5:  93.17%
  Val F1 (M): 69.48%

Epoch 25/30
  Train Loss: 2.2246
  Train Acc:  86.70%
  CE Loss:    0.7994
  KD Loss:    1.4252
  Val Loss:   1.1002
  Val Acc:    70.50%
  Val Top-5:  93.67%
  Val F1 (M): 69.00%

Epoch 26/30
  Train Loss: 2.2000
  Train Acc:  86.44%
  CE Loss:    0.7904
  KD Loss:    1.4096
  Val Loss:   1.1070
  Val Acc:    71.50%
  Val Top-5:  93.67%
  Val F1 (M): 70.59%

Epoch 27/30
  Train Loss: 2.2149
  Train Acc:  86.33%
  CE Loss:    0.7928
  KD Loss:    1.4221
  Val Loss:   1.0923
  Val Acc:    71.50%
  Val Top-5:  93.67%
  Val F1 (M): 70.41%

Epoch 28/30
  Train Loss: 2.2012
  Train Acc:  86.31%
  CE Loss:    0.7892
  KD Loss:    1.4120
  Val Loss:   1.0891
  Val Acc:    71.33%
  Val Top-5:  93.67%
  Val F1 (M): 69.93%

Epoch 29/30
  Train Loss: 2.2021
  Train Acc:  86.57%
  CE Loss:    0.7869
  KD Loss:    1.4151
  Val Loss:   1.0802
  Val Acc:    71.17%
  Val Top-5:  94.17%
  Val F1 (M): 70.02%

Epoch 30/30
  Train Loss: 2.1673
  Train Acc:  86.63%
  CE Loss:    0.7800
  KD Loss:    1.3873
  Val Loss:   1.0866
  Val Acc:    70.17%
  Val Top-5:  93.83%
  Val F1 (M): 69.13%
  Test Acc:   72.52%
  Test Top-5: 93.29%
  Test F1 (M):72.38%

============================================================
Training completed in 405.80s
Best validation accuracy: 72.33%
============================================================


Results saved to: outputs/resnet18_combined_kd
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: resnet34_scratch
Student Architecture: resnet34
Distillation Type: none
Device: cuda
Seed: 42

Configuration saved to: outputs/resnet34_scratch/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: resnet34
  Total parameters: 21,387,272
  Trainable parameters: 21,387,272

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 5.2922
  Train Acc:  0.63%
  Val Loss:   5.1457
  Val Acc:    0.50%
  Val Top-5:  5.17%
  Val F1 (M): 0.06%
  Saved best model to outputs/resnet34_scratch/best_model.pth

Epoch 2/30
  Train Loss: 5.1061
  Train Acc:  1.32%
  Val Loss:   4.9867
  Val Acc:    2.17%
  Val Top-5:  11.00%
  Val F1 (M): 0.68%
  Saved best model to outputs/resnet34_scratch/best_model.pth

Epoch 3/30
  Train Loss: 4.9680
  Train Acc:  2.27%
  Val Loss:   4.9160
  Val Acc:    4.50%
  Val Top-5:  11.17%
  Val F1 (M): 2.09%
  Saved best model to outputs/resnet34_scratch/best_model.pth

Epoch 4/30
  Train Loss: 4.8623
  Train Acc:  3.24%
  Val Loss:   4.7725
  Val Acc:    3.83%
  Val Top-5:  14.33%
  Val F1 (M): 1.56%

Epoch 5/30
  Train Loss: 4.7542
  Train Acc:  3.42%
  Val Loss:   4.6855
  Val Acc:    5.00%
  Val Top-5:  15.33%
  Val F1 (M): 2.29%
  Saved best model to outputs/resnet34_scratch/best_model.pth

Epoch 6/30
  Train Loss: 4.6537
  Train Acc:  4.19%
  Val Loss:   4.5616
  Val Acc:    6.33%
  Val Top-5:  19.83%
  Val F1 (M): 3.81%
  Saved best model to outputs/resnet34_scratch/best_model.pth

Epoch 7/30
  Train Loss: 4.5209
  Train Acc:  5.54%
  Val Loss:   4.4592
  Val Acc:    6.50%
  Val Top-5:  20.33%
  Val F1 (M): 3.41%
  Saved best model to outputs/resnet34_scratch/best_model.pth

Epoch 8/30
  Train Loss: 4.4137
  Train Acc:  5.92%
  Val Loss:   4.3180
  Val Acc:    7.00%
  Val Top-5:  25.33%
  Val F1 (M): 4.81%
  Saved best model to outputs/resnet34_scratch/best_model.pth

Epoch 9/30
  Train Loss: 4.2767
  Train Acc:  7.51%
  Val Loss:   4.1721
  Val Acc:    8.00%
  Val Top-5:  27.50%
  Val F1 (M): 4.97%
  Saved best model to outputs/resnet34_scratch/best_model.pth

Epoch 10/30
  Train Loss: 4.1308
  Train Acc:  8.67%
  Val Loss:   4.1049
  Val Acc:    11.17%
  Val Top-5:  31.50%
  Val F1 (M): 7.61%
  Saved best model to outputs/resnet34_scratch/best_model.pth

Epoch 11/30
  Train Loss: 4.0122
  Train Acc:  11.18%
  Val Loss:   4.0046
  Val Acc:    10.50%
  Val Top-5:  32.67%
  Val F1 (M): 7.12%

Epoch 12/30
  Train Loss: 3.8671
  Train Acc:  11.85%
  Val Loss:   4.0381
  Val Acc:    11.67%
  Val Top-5:  29.83%
  Val F1 (M): 9.32%
  Saved best model to outputs/resnet34_scratch/best_model.pth

Epoch 13/30
  Train Loss: 3.7412
  Train Acc:  13.78%
  Val Loss:   3.8486
  Val Acc:    12.00%
  Val Top-5:  36.50%
  Val F1 (M): 9.69%
  Saved best model to outputs/resnet34_scratch/best_model.pth

Epoch 14/30
  Train Loss: 3.6310
  Train Acc:  15.23%
  Val Loss:   3.9589
  Val Acc:    11.50%
  Val Top-5:  35.17%
  Val F1 (M): 9.16%

Epoch 15/30
  Train Loss: 3.5354
  Train Acc:  17.45%
  Val Loss:   3.7445
  Val Acc:    13.33%
  Val Top-5:  39.83%
  Val F1 (M): 11.00%
  Saved best model to outputs/resnet34_scratch/best_model.pth

Epoch 16/30
  Train Loss: 3.4296
  Train Acc:  18.84%
  Val Loss:   3.7137
  Val Acc:    14.33%
  Val Top-5:  38.50%
  Val F1 (M): 12.30%
  Saved best model to outputs/resnet34_scratch/best_model.pth

Epoch 17/30
  Train Loss: 3.3003
  Train Acc:  20.44%
  Val Loss:   3.5559
  Val Acc:    13.50%
  Val Top-5:  42.50%
  Val F1 (M): 12.05%

Epoch 18/30
  Train Loss: 3.2177
  Train Acc:  23.07%
  Val Loss:   3.4806
  Val Acc:    16.67%
  Val Top-5:  45.83%
  Val F1 (M): 13.37%
  Saved best model to outputs/resnet34_scratch/best_model.pth

Epoch 19/30
  Train Loss: 3.1318
  Train Acc:  22.82%
  Val Loss:   3.4119
  Val Acc:    16.83%
  Val Top-5:  48.17%
  Val F1 (M): 14.10%
  Saved best model to outputs/resnet34_scratch/best_model.pth

Epoch 20/30
  Train Loss: 3.0443
  Train Acc:  25.41%
  Val Loss:   3.3590
  Val Acc:    18.67%
  Val Top-5:  48.83%
  Val F1 (M): 15.79%
  Saved best model to outputs/resnet34_scratch/best_model.pth

Epoch 21/30
  Train Loss: 2.9742
  Train Acc:  27.21%
  Val Loss:   3.2917
  Val Acc:    18.17%
  Val Top-5:  50.00%
  Val F1 (M): 16.05%

Epoch 22/30
  Train Loss: 2.9088
  Train Acc:  28.42%
  Val Loss:   3.2413
  Val Acc:    20.67%
  Val Top-5:  53.33%
  Val F1 (M): 17.55%
  Saved best model to outputs/resnet34_scratch/best_model.pth

Epoch 23/30
  Train Loss: 2.8532
  Train Acc:  29.43%
  Val Loss:   3.2338
  Val Acc:    21.00%
  Val Top-5:  52.00%
  Val F1 (M): 17.80%
  Saved best model to outputs/resnet34_scratch/best_model.pth

Epoch 24/30
  Train Loss: 2.7800
  Train Acc:  31.32%
  Val Loss:   3.1891
  Val Acc:    21.67%
  Val Top-5:  52.00%
  Val F1 (M): 18.69%
  Saved best model to outputs/resnet34_scratch/best_model.pth

Epoch 25/30
  Train Loss: 2.7477
  Train Acc:  32.51%
  Val Loss:   3.1571
  Val Acc:    22.50%
  Val Top-5:  53.17%
  Val F1 (M): 19.62%
  Saved best model to outputs/resnet34_scratch/best_model.pth

Epoch 26/30
  Train Loss: 2.7260
  Train Acc:  32.94%
  Val Loss:   3.1414
  Val Acc:    22.67%
  Val Top-5:  54.00%
  Val F1 (M): 19.82%
  Saved best model to outputs/resnet34_scratch/best_model.pth

Epoch 27/30
  Train Loss: 2.7009
  Train Acc:  33.35%
  Val Loss:   3.1476
  Val Acc:    23.00%
  Val Top-5:  54.33%
  Val F1 (M): 20.24%
  Saved best model to outputs/resnet34_scratch/best_model.pth

Epoch 28/30
  Train Loss: 2.6713
  Train Acc:  34.51%
  Val Loss:   3.1291
  Val Acc:    22.33%
  Val Top-5:  53.83%
  Val F1 (M): 19.21%

Epoch 29/30
  Train Loss: 2.6632
  Train Acc:  34.41%
  Val Loss:   3.1254
  Val Acc:    23.00%
  Val Top-5:  54.83%
  Val F1 (M): 19.88%

Epoch 30/30
  Train Loss: 2.6440
  Train Acc:  35.10%
  Val Loss:   3.1190
  Val Acc:    22.83%
  Val Top-5:  54.00%
  Val F1 (M): 19.77%
  Test Acc:   22.54%
  Test Top-5: 52.38%
  Test F1 (M):21.09%

============================================================
Training completed in 349.10s
Best validation accuracy: 23.00%
============================================================


Results saved to: outputs/resnet34_scratch
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: resnet34_transfer
Student Architecture: resnet34
Distillation Type: none
Device: cuda
Seed: 42

Configuration saved to: outputs/resnet34_transfer/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: resnet34
  Total parameters: 21,387,272
  Trainable parameters: 21,387,272

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 5.1530
  Train Acc:  3.72%
  Val Loss:   4.4643
  Val Acc:    12.50%
  Val Top-5:  41.00%
  Val F1 (M): 9.01%
  Saved best model to outputs/resnet34_transfer/best_model.pth

Epoch 2/30
  Train Loss: 3.8405
  Train Acc:  21.13%
  Val Loss:   2.8941
  Val Acc:    32.67%
  Val Top-5:  70.83%
  Val F1 (M): 25.50%
  Saved best model to outputs/resnet34_transfer/best_model.pth

Epoch 3/30
  Train Loss: 2.6336
  Train Acc:  41.61%
  Val Loss:   2.0669
  Val Acc:    51.00%
  Val Top-5:  82.67%
  Val F1 (M): 46.92%
  Saved best model to outputs/resnet34_transfer/best_model.pth

Epoch 4/30
  Train Loss: 1.8945
  Train Acc:  57.38%
  Val Loss:   1.7345
  Val Acc:    58.50%
  Val Top-5:  88.00%
  Val F1 (M): 55.39%
  Saved best model to outputs/resnet34_transfer/best_model.pth

Epoch 5/30
  Train Loss: 1.4514
  Train Acc:  65.87%
  Val Loss:   1.3682
  Val Acc:    63.33%
  Val Top-5:  91.00%
  Val F1 (M): 61.05%
  Saved best model to outputs/resnet34_transfer/best_model.pth

Epoch 6/30
  Train Loss: 1.1318
  Train Acc:  72.73%
  Val Loss:   1.2409
  Val Acc:    66.50%
  Val Top-5:  91.83%
  Val F1 (M): 64.72%
  Saved best model to outputs/resnet34_transfer/best_model.pth

Epoch 7/30
  Train Loss: 0.9091
  Train Acc:  77.68%
  Val Loss:   1.1973
  Val Acc:    66.67%
  Val Top-5:  92.33%
  Val F1 (M): 65.13%
  Saved best model to outputs/resnet34_transfer/best_model.pth

Epoch 8/30
  Train Loss: 0.7317
  Train Acc:  82.79%
  Val Loss:   1.0963
  Val Acc:    66.83%
  Val Top-5:  92.67%
  Val F1 (M): 65.15%
  Saved best model to outputs/resnet34_transfer/best_model.pth

Epoch 9/30
  Train Loss: 0.6110
  Train Acc:  85.53%
  Val Loss:   1.0259
  Val Acc:    69.67%
  Val Top-5:  93.33%
  Val F1 (M): 68.85%
  Saved best model to outputs/resnet34_transfer/best_model.pth

Epoch 10/30
  Train Loss: 0.5033
  Train Acc:  88.02%
  Val Loss:   0.9814
  Val Acc:    71.17%
  Val Top-5:  93.83%
  Val F1 (M): 70.28%
  Saved best model to outputs/resnet34_transfer/best_model.pth

Epoch 11/30
  Train Loss: 0.4336
  Train Acc:  90.16%
  Val Loss:   0.9703
  Val Acc:    71.83%
  Val Top-5:  93.17%
  Val F1 (M): 70.65%
  Saved best model to outputs/resnet34_transfer/best_model.pth

Epoch 12/30
  Train Loss: 0.3531
  Train Acc:  92.06%
  Val Loss:   1.0100
  Val Acc:    70.50%
  Val Top-5:  92.50%
  Val F1 (M): 70.07%

Epoch 13/30
  Train Loss: 0.3001
  Train Acc:  93.42%
  Val Loss:   0.9834
  Val Acc:    71.33%
  Val Top-5:  93.50%
  Val F1 (M): 70.95%

Epoch 14/30
  Train Loss: 0.2544
  Train Acc:  94.88%
  Val Loss:   0.9631
  Val Acc:    73.50%
  Val Top-5:  93.50%
  Val F1 (M): 72.57%
  Saved best model to outputs/resnet34_transfer/best_model.pth

Epoch 15/30
  Train Loss: 0.2253
  Train Acc:  95.57%
  Val Loss:   0.9591
  Val Acc:    73.33%
  Val Top-5:  93.17%
  Val F1 (M): 72.68%

Epoch 16/30
  Train Loss: 0.1917
  Train Acc:  96.65%
  Val Loss:   0.9468
  Val Acc:    72.33%
  Val Top-5:  93.83%
  Val F1 (M): 71.77%

Epoch 17/30
  Train Loss: 0.1641
  Train Acc:  97.21%
  Val Loss:   0.9436
  Val Acc:    74.00%
  Val Top-5:  94.17%
  Val F1 (M): 73.23%
  Saved best model to outputs/resnet34_transfer/best_model.pth

Epoch 18/30
  Train Loss: 0.1541
  Train Acc:  97.58%
  Val Loss:   0.9453
  Val Acc:    73.33%
  Val Top-5:  93.50%
  Val F1 (M): 72.85%

Epoch 19/30
  Train Loss: 0.1350
  Train Acc:  97.90%
  Val Loss:   0.9441
  Val Acc:    73.67%
  Val Top-5:  93.67%
  Val F1 (M): 72.82%

Epoch 20/30
  Train Loss: 0.1200
  Train Acc:  98.40%
  Val Loss:   0.9534
  Val Acc:    73.67%
  Val Top-5:  94.50%
  Val F1 (M): 72.87%

Epoch 21/30
  Train Loss: 0.1044
  Train Acc:  98.79%
  Val Loss:   0.9516
  Val Acc:    73.33%
  Val Top-5:  93.83%
  Val F1 (M): 72.51%

Epoch 22/30
  Train Loss: 0.1023
  Train Acc:  98.72%
  Val Loss:   0.9418
  Val Acc:    73.33%
  Val Top-5:  94.00%
  Val F1 (M): 72.81%

Epoch 23/30
  Train Loss: 0.0901
  Train Acc:  99.22%
  Val Loss:   0.9633
  Val Acc:    73.17%
  Val Top-5:  93.83%
  Val F1 (M): 72.83%

Epoch 24/30
  Train Loss: 0.0813
  Train Acc:  99.27%
  Val Loss:   0.9503
  Val Acc:    73.83%
  Val Top-5:  94.50%
  Val F1 (M): 73.39%

Epoch 25/30
  Train Loss: 0.0834
  Train Acc:  98.94%
  Val Loss:   0.9452
  Val Acc:    74.00%
  Val Top-5:  94.67%
  Val F1 (M): 73.50%

Epoch 26/30
  Train Loss: 0.0830
  Train Acc:  98.90%
  Val Loss:   0.9484
  Val Acc:    73.67%
  Val Top-5:  94.17%
  Val F1 (M): 73.33%

Epoch 27/30
  Train Loss: 0.0786
  Train Acc:  99.29%
  Val Loss:   0.9397
  Val Acc:    73.67%
  Val Top-5:  94.17%
  Val F1 (M): 73.18%

Epoch 28/30
  Train Loss: 0.0776
  Train Acc:  99.26%
  Val Loss:   0.9359
  Val Acc:    74.33%
  Val Top-5:  94.17%
  Val F1 (M): 73.76%
  Saved best model to outputs/resnet34_transfer/best_model.pth

Epoch 29/30
  Train Loss: 0.0725
  Train Acc:  99.35%
  Val Loss:   0.9462
  Val Acc:    73.33%
  Val Top-5:  94.00%
  Val F1 (M): 72.77%

Epoch 30/30
  Train Loss: 0.0747
  Train Acc:  99.24%
  Val Loss:   0.9541
  Val Acc:    73.00%
  Val Top-5:  94.17%
  Val F1 (M): 72.46%
  Test Acc:   73.70%
  Test Top-5: 93.65%
  Test F1 (M):73.71%

============================================================
Training completed in 344.77s
Best validation accuracy: 74.33%
============================================================


Results saved to: outputs/resnet34_transfer
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: resnet34_logit_kd
Student Architecture: resnet34
Distillation Type: logit
Device: cuda
Seed: 42

Configuration saved to: outputs/resnet34_logit_kd/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: resnet34
  Total parameters: 21,387,272
  Trainable parameters: 21,387,272

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01

Setting up knowledge distillation...
  Teacher: openai/clip-vit-base-patch32
  Distillation type: logit
  Alpha CE: 1.0
  Alpha KD: 1.0


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 11.5448
  Train Acc:  2.62%
  CE Loss:    4.9892
  KD Loss:    6.5555
  Val Loss:   4.1665
  Val Acc:    6.83%
  Val Top-5:  25.67%
  Val F1 (M): 3.30%
  Saved best model to outputs/resnet34_logit_kd/best_model.pth

Epoch 2/30
  Train Loss: 7.4669
  Train Acc:  13.26%
  CE Loss:    3.7610
  KD Loss:    3.7059
  Val Loss:   2.8801
  Val Acc:    25.17%
  Val Top-5:  61.67%
  Val F1 (M): 19.54%
  Saved best model to outputs/resnet34_logit_kd/best_model.pth

Epoch 3/30
  Train Loss: 5.3957
  Train Acc:  31.23%
  CE Loss:    2.8314
  KD Loss:    2.5643
  Val Loss:   2.2135
  Val Acc:    41.33%
  Val Top-5:  80.17%
  Val F1 (M): 35.25%
  Saved best model to outputs/resnet34_logit_kd/best_model.pth

Epoch 4/30
  Train Loss: 4.3658
  Train Acc:  46.19%
  CE Loss:    2.2564
  KD Loss:    2.1094
  Val Loss:   1.7792
  Val Acc:    50.83%
  Val Top-5:  85.17%
  Val F1 (M): 46.03%
  Saved best model to outputs/resnet34_logit_kd/best_model.pth

Epoch 5/30
  Train Loss: 3.7336
  Train Acc:  56.47%
  CE Loss:    1.8729
  KD Loss:    1.8607
  Val Loss:   1.5762
  Val Acc:    57.17%
  Val Top-5:  89.00%
  Val F1 (M): 53.66%
  Saved best model to outputs/resnet34_logit_kd/best_model.pth

Epoch 6/30
  Train Loss: 3.3866
  Train Acc:  62.35%
  CE Loss:    1.6258
  KD Loss:    1.7608
  Val Loss:   1.4349
  Val Acc:    63.00%
  Val Top-5:  91.17%
  Val F1 (M): 60.19%
  Saved best model to outputs/resnet34_logit_kd/best_model.pth

Epoch 7/30
  Train Loss: 3.1158
  Train Acc:  68.17%
  CE Loss:    1.4486
  KD Loss:    1.6672
  Val Loss:   1.2872
  Val Acc:    66.50%
  Val Top-5:  92.33%
  Val F1 (M): 64.80%
  Saved best model to outputs/resnet34_logit_kd/best_model.pth

Epoch 8/30
  Train Loss: 2.9104
  Train Acc:  71.37%
  CE Loss:    1.3006
  KD Loss:    1.6098
  Val Loss:   1.2116
  Val Acc:    68.33%
  Val Top-5:  92.50%
  Val F1 (M): 66.66%
  Saved best model to outputs/resnet34_logit_kd/best_model.pth

Epoch 9/30
  Train Loss: 2.7424
  Train Acc:  76.12%
  CE Loss:    1.1698
  KD Loss:    1.5726
  Val Loss:   1.1783
  Val Acc:    69.50%
  Val Top-5:  92.50%
  Val F1 (M): 67.81%
  Saved best model to outputs/resnet34_logit_kd/best_model.pth

Epoch 10/30
  Train Loss: 2.6386
  Train Acc:  78.16%
  CE Loss:    1.0959
  KD Loss:    1.5427
  Val Loss:   1.1183
  Val Acc:    72.83%
  Val Top-5:  94.17%
  Val F1 (M): 71.99%
  Saved best model to outputs/resnet34_logit_kd/best_model.pth

Epoch 11/30
  Train Loss: 2.5181
  Train Acc:  80.08%
  CE Loss:    1.0050
  KD Loss:    1.5131
  Val Loss:   1.0792
  Val Acc:    73.00%
  Val Top-5:  93.83%
  Val F1 (M): 71.80%
  Saved best model to outputs/resnet34_logit_kd/best_model.pth

Epoch 12/30
  Train Loss: 2.4290
  Train Acc:  82.51%
  CE Loss:    0.9429
  KD Loss:    1.4861
  Val Loss:   1.0216
  Val Acc:    73.83%
  Val Top-5:  95.00%
  Val F1 (M): 72.20%
  Saved best model to outputs/resnet34_logit_kd/best_model.pth

Epoch 13/30
  Train Loss: 2.3616
  Train Acc:  82.98%
  CE Loss:    0.8922
  KD Loss:    1.4693
  Val Loss:   1.0133
  Val Acc:    75.50%
  Val Top-5:  94.50%
  Val F1 (M): 74.39%
  Saved best model to outputs/resnet34_logit_kd/best_model.pth

Epoch 14/30
  Train Loss: 2.2885
  Train Acc:  85.34%
  CE Loss:    0.8319
  KD Loss:    1.4566
  Val Loss:   1.0075
  Val Acc:    75.00%
  Val Top-5:  95.00%
  Val F1 (M): 73.93%

Epoch 15/30
  Train Loss: 2.2336
  Train Acc:  86.66%
  CE Loss:    0.7874
  KD Loss:    1.4461
  Val Loss:   0.9975
  Val Acc:    74.00%
  Val Top-5:  94.50%
  Val F1 (M): 73.04%

Epoch 16/30
  Train Loss: 2.1746
  Train Acc:  87.35%
  CE Loss:    0.7589
  KD Loss:    1.4156
  Val Loss:   0.9519
  Val Acc:    75.33%
  Val Top-5:  94.83%
  Val F1 (M): 74.32%

Epoch 17/30
  Train Loss: 2.1208
  Train Acc:  88.08%
  CE Loss:    0.7172
  KD Loss:    1.4036
  Val Loss:   0.9540
  Val Acc:    75.33%
  Val Top-5:  94.00%
  Val F1 (M): 74.59%

Epoch 18/30
  Train Loss: 2.0923
  Train Acc:  88.71%
  CE Loss:    0.7008
  KD Loss:    1.3915
  Val Loss:   0.9503
  Val Acc:    75.17%
  Val Top-5:  95.17%
  Val F1 (M): 74.56%

Epoch 19/30
  Train Loss: 2.0545
  Train Acc:  89.84%
  CE Loss:    0.6739
  KD Loss:    1.3806
  Val Loss:   0.9566
  Val Acc:    75.33%
  Val Top-5:  94.67%
  Val F1 (M): 74.29%

Epoch 20/30
  Train Loss: 2.0388
  Train Acc:  90.20%
  CE Loss:    0.6552
  KD Loss:    1.3835
  Val Loss:   0.9324
  Val Acc:    76.83%
  Val Top-5:  95.17%
  Val F1 (M): 75.72%
  Saved best model to outputs/resnet34_logit_kd/best_model.pth

Epoch 21/30
  Train Loss: 1.9960
  Train Acc:  90.77%
  CE Loss:    0.6326
  KD Loss:    1.3634
  Val Loss:   0.9357
  Val Acc:    75.00%
  Val Top-5:  93.83%
  Val F1 (M): 73.75%

Epoch 22/30
  Train Loss: 1.9699
  Train Acc:  91.26%
  CE Loss:    0.6229
  KD Loss:    1.3471
  Val Loss:   0.9246
  Val Acc:    76.17%
  Val Top-5:  95.17%
  Val F1 (M): 75.25%

Epoch 23/30
  Train Loss: 1.9768
  Train Acc:  91.46%
  CE Loss:    0.6110
  KD Loss:    1.3658
  Val Loss:   0.9247
  Val Acc:    76.33%
  Val Top-5:  95.17%
  Val F1 (M): 75.48%

Epoch 24/30
  Train Loss: 1.9206
  Train Acc:  91.70%
  CE Loss:    0.5843
  KD Loss:    1.3363
  Val Loss:   0.9199
  Val Acc:    76.67%
  Val Top-5:  94.67%
  Val F1 (M): 76.04%

Epoch 25/30
  Train Loss: 1.9219
  Train Acc:  91.96%
  CE Loss:    0.5871
  KD Loss:    1.3348
  Val Loss:   0.9229
  Val Acc:    75.67%
  Val Top-5:  95.00%
  Val F1 (M): 74.68%

Epoch 26/30
  Train Loss: 1.9286
  Train Acc:  91.48%
  CE Loss:    0.5911
  KD Loss:    1.3375
  Val Loss:   0.9376
  Val Acc:    74.67%
  Val Top-5:  95.00%
  Val F1 (M): 73.63%

Epoch 27/30
  Train Loss: 1.9146
  Train Acc:  92.24%
  CE Loss:    0.5632
  KD Loss:    1.3514
  Val Loss:   0.9295
  Val Acc:    75.67%
  Val Top-5:  94.83%
  Val F1 (M): 74.71%

Epoch 28/30
  Train Loss: 1.8929
  Train Acc:  92.62%
  CE Loss:    0.5607
  KD Loss:    1.3323
  Val Loss:   0.9306
  Val Acc:    74.67%
  Val Top-5:  94.67%
  Val F1 (M): 73.94%

Epoch 29/30
  Train Loss: 1.9015
  Train Acc:  91.83%
  CE Loss:    0.5714
  KD Loss:    1.3301
  Val Loss:   0.9240
  Val Acc:    75.83%
  Val Top-5:  94.00%
  Val F1 (M): 75.06%

Epoch 30/30
  Train Loss: 1.8890
  Train Acc:  92.15%
  CE Loss:    0.5660
  KD Loss:    1.3230
  Val Loss:   0.9287
  Val Acc:    76.33%
  Val Top-5:  94.00%
  Val F1 (M): 75.46%
  Test Acc:   76.35%
  Test Top-5: 94.62%
  Test F1 (M):76.23%

============================================================
Training completed in 377.38s
Best validation accuracy: 76.83%
============================================================


Results saved to: outputs/resnet34_logit_kd
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: resnet34_attention_kd
Student Architecture: resnet34
Distillation Type: attention
Device: cuda
Seed: 42

Configuration saved to: outputs/resnet34_attention_kd/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: resnet34
  Total parameters: 21,387,272
  Trainable parameters: 21,387,272

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01

Setting up knowledge distillation...
  Teacher: openai/clip-vit-base-patch32
  Distillation type: attention
  Alpha CE: 1.0
  Alpha KD: 0.0
  Alpha Attention: 0.5
  Attention loss: mse


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 5.1673
  Train Acc:  4.52%
  CE Loss:    5.1673
  KD Loss:    7.9000
  Val Loss:   4.5872
  Val Acc:    14.17%
  Val Top-5:  39.17%
  Val F1 (M): 8.61%
  Saved best model to outputs/resnet34_attention_kd/best_model.pth

Epoch 2/30
  Train Loss: 3.8779
  Train Acc:  25.56%
  CE Loss:    3.8779
  KD Loss:    6.1943
  Val Loss:   2.9181
  Val Acc:    34.17%
  Val Top-5:  71.17%
  Val F1 (M): 27.94%
  Saved best model to outputs/resnet34_attention_kd/best_model.pth

Epoch 3/30
  Train Loss: 2.6352
  Train Acc:  47.04%
  CE Loss:    2.6352
  KD Loss:    4.8169
  Val Loss:   2.0747
  Val Acc:    52.33%
  Val Top-5:  84.00%
  Val F1 (M): 47.69%
  Saved best model to outputs/resnet34_attention_kd/best_model.pth

Epoch 4/30
  Train Loss: 1.9157
  Train Acc:  61.29%
  CE Loss:    1.9157
  KD Loss:    4.3290
  Val Loss:   1.6400
  Val Acc:    56.67%
  Val Top-5:  87.83%
  Val F1 (M): 53.47%
  Saved best model to outputs/resnet34_attention_kd/best_model.pth

Epoch 5/30
  Train Loss: 1.4414
  Train Acc:  71.34%
  CE Loss:    1.4414
  KD Loss:    4.2098
  Val Loss:   1.4127
  Val Acc:    63.33%
  Val Top-5:  91.00%
  Val F1 (M): 61.48%
  Saved best model to outputs/resnet34_attention_kd/best_model.pth

Epoch 6/30
  Train Loss: 1.1277
  Train Acc:  77.98%
  CE Loss:    1.1277
  KD Loss:    4.2204
  Val Loss:   1.2580
  Val Acc:    64.00%
  Val Top-5:  92.17%
  Val F1 (M): 62.17%
  Saved best model to outputs/resnet34_attention_kd/best_model.pth

Epoch 7/30
  Train Loss: 0.9089
  Train Acc:  82.74%
  CE Loss:    0.9089
  KD Loss:    4.3071
  Val Loss:   1.1677
  Val Acc:    66.00%
  Val Top-5:  92.83%
  Val F1 (M): 64.51%
  Saved best model to outputs/resnet34_attention_kd/best_model.pth

Epoch 8/30
  Train Loss: 0.7550
  Train Acc:  85.92%
  CE Loss:    0.7550
  KD Loss:    4.4376
  Val Loss:   1.1076
  Val Acc:    69.17%
  Val Top-5:  92.67%
  Val F1 (M): 67.61%
  Saved best model to outputs/resnet34_attention_kd/best_model.pth

Epoch 9/30
  Train Loss: 0.6046
  Train Acc:  89.01%
  CE Loss:    0.6046
  KD Loss:    4.5901
  Val Loss:   1.0262
  Val Acc:    73.00%
  Val Top-5:  92.83%
  Val F1 (M): 71.93%
  Saved best model to outputs/resnet34_attention_kd/best_model.pth

Epoch 10/30
  Train Loss: 0.5066
  Train Acc:  91.46%
  CE Loss:    0.5066
  KD Loss:    4.7114
  Val Loss:   1.0286
  Val Acc:    72.67%
  Val Top-5:  93.33%
  Val F1 (M): 71.67%

Epoch 11/30
  Train Loss: 0.4338
  Train Acc:  92.73%
  CE Loss:    0.4338
  KD Loss:    4.8268
  Val Loss:   1.0642
  Val Acc:    71.00%
  Val Top-5:  92.33%
  Val F1 (M): 70.44%

Epoch 12/30
  Train Loss: 0.3602
  Train Acc:  94.94%
  CE Loss:    0.3602
  KD Loss:    4.9720
  Val Loss:   1.0071
  Val Acc:    72.17%
  Val Top-5:  92.67%
  Val F1 (M): 71.17%

Epoch 13/30
  Train Loss: 0.3024
  Train Acc:  96.24%
  CE Loss:    0.3024
  KD Loss:    5.0778
  Val Loss:   1.0175
  Val Acc:    71.00%
  Val Top-5:  92.33%
  Val F1 (M): 70.19%

Epoch 14/30
  Train Loss: 0.2566
  Train Acc:  96.78%
  CE Loss:    0.2566
  KD Loss:    5.2494
  Val Loss:   1.0451
  Val Acc:    72.00%
  Val Top-5:  92.00%
  Val F1 (M): 71.04%

Epoch 15/30
  Train Loss: 0.2192
  Train Acc:  97.71%
  CE Loss:    0.2192
  KD Loss:    5.3302
  Val Loss:   1.0186
  Val Acc:    72.50%
  Val Top-5:  93.33%
  Val F1 (M): 71.48%

Epoch 16/30
  Train Loss: 0.1903
  Train Acc:  98.14%
  CE Loss:    0.1903
  KD Loss:    5.4523
  Val Loss:   1.0176
  Val Acc:    72.33%
  Val Top-5:  93.17%
  Val F1 (M): 71.91%

Epoch 17/30
  Train Loss: 0.1704
  Train Acc:  98.20%
  CE Loss:    0.1704
  KD Loss:    5.5348
  Val Loss:   0.9979
  Val Acc:    73.00%
  Val Top-5:  92.33%
  Val F1 (M): 71.96%

Epoch 18/30
  Train Loss: 0.1518
  Train Acc:  98.62%
  CE Loss:    0.1518
  KD Loss:    5.6406
  Val Loss:   1.0215
  Val Acc:    72.67%
  Val Top-5:  92.33%
  Val F1 (M): 72.06%

Epoch 19/30
  Train Loss: 0.1360
  Train Acc:  98.72%
  CE Loss:    0.1360
  KD Loss:    5.6868
  Val Loss:   1.0125
  Val Acc:    72.33%
  Val Top-5:  93.00%
  Val F1 (M): 71.64%

Epoch 20/30
  Train Loss: 0.1212
  Train Acc:  99.07%
  CE Loss:    0.1212
  KD Loss:    5.7751
  Val Loss:   1.0113
  Val Acc:    73.33%
  Val Top-5:  92.33%
  Val F1 (M): 72.58%
  Saved best model to outputs/resnet34_attention_kd/best_model.pth

Epoch 21/30
  Train Loss: 0.1149
  Train Acc:  98.88%
  CE Loss:    0.1149
  KD Loss:    5.8025
  Val Loss:   1.0041
  Val Acc:    71.67%
  Val Top-5:  93.17%
  Val F1 (M): 70.92%

Epoch 22/30
  Train Loss: 0.1002
  Train Acc:  99.24%
  CE Loss:    0.1002
  KD Loss:    5.8573
  Val Loss:   1.0012
  Val Acc:    72.17%
  Val Top-5:  92.83%
  Val F1 (M): 71.39%

Epoch 23/30
  Train Loss: 0.0909
  Train Acc:  99.48%
  CE Loss:    0.0909
  KD Loss:    5.9215
  Val Loss:   1.0268
  Val Acc:    74.00%
  Val Top-5:  92.17%
  Val F1 (M): 73.17%
  Saved best model to outputs/resnet34_attention_kd/best_model.pth

Epoch 24/30
  Train Loss: 0.0860
  Train Acc:  99.37%
  CE Loss:    0.0860
  KD Loss:    5.9287
  Val Loss:   0.9964
  Val Acc:    74.33%
  Val Top-5:  92.83%
  Val F1 (M): 73.68%
  Saved best model to outputs/resnet34_attention_kd/best_model.pth

Epoch 25/30
  Train Loss: 0.0867
  Train Acc:  99.20%
  CE Loss:    0.0867
  KD Loss:    5.9558
  Val Loss:   1.0026
  Val Acc:    72.50%
  Val Top-5:  92.67%
  Val F1 (M): 72.03%

Epoch 26/30
  Train Loss: 0.0840
  Train Acc:  99.31%
  CE Loss:    0.0840
  KD Loss:    6.0048
  Val Loss:   1.0460
  Val Acc:    72.50%
  Val Top-5:  92.33%
  Val F1 (M): 71.65%

Epoch 27/30
  Train Loss: 0.0766
  Train Acc:  99.48%
  CE Loss:    0.0766
  KD Loss:    6.0287
  Val Loss:   1.0246
  Val Acc:    73.33%
  Val Top-5:  92.33%
  Val F1 (M): 72.50%

Epoch 28/30
  Train Loss: 0.0724
  Train Acc:  99.50%
  CE Loss:    0.0724
  KD Loss:    6.0246
  Val Loss:   1.0159
  Val Acc:    73.50%
  Val Top-5:  93.33%
  Val F1 (M): 72.67%

Epoch 29/30
  Train Loss: 0.0757
  Train Acc:  99.22%
  CE Loss:    0.0757
  KD Loss:    6.0357
  Val Loss:   1.0165
  Val Acc:    73.17%
  Val Top-5:  93.17%
  Val F1 (M): 72.26%

Epoch 30/30
  Train Loss: 0.0710
  Train Acc:  99.39%
  CE Loss:    0.0710
  KD Loss:    5.9883
  Val Loss:   1.0234
  Val Acc:    73.33%
  Val Top-5:  92.33%
  Val F1 (M): 72.53%
  Test Acc:   73.51%
  Test Top-5: 93.04%
  Test F1 (M):73.55%

============================================================
Training completed in 460.51s
Best validation accuracy: 74.33%
============================================================


Results saved to: outputs/resnet34_attention_kd
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: resnet34_combined_kd
Student Architecture: resnet34
Distillation Type: combined
Device: cuda
Seed: 42

Configuration saved to: outputs/resnet34_combined_kd/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: resnet34
  Total parameters: 21,387,272
  Trainable parameters: 21,387,272

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01

Setting up knowledge distillation...
  Teacher: openai/clip-vit-base-patch32
  Distillation type: combined
  Alpha CE: 1.0
  Alpha KD: 1.0
  Alpha Attention: 0.1
  Attention loss: mse


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 11.5448
  Train Acc:  2.62%
  CE Loss:    4.9892
  KD Loss:    6.5555
  Val Loss:   4.1678
  Val Acc:    6.50%
  Val Top-5:  26.00%
  Val F1 (M): 3.17%
  Saved best model to outputs/resnet34_combined_kd/best_model.pth

Epoch 2/30
  Train Loss: 7.4669
  Train Acc:  13.26%
  CE Loss:    3.7610
  KD Loss:    3.7059
  Val Loss:   2.8798
  Val Acc:    25.50%
  Val Top-5:  61.67%
  Val F1 (M): 19.65%
  Saved best model to outputs/resnet34_combined_kd/best_model.pth

Epoch 3/30
  Train Loss: 5.3957
  Train Acc:  31.23%
  CE Loss:    2.8314
  KD Loss:    2.5643
  Val Loss:   2.2022
  Val Acc:    42.67%
  Val Top-5:  80.50%
  Val F1 (M): 36.39%
  Saved best model to outputs/resnet34_combined_kd/best_model.pth

Epoch 4/30
  Train Loss: 4.3658
  Train Acc:  46.19%
  CE Loss:    2.2564
  KD Loss:    2.1094
  Val Loss:   1.7874
  Val Acc:    50.50%
  Val Top-5:  85.50%
  Val F1 (M): 45.93%
  Saved best model to outputs/resnet34_combined_kd/best_model.pth

Epoch 5/30
  Train Loss: 3.7336
  Train Acc:  56.47%
  CE Loss:    1.8729
  KD Loss:    1.8607
  Val Loss:   1.5773
  Val Acc:    57.00%
  Val Top-5:  89.00%
  Val F1 (M): 53.47%
  Saved best model to outputs/resnet34_combined_kd/best_model.pth

Epoch 6/30
  Train Loss: 3.3866
  Train Acc:  62.35%
  CE Loss:    1.6258
  KD Loss:    1.7608
  Val Loss:   1.4468
  Val Acc:    63.00%
  Val Top-5:  90.83%
  Val F1 (M): 60.32%
  Saved best model to outputs/resnet34_combined_kd/best_model.pth

Epoch 7/30
  Train Loss: 3.1158
  Train Acc:  68.17%
  CE Loss:    1.4486
  KD Loss:    1.6672
  Val Loss:   1.2914
  Val Acc:    66.33%
  Val Top-5:  92.33%
  Val F1 (M): 64.41%
  Saved best model to outputs/resnet34_combined_kd/best_model.pth

Epoch 8/30
  Train Loss: 2.9104
  Train Acc:  71.37%
  CE Loss:    1.3006
  KD Loss:    1.6098
  Val Loss:   1.2169
  Val Acc:    68.00%
  Val Top-5:  92.17%
  Val F1 (M): 66.41%
  Saved best model to outputs/resnet34_combined_kd/best_model.pth

Epoch 9/30
  Train Loss: 2.7424
  Train Acc:  76.12%
  CE Loss:    1.1698
  KD Loss:    1.5726
  Val Loss:   1.1851
  Val Acc:    69.17%
  Val Top-5:  92.17%
  Val F1 (M): 67.45%
  Saved best model to outputs/resnet34_combined_kd/best_model.pth

Epoch 10/30
  Train Loss: 2.6386
  Train Acc:  78.16%
  CE Loss:    1.0959
  KD Loss:    1.5427
  Val Loss:   1.1263
  Val Acc:    71.83%
  Val Top-5:  94.33%
  Val F1 (M): 71.04%
  Saved best model to outputs/resnet34_combined_kd/best_model.pth

Epoch 11/30
  Train Loss: 2.5181
  Train Acc:  80.08%
  CE Loss:    1.0050
  KD Loss:    1.5131
  Val Loss:   1.0920
  Val Acc:    72.67%
  Val Top-5:  93.50%
  Val F1 (M): 71.52%
  Saved best model to outputs/resnet34_combined_kd/best_model.pth

Epoch 12/30
  Train Loss: 2.4290
  Train Acc:  82.51%
  CE Loss:    0.9429
  KD Loss:    1.4861
  Val Loss:   1.0222
  Val Acc:    74.00%
  Val Top-5:  95.17%
  Val F1 (M): 72.33%
  Saved best model to outputs/resnet34_combined_kd/best_model.pth

Epoch 13/30
  Train Loss: 2.3616
  Train Acc:  82.98%
  CE Loss:    0.8922
  KD Loss:    1.4693
  Val Loss:   1.0148
  Val Acc:    75.17%
  Val Top-5:  94.17%
  Val F1 (M): 74.11%
  Saved best model to outputs/resnet34_combined_kd/best_model.pth

Epoch 14/30
  Train Loss: 2.2885
  Train Acc:  85.34%
  CE Loss:    0.8319
  KD Loss:    1.4566
  Val Loss:   1.0120
  Val Acc:    75.17%
  Val Top-5:  95.00%
  Val F1 (M): 74.07%

Epoch 15/30
  Train Loss: 2.2336
  Train Acc:  86.66%
  CE Loss:    0.7874
  KD Loss:    1.4461
  Val Loss:   1.0004
  Val Acc:    74.33%
  Val Top-5:  94.50%
  Val F1 (M): 73.45%

Epoch 16/30
  Train Loss: 2.1746
  Train Acc:  87.35%
  CE Loss:    0.7589
  KD Loss:    1.4156
  Val Loss:   0.9545
  Val Acc:    75.67%
  Val Top-5:  94.67%
  Val F1 (M): 74.67%
  Saved best model to outputs/resnet34_combined_kd/best_model.pth

Epoch 17/30
  Train Loss: 2.1208
  Train Acc:  88.08%
  CE Loss:    0.7172
  KD Loss:    1.4036
  Val Loss:   0.9591
  Val Acc:    75.50%
  Val Top-5:  94.00%
  Val F1 (M): 74.73%

Epoch 18/30
  Train Loss: 2.0923
  Train Acc:  88.71%
  CE Loss:    0.7008
  KD Loss:    1.3915
  Val Loss:   0.9512
  Val Acc:    75.33%
  Val Top-5:  94.67%
  Val F1 (M): 74.64%

Epoch 19/30
  Train Loss: 2.0545
  Train Acc:  89.84%
  CE Loss:    0.6739
  KD Loss:    1.3806
  Val Loss:   0.9623
  Val Acc:    75.67%
  Val Top-5:  94.50%
  Val F1 (M): 74.52%

Epoch 20/30
  Train Loss: 2.0388
  Train Acc:  90.20%
  CE Loss:    0.6552
  KD Loss:    1.3835
  Val Loss:   0.9389
  Val Acc:    76.33%
  Val Top-5:  95.00%
  Val F1 (M): 75.19%
  Saved best model to outputs/resnet34_combined_kd/best_model.pth

Epoch 21/30
  Train Loss: 1.9960
  Train Acc:  90.77%
  CE Loss:    0.6326
  KD Loss:    1.3634
  Val Loss:   0.9410
  Val Acc:    74.83%
  Val Top-5:  94.33%
  Val F1 (M): 73.45%

Epoch 22/30
  Train Loss: 1.9699
  Train Acc:  91.26%
  CE Loss:    0.6229
  KD Loss:    1.3471
  Val Loss:   0.9279
  Val Acc:    76.33%
  Val Top-5:  94.83%
  Val F1 (M): 75.33%

Epoch 23/30
  Train Loss: 1.9768
  Train Acc:  91.46%
  CE Loss:    0.6110
  KD Loss:    1.3658
  Val Loss:   0.9291
  Val Acc:    76.00%
  Val Top-5:  94.67%
  Val F1 (M): 75.05%

Epoch 24/30
  Train Loss: 1.9206
  Train Acc:  91.70%
  CE Loss:    0.5843
  KD Loss:    1.3363
  Val Loss:   0.9214
  Val Acc:    76.67%
  Val Top-5:  94.67%
  Val F1 (M): 75.98%
  Saved best model to outputs/resnet34_combined_kd/best_model.pth

Epoch 25/30
  Train Loss: 1.9219
  Train Acc:  91.96%
  CE Loss:    0.5871
  KD Loss:    1.3348
  Val Loss:   0.9238
  Val Acc:    75.67%
  Val Top-5:  94.83%
  Val F1 (M): 74.67%

Epoch 26/30
  Train Loss: 1.9286
  Train Acc:  91.48%
  CE Loss:    0.5911
  KD Loss:    1.3375
  Val Loss:   0.9449
  Val Acc:    74.67%
  Val Top-5:  95.00%
  Val F1 (M): 73.61%

Epoch 27/30
  Train Loss: 1.9146
  Train Acc:  92.24%
  CE Loss:    0.5632
  KD Loss:    1.3514
  Val Loss:   0.9352
  Val Acc:    75.50%
  Val Top-5:  94.50%
  Val F1 (M): 74.70%

Epoch 28/30
  Train Loss: 1.8929
  Train Acc:  92.62%
  CE Loss:    0.5607
  KD Loss:    1.3323
  Val Loss:   0.9344
  Val Acc:    74.33%
  Val Top-5:  94.67%
  Val F1 (M): 73.69%

Epoch 29/30
  Train Loss: 1.9015
  Train Acc:  91.83%
  CE Loss:    0.5714
  KD Loss:    1.3301
  Val Loss:   0.9284
  Val Acc:    75.67%
  Val Top-5:  93.67%
  Val F1 (M): 74.77%

Epoch 30/30
  Train Loss: 1.8890
  Train Acc:  92.15%
  CE Loss:    0.5660
  KD Loss:    1.3230
  Val Loss:   0.9329
  Val Acc:    76.00%
  Val Top-5:  94.17%
  Val F1 (M): 74.96%
  Test Acc:   76.27%
  Test Top-5: 94.34%
  Test F1 (M):76.17%

============================================================
Training completed in 462.29s
Best validation accuracy: 76.67%
============================================================


Results saved to: outputs/resnet34_combined_kd
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: resnet50_scratch
Student Architecture: resnet50
Distillation Type: none
Device: cuda
Seed: 42

Configuration saved to: outputs/resnet50_scratch/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: resnet50
  Total parameters: 23,917,832
  Trainable parameters: 23,917,832

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 5.3287
  Train Acc:  1.08%
  Val Loss:   5.0987
  Val Acc:    2.17%
  Val Top-5:  7.50%
  Val F1 (M): 0.96%
  Saved best model to outputs/resnet50_scratch/best_model.pth

Epoch 2/30
  Train Loss: 5.0483
  Train Acc:  1.90%
  Val Loss:   4.9536
  Val Acc:    2.17%
  Val Top-5:  11.00%
  Val F1 (M): 0.40%

Epoch 3/30
  Train Loss: 4.9136
  Train Acc:  2.51%
  Val Loss:   4.8079
  Val Acc:    4.00%
  Val Top-5:  13.83%
  Val F1 (M): 1.46%
  Saved best model to outputs/resnet50_scratch/best_model.pth

Epoch 4/30
  Train Loss: 4.7823
  Train Acc:  3.63%
  Val Loss:   4.7542
  Val Acc:    6.00%
  Val Top-5:  18.00%
  Val F1 (M): 3.47%
  Saved best model to outputs/resnet50_scratch/best_model.pth

Epoch 5/30
  Train Loss: 4.6693
  Train Acc:  4.24%
  Val Loss:   4.6337
  Val Acc:    4.50%
  Val Top-5:  18.50%
  Val F1 (M): 2.48%

Epoch 6/30
  Train Loss: 4.5776
  Train Acc:  5.38%
  Val Loss:   4.5795
  Val Acc:    6.17%
  Val Top-5:  19.17%
  Val F1 (M): 3.65%
  Saved best model to outputs/resnet50_scratch/best_model.pth

Epoch 7/30
  Train Loss: 4.4312
  Train Acc:  6.29%
  Val Loss:   4.4800
  Val Acc:    6.67%
  Val Top-5:  23.00%
  Val F1 (M): 3.85%
  Saved best model to outputs/resnet50_scratch/best_model.pth

Epoch 8/30
  Train Loss: 4.2710
  Train Acc:  7.46%
  Val Loss:   4.4678
  Val Acc:    9.50%
  Val Top-5:  25.17%
  Val F1 (M): 6.40%
  Saved best model to outputs/resnet50_scratch/best_model.pth

Epoch 9/30
  Train Loss: 4.1494
  Train Acc:  8.82%
  Val Loss:   4.2172
  Val Acc:    9.00%
  Val Top-5:  29.50%
  Val F1 (M): 5.39%

Epoch 10/30
  Train Loss: 3.9945
  Train Acc:  10.51%
  Val Loss:   4.1446
  Val Acc:    8.83%
  Val Top-5:  29.67%
  Val F1 (M): 6.71%

Epoch 11/30
  Train Loss: 3.8472
  Train Acc:  12.78%
  Val Loss:   3.9728
  Val Acc:    13.00%
  Val Top-5:  33.00%
  Val F1 (M): 10.28%
  Saved best model to outputs/resnet50_scratch/best_model.pth

Epoch 12/30
  Train Loss: 3.7365
  Train Acc:  14.01%
  Val Loss:   3.9613
  Val Acc:    11.67%
  Val Top-5:  32.17%
  Val F1 (M): 8.65%

Epoch 13/30
  Train Loss: 3.6039
  Train Acc:  14.99%
  Val Loss:   4.0569
  Val Acc:    10.33%
  Val Top-5:  35.50%
  Val F1 (M): 8.37%

Epoch 14/30
  Train Loss: 3.4470
  Train Acc:  18.19%
  Val Loss:   3.7580
  Val Acc:    14.50%
  Val Top-5:  38.17%
  Val F1 (M): 12.21%
  Saved best model to outputs/resnet50_scratch/best_model.pth

Epoch 15/30
  Train Loss: 3.3365
  Train Acc:  19.55%
  Val Loss:   3.7614
  Val Acc:    14.50%
  Val Top-5:  41.50%
  Val F1 (M): 10.76%

Epoch 16/30
  Train Loss: 3.2253
  Train Acc:  22.04%
  Val Loss:   3.6496
  Val Acc:    16.67%
  Val Top-5:  42.00%
  Val F1 (M): 13.81%
  Saved best model to outputs/resnet50_scratch/best_model.pth

Epoch 17/30
  Train Loss: 3.1086
  Train Acc:  23.12%
  Val Loss:   3.5243
  Val Acc:    17.33%
  Val Top-5:  45.83%
  Val F1 (M): 15.02%
  Saved best model to outputs/resnet50_scratch/best_model.pth

Epoch 18/30
  Train Loss: 3.0151
  Train Acc:  25.74%
  Val Loss:   3.4000
  Val Acc:    18.83%
  Val Top-5:  46.33%
  Val F1 (M): 15.68%
  Saved best model to outputs/resnet50_scratch/best_model.pth

Epoch 19/30
  Train Loss: 2.8944
  Train Acc:  27.55%
  Val Loss:   3.3092
  Val Acc:    20.00%
  Val Top-5:  48.67%
  Val F1 (M): 16.81%
  Saved best model to outputs/resnet50_scratch/best_model.pth

Epoch 20/30
  Train Loss: 2.8185
  Train Acc:  29.54%
  Val Loss:   3.2556
  Val Acc:    20.00%
  Val Top-5:  50.83%
  Val F1 (M): 16.79%

Epoch 21/30
  Train Loss: 2.6994
  Train Acc:  32.91%
  Val Loss:   3.1986
  Val Acc:    21.50%
  Val Top-5:  53.17%
  Val F1 (M): 18.98%
  Saved best model to outputs/resnet50_scratch/best_model.pth

Epoch 22/30
  Train Loss: 2.6413
  Train Acc:  33.26%
  Val Loss:   3.1381
  Val Acc:    24.33%
  Val Top-5:  53.67%
  Val F1 (M): 21.81%
  Saved best model to outputs/resnet50_scratch/best_model.pth

Epoch 23/30
  Train Loss: 2.5745
  Train Acc:  35.70%
  Val Loss:   3.1349
  Val Acc:    24.83%
  Val Top-5:  54.00%
  Val F1 (M): 22.05%
  Saved best model to outputs/resnet50_scratch/best_model.pth

Epoch 24/30
  Train Loss: 2.5079
  Train Acc:  36.35%
  Val Loss:   3.0737
  Val Acc:    25.00%
  Val Top-5:  54.67%
  Val F1 (M): 22.61%
  Saved best model to outputs/resnet50_scratch/best_model.pth

Epoch 25/30
  Train Loss: 2.4601
  Train Acc:  37.82%
  Val Loss:   3.0588
  Val Acc:    24.00%
  Val Top-5:  55.00%
  Val F1 (M): 21.68%

Epoch 26/30
  Train Loss: 2.4180
  Train Acc:  38.34%
  Val Loss:   3.0479
  Val Acc:    24.67%
  Val Top-5:  55.67%
  Val F1 (M): 23.27%

Epoch 27/30
  Train Loss: 2.3796
  Train Acc:  39.77%
  Val Loss:   3.0143
  Val Acc:    24.83%
  Val Top-5:  56.50%
  Val F1 (M): 22.93%

Epoch 28/30
  Train Loss: 2.3452
  Train Acc:  40.89%
  Val Loss:   3.0145
  Val Acc:    25.33%
  Val Top-5:  55.67%
  Val F1 (M): 23.19%
  Saved best model to outputs/resnet50_scratch/best_model.pth

Epoch 29/30
  Train Loss: 2.3578
  Train Acc:  40.92%
  Val Loss:   3.0141
  Val Acc:    25.83%
  Val Top-5:  56.50%
  Val F1 (M): 23.93%
  Saved best model to outputs/resnet50_scratch/best_model.pth

Epoch 30/30
  Train Loss: 2.3437
  Train Acc:  41.07%
  Val Loss:   3.0092
  Val Acc:    25.00%
  Val Top-5:  56.67%
  Val F1 (M): 23.07%
  Test Acc:   25.37%
  Test Top-5: 55.16%
  Test F1 (M):24.30%

============================================================
Training completed in 374.52s
Best validation accuracy: 25.83%
============================================================


Results saved to: outputs/resnet50_scratch
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: resnet50_transfer
Student Architecture: resnet50
Distillation Type: none
Device: cuda
Seed: 42

Configuration saved to: outputs/resnet50_transfer/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: resnet50
  Total parameters: 23,917,832
  Trainable parameters: 23,917,832

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 4.7944
  Train Acc:  8.39%
  Val Loss:   3.0594
  Val Acc:    30.83%
  Val Top-5:  65.17%
  Val F1 (M): 23.71%
  Saved best model to outputs/resnet50_transfer/best_model.pth

Epoch 2/30
  Train Loss: 2.4804
  Train Acc:  43.28%
  Val Loss:   1.7022
  Val Acc:    55.17%
  Val Top-5:  87.17%
  Val F1 (M): 50.40%
  Saved best model to outputs/resnet50_transfer/best_model.pth

Epoch 3/30
  Train Loss: 1.4449
  Train Acc:  64.66%
  Val Loss:   1.3090
  Val Acc:    63.67%
  Val Top-5:  90.50%
  Val F1 (M): 59.89%
  Saved best model to outputs/resnet50_transfer/best_model.pth

Epoch 4/30
  Train Loss: 0.9853
  Train Acc:  74.59%
  Val Loss:   1.1272
  Val Acc:    66.33%
  Val Top-5:  94.00%
  Val F1 (M): 63.76%
  Saved best model to outputs/resnet50_transfer/best_model.pth

Epoch 5/30
  Train Loss: 0.7067
  Train Acc:  81.77%
  Val Loss:   1.0039
  Val Acc:    72.17%
  Val Top-5:  94.50%
  Val F1 (M): 70.69%
  Saved best model to outputs/resnet50_transfer/best_model.pth

Epoch 6/30
  Train Loss: 0.5426
  Train Acc:  85.83%
  Val Loss:   0.9778
  Val Acc:    73.67%
  Val Top-5:  92.83%
  Val F1 (M): 72.18%
  Saved best model to outputs/resnet50_transfer/best_model.pth

Epoch 7/30
  Train Loss: 0.4251
  Train Acc:  88.93%
  Val Loss:   0.9688
  Val Acc:    73.50%
  Val Top-5:  94.17%
  Val F1 (M): 71.91%

Epoch 8/30
  Train Loss: 0.3246
  Train Acc:  92.34%
  Val Loss:   0.9358
  Val Acc:    74.17%
  Val Top-5:  94.50%
  Val F1 (M): 73.18%
  Saved best model to outputs/resnet50_transfer/best_model.pth

Epoch 9/30
  Train Loss: 0.2555
  Train Acc:  93.86%
  Val Loss:   0.9273
  Val Acc:    74.67%
  Val Top-5:  93.50%
  Val F1 (M): 73.58%
  Saved best model to outputs/resnet50_transfer/best_model.pth

Epoch 10/30
  Train Loss: 0.1992
  Train Acc:  95.76%
  Val Loss:   0.8877
  Val Acc:    75.00%
  Val Top-5:  94.67%
  Val F1 (M): 73.64%
  Saved best model to outputs/resnet50_transfer/best_model.pth

Epoch 11/30
  Train Loss: 0.1574
  Train Acc:  96.60%
  Val Loss:   0.9261
  Val Acc:    73.67%
  Val Top-5:  94.50%
  Val F1 (M): 72.79%

Epoch 12/30
  Train Loss: 0.1278
  Train Acc:  97.56%
  Val Loss:   0.9169
  Val Acc:    77.17%
  Val Top-5:  95.33%
  Val F1 (M): 76.00%
  Saved best model to outputs/resnet50_transfer/best_model.pth

Epoch 13/30
  Train Loss: 0.1090
  Train Acc:  97.92%
  Val Loss:   0.9221
  Val Acc:    76.83%
  Val Top-5:  94.17%
  Val F1 (M): 76.13%

Epoch 14/30
  Train Loss: 0.0838
  Train Acc:  98.81%
  Val Loss:   0.9034
  Val Acc:    76.00%
  Val Top-5:  94.33%
  Val F1 (M): 74.76%

Epoch 15/30
  Train Loss: 0.0708
  Train Acc:  99.09%
  Val Loss:   0.9286
  Val Acc:    77.00%
  Val Top-5:  94.17%
  Val F1 (M): 76.18%

Epoch 16/30
  Train Loss: 0.0578
  Train Acc:  99.37%
  Val Loss:   0.9382
  Val Acc:    75.50%
  Val Top-5:  94.33%
  Val F1 (M): 74.60%

Epoch 17/30
  Train Loss: 0.0537
  Train Acc:  99.35%
  Val Loss:   0.9153
  Val Acc:    76.50%
  Val Top-5:  95.00%
  Val F1 (M): 75.67%

Epoch 18/30
  Train Loss: 0.0448
  Train Acc:  99.50%
  Val Loss:   0.9064
  Val Acc:    78.00%
  Val Top-5:  95.00%
  Val F1 (M): 77.34%
  Saved best model to outputs/resnet50_transfer/best_model.pth

Epoch 19/30
  Train Loss: 0.0403
  Train Acc:  99.48%
  Val Loss:   0.9055
  Val Acc:    76.67%
  Val Top-5:  94.83%
  Val F1 (M): 75.72%

Epoch 20/30
  Train Loss: 0.0397
  Train Acc:  99.52%
  Val Loss:   0.9250
  Val Acc:    76.50%
  Val Top-5:  95.00%
  Val F1 (M): 75.55%

Epoch 21/30
  Train Loss: 0.0333
  Train Acc:  99.74%
  Val Loss:   0.8902
  Val Acc:    78.00%
  Val Top-5:  95.00%
  Val F1 (M): 76.85%

Epoch 22/30
  Train Loss: 0.0289
  Train Acc:  99.74%
  Val Loss:   0.9009
  Val Acc:    78.00%
  Val Top-5:  95.00%
  Val F1 (M): 77.11%

Epoch 23/30
  Train Loss: 0.0305
  Train Acc:  99.65%
  Val Loss:   0.9099
  Val Acc:    77.17%
  Val Top-5:  94.50%
  Val F1 (M): 76.30%

Epoch 24/30
  Train Loss: 0.0269
  Train Acc:  99.80%
  Val Loss:   0.9114
  Val Acc:    77.83%
  Val Top-5:  95.33%
  Val F1 (M): 76.76%

Epoch 25/30
  Train Loss: 0.0265
  Train Acc:  99.67%
  Val Loss:   0.8885
  Val Acc:    77.00%
  Val Top-5:  95.17%
  Val F1 (M): 76.03%

Epoch 26/30
  Train Loss: 0.0245
  Train Acc:  99.78%
  Val Loss:   0.8999
  Val Acc:    78.17%
  Val Top-5:  95.33%
  Val F1 (M): 77.48%
  Saved best model to outputs/resnet50_transfer/best_model.pth

Epoch 27/30
  Train Loss: 0.0235
  Train Acc:  99.80%
  Val Loss:   0.9026
  Val Acc:    76.50%
  Val Top-5:  95.33%
  Val F1 (M): 75.79%

Epoch 28/30
  Train Loss: 0.0222
  Train Acc:  99.80%
  Val Loss:   0.9051
  Val Acc:    77.67%
  Val Top-5:  95.17%
  Val F1 (M): 76.83%

Epoch 29/30
  Train Loss: 0.0217
  Train Acc:  99.91%
  Val Loss:   0.8945
  Val Acc:    78.17%
  Val Top-5:  95.00%
  Val F1 (M): 77.43%

Epoch 30/30
  Train Loss: 0.0254
  Train Acc:  99.70%
  Val Loss:   0.9090
  Val Acc:    78.50%
  Val Top-5:  94.50%
  Val F1 (M): 77.47%
  Saved best model to outputs/resnet50_transfer/best_model.pth
  Test Acc:   78.05%
  Test Top-5: 94.82%
  Test F1 (M):77.95%

============================================================
Training completed in 369.47s
Best validation accuracy: 78.50%
============================================================


Results saved to: outputs/resnet50_transfer
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: resnet50_logit_kd
Student Architecture: resnet50
Distillation Type: logit
Device: cuda
Seed: 42

Configuration saved to: outputs/resnet50_logit_kd/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: resnet50
  Total parameters: 23,917,832
  Trainable parameters: 23,917,832

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01

Setting up knowledge distillation...
  Teacher: openai/clip-vit-base-patch32
  Distillation type: logit
  Alpha CE: 1.0
  Alpha KD: 1.0


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 10.1766
  Train Acc:  6.19%
  CE Loss:    4.5884
  KD Loss:    5.5882
  Val Loss:   3.0404
  Val Acc:    24.50%
  Val Top-5:  56.50%
  Val F1 (M): 18.64%
  Saved best model to outputs/resnet50_logit_kd/best_model.pth

Epoch 2/30
  Train Loss: 5.2080
  Train Acc:  36.42%
  CE Loss:    2.7166
  KD Loss:    2.4914
  Val Loss:   1.8239
  Val Acc:    51.00%
  Val Top-5:  86.17%
  Val F1 (M): 47.17%
  Saved best model to outputs/resnet50_logit_kd/best_model.pth

Epoch 3/30
  Train Loss: 3.8347
  Train Acc:  56.01%
  CE Loss:    1.9138
  KD Loss:    1.9209
  Val Loss:   1.4188
  Val Acc:    63.50%
  Val Top-5:  91.83%
  Val F1 (M): 60.63%
  Saved best model to outputs/resnet50_logit_kd/best_model.pth

Epoch 4/30
  Train Loss: 3.2411
  Train Acc:  67.95%
  CE Loss:    1.4941
  KD Loss:    1.7470
  Val Loss:   1.2004
  Val Acc:    68.33%
  Val Top-5:  94.17%
  Val F1 (M): 66.23%
  Saved best model to outputs/resnet50_logit_kd/best_model.pth

Epoch 5/30
  Train Loss: 2.8790
  Train Acc:  73.79%
  CE Loss:    1.2543
  KD Loss:    1.6247
  Val Loss:   1.0934
  Val Acc:    69.33%
  Val Top-5:  95.17%
  Val F1 (M): 67.56%
  Saved best model to outputs/resnet50_logit_kd/best_model.pth

Epoch 6/30
  Train Loss: 2.6447
  Train Acc:  79.02%
  CE Loss:    1.0804
  KD Loss:    1.5644
  Val Loss:   1.0231
  Val Acc:    71.17%
  Val Top-5:  95.50%
  Val F1 (M): 69.15%
  Saved best model to outputs/resnet50_logit_kd/best_model.pth

Epoch 7/30
  Train Loss: 2.4669
  Train Acc:  82.72%
  CE Loss:    0.9540
  KD Loss:    1.5129
  Val Loss:   0.9604
  Val Acc:    74.83%
  Val Top-5:  96.00%
  Val F1 (M): 73.59%
  Saved best model to outputs/resnet50_logit_kd/best_model.pth

Epoch 8/30
  Train Loss: 2.3503
  Train Acc:  85.44%
  CE Loss:    0.8630
  KD Loss:    1.4874
  Val Loss:   0.9306
  Val Acc:    76.17%
  Val Top-5:  95.67%
  Val F1 (M): 74.42%
  Saved best model to outputs/resnet50_logit_kd/best_model.pth

Epoch 9/30
  Train Loss: 2.2117
  Train Acc:  87.82%
  CE Loss:    0.7619
  KD Loss:    1.4498
  Val Loss:   0.8870
  Val Acc:    77.33%
  Val Top-5:  95.83%
  Val F1 (M): 75.99%
  Saved best model to outputs/resnet50_logit_kd/best_model.pth

Epoch 10/30
  Train Loss: 2.1499
  Train Acc:  89.25%
  CE Loss:    0.7100
  KD Loss:    1.4400
  Val Loss:   0.8889
  Val Acc:    77.17%
  Val Top-5:  96.50%
  Val F1 (M): 76.22%

Epoch 11/30
  Train Loss: 2.0587
  Train Acc:  90.76%
  CE Loss:    0.6577
  KD Loss:    1.4010
  Val Loss:   0.8600
  Val Acc:    77.33%
  Val Top-5:  95.83%
  Val F1 (M): 75.60%

Epoch 12/30
  Train Loss: 1.9718
  Train Acc:  92.11%
  CE Loss:    0.6046
  KD Loss:    1.3672
  Val Loss:   0.8550
  Val Acc:    77.83%
  Val Top-5:  96.67%
  Val F1 (M): 76.84%
  Saved best model to outputs/resnet50_logit_kd/best_model.pth

Epoch 13/30
  Train Loss: 1.9195
  Train Acc:  93.58%
  CE Loss:    0.5651
  KD Loss:    1.3544
  Val Loss:   0.8384
  Val Acc:    78.67%
  Val Top-5:  96.00%
  Val F1 (M): 77.62%
  Saved best model to outputs/resnet50_logit_kd/best_model.pth

Epoch 14/30
  Train Loss: 1.8631
  Train Acc:  93.94%
  CE Loss:    0.5321
  KD Loss:    1.3310
  Val Loss:   0.8215
  Val Acc:    79.33%
  Val Top-5:  95.67%
  Val F1 (M): 78.45%
  Saved best model to outputs/resnet50_logit_kd/best_model.pth

Epoch 15/30
  Train Loss: 1.8208
  Train Acc:  95.16%
  CE Loss:    0.4968
  KD Loss:    1.3240
  Val Loss:   0.8430
  Val Acc:    79.17%
  Val Top-5:  95.50%
  Val F1 (M): 78.38%

Epoch 16/30
  Train Loss: 1.7666
  Train Acc:  95.44%
  CE Loss:    0.4712
  KD Loss:    1.2954
  Val Loss:   0.8358
  Val Acc:    77.33%
  Val Top-5:  95.67%
  Val F1 (M): 76.15%

Epoch 17/30
  Train Loss: 1.7290
  Train Acc:  95.78%
  CE Loss:    0.4499
  KD Loss:    1.2791
  Val Loss:   0.8207
  Val Acc:    78.50%
  Val Top-5:  96.00%
  Val F1 (M): 77.86%

Epoch 18/30
  Train Loss: 1.6933
  Train Acc:  96.13%
  CE Loss:    0.4331
  KD Loss:    1.2603
  Val Loss:   0.8291
  Val Acc:    78.50%
  Val Top-5:  96.17%
  Val F1 (M): 77.77%

Epoch 19/30
  Train Loss: 1.6915
  Train Acc:  96.48%
  CE Loss:    0.4250
  KD Loss:    1.2665
  Val Loss:   0.8160
  Val Acc:    79.00%
  Val Top-5:  96.00%
  Val F1 (M): 77.87%

Epoch 20/30
  Train Loss: 1.6483
  Train Acc:  96.63%
  CE Loss:    0.4021
  KD Loss:    1.2462
  Val Loss:   0.8187
  Val Acc:    79.00%
  Val Top-5:  95.33%
  Val F1 (M): 78.28%

Epoch 21/30
  Train Loss: 1.6289
  Train Acc:  97.17%
  CE Loss:    0.3901
  KD Loss:    1.2388
  Val Loss:   0.8164
  Val Acc:    78.83%
  Val Top-5:  96.17%
  Val F1 (M): 78.07%

Epoch 22/30
  Train Loss: 1.6337
  Train Acc:  97.45%
  CE Loss:    0.3837
  KD Loss:    1.2500
  Val Loss:   0.8133
  Val Acc:    78.67%
  Val Top-5:  96.17%
  Val F1 (M): 77.91%

Epoch 23/30
  Train Loss: 1.5904
  Train Acc:  97.23%
  CE Loss:    0.3721
  KD Loss:    1.2183
  Val Loss:   0.8071
  Val Acc:    79.33%
  Val Top-5:  95.83%
  Val F1 (M): 78.58%

Epoch 24/30
  Train Loss: 1.5777
  Train Acc:  97.56%
  CE Loss:    0.3702
  KD Loss:    1.2075
  Val Loss:   0.8135
  Val Acc:    79.33%
  Val Top-5:  95.50%
  Val F1 (M): 78.57%

Epoch 25/30
  Train Loss: 1.5761
  Train Acc:  97.51%
  CE Loss:    0.3634
  KD Loss:    1.2127
  Val Loss:   0.8199
  Val Acc:    78.33%
  Val Top-5:  95.50%
  Val F1 (M): 77.57%

Epoch 26/30
  Train Loss: 1.5695
  Train Acc:  97.51%
  CE Loss:    0.3548
  KD Loss:    1.2147
  Val Loss:   0.8154
  Val Acc:    78.83%
  Val Top-5:  95.83%
  Val F1 (M): 78.00%

Epoch 27/30
  Train Loss: 1.5503
  Train Acc:  97.84%
  CE Loss:    0.3513
  KD Loss:    1.1990
  Val Loss:   0.8167
  Val Acc:    77.83%
  Val Top-5:  95.83%
  Val F1 (M): 77.17%

Epoch 28/30
  Train Loss: 1.5477
  Train Acc:  97.45%
  CE Loss:    0.3513
  KD Loss:    1.1964
  Val Loss:   0.8080
  Val Acc:    79.17%
  Val Top-5:  96.17%
  Val F1 (M): 78.17%

Epoch 29/30
  Train Loss: 1.5353
  Train Acc:  97.73%
  CE Loss:    0.3392
  KD Loss:    1.1960
  Val Loss:   0.8072
  Val Acc:    78.33%
  Val Top-5:  96.50%
  Val F1 (M): 77.60%

Epoch 30/30
  Train Loss: 1.5418
  Train Acc:  97.95%
  CE Loss:    0.3404
  KD Loss:    1.2014
  Val Loss:   0.8039
  Val Acc:    79.50%
  Val Top-5:  96.33%
  Val F1 (M): 78.91%
  Saved best model to outputs/resnet50_logit_kd/best_model.pth
  Test Acc:   79.74%
  Test Top-5: 95.79%
  Test F1 (M):79.77%

============================================================
Training completed in 467.54s
Best validation accuracy: 79.50%
============================================================


Results saved to: outputs/resnet50_logit_kd
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: resnet50_attention_kd
Student Architecture: resnet50
Distillation Type: attention
Device: cuda
Seed: 42

Configuration saved to: outputs/resnet50_attention_kd/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: resnet50
  Total parameters: 23,917,832
  Trainable parameters: 23,917,832

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01

Setting up knowledge distillation...
  Teacher: openai/clip-vit-base-patch32
  Distillation type: attention
  Alpha CE: 1.0
  Alpha KD: 0.0
  Alpha Attention: 0.5
  Attention loss: mse


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 4.8013
  Train Acc:  10.75%
  CE Loss:    4.8013
  KD Loss:    7.3011
  Val Loss:   3.0881
  Val Acc:    33.50%
  Val Top-5:  68.00%
  Val F1 (M): 26.84%
  Saved best model to outputs/resnet50_attention_kd/best_model.pth

Epoch 2/30
  Train Loss: 2.4781
  Train Acc:  49.40%
  CE Loss:    2.4781
  KD Loss:    4.5785
  Val Loss:   1.6568
  Val Acc:    57.17%
  Val Top-5:  89.33%
  Val F1 (M): 53.71%
  Saved best model to outputs/resnet50_attention_kd/best_model.pth

Epoch 3/30
  Train Loss: 1.4568
  Train Acc:  71.06%
  CE Loss:    1.4568
  KD Loss:    4.1492
  Val Loss:   1.2207
  Val Acc:    67.33%
  Val Top-5:  94.17%
  Val F1 (M): 64.63%
  Saved best model to outputs/resnet50_attention_kd/best_model.pth

Epoch 4/30
  Train Loss: 0.9754
  Train Acc:  81.08%
  CE Loss:    0.9754
  KD Loss:    4.3599
  Val Loss:   1.0634
  Val Acc:    70.00%
  Val Top-5:  94.50%
  Val F1 (M): 68.09%
  Saved best model to outputs/resnet50_attention_kd/best_model.pth

Epoch 5/30
  Train Loss: 0.7235
  Train Acc:  86.57%
  CE Loss:    0.7235
  KD Loss:    4.5951
  Val Loss:   1.0065
  Val Acc:    70.83%
  Val Top-5:  94.33%
  Val F1 (M): 69.36%
  Saved best model to outputs/resnet50_attention_kd/best_model.pth

Epoch 6/30
  Train Loss: 0.5268
  Train Acc:  91.69%
  CE Loss:    0.5268
  KD Loss:    4.8904
  Val Loss:   0.9595
  Val Acc:    72.17%
  Val Top-5:  94.33%
  Val F1 (M): 70.55%
  Saved best model to outputs/resnet50_attention_kd/best_model.pth

Epoch 7/30
  Train Loss: 0.4147
  Train Acc:  94.18%
  CE Loss:    0.4147
  KD Loss:    5.2502
  Val Loss:   0.8985
  Val Acc:    75.33%
  Val Top-5:  95.00%
  Val F1 (M): 74.03%
  Saved best model to outputs/resnet50_attention_kd/best_model.pth

Epoch 8/30
  Train Loss: 0.3280
  Train Acc:  95.80%
  CE Loss:    0.3280
  KD Loss:    5.5163
  Val Loss:   0.8902
  Val Acc:    74.83%
  Val Top-5:  94.17%
  Val F1 (M): 73.37%

Epoch 9/30
  Train Loss: 0.2491
  Train Acc:  97.62%
  CE Loss:    0.2491
  KD Loss:    5.7013
  Val Loss:   0.9215
  Val Acc:    74.33%
  Val Top-5:  94.67%
  Val F1 (M): 73.04%

Epoch 10/30
  Train Loss: 0.2021
  Train Acc:  97.92%
  CE Loss:    0.2021
  KD Loss:    5.9761
  Val Loss:   0.9293
  Val Acc:    74.67%
  Val Top-5:  95.00%
  Val F1 (M): 73.42%

Epoch 11/30
  Train Loss: 0.1653
  Train Acc:  98.79%
  CE Loss:    0.1653
  KD Loss:    6.1670
  Val Loss:   0.9279
  Val Acc:    74.50%
  Val Top-5:  94.50%
  Val F1 (M): 73.31%

Epoch 12/30
  Train Loss: 0.1306
  Train Acc:  99.26%
  CE Loss:    0.1306
  KD Loss:    6.3981
  Val Loss:   0.9253
  Val Acc:    74.17%
  Val Top-5:  93.83%
  Val F1 (M): 73.08%

Epoch 13/30
  Train Loss: 0.0999
  Train Acc:  99.68%
  CE Loss:    0.0999
  KD Loss:    6.6434
  Val Loss:   0.9513
  Val Acc:    76.00%
  Val Top-5:  94.67%
  Val F1 (M): 74.81%
  Saved best model to outputs/resnet50_attention_kd/best_model.pth

Epoch 14/30
  Train Loss: 0.0883
  Train Acc:  99.65%
  CE Loss:    0.0883
  KD Loss:    6.8278
  Val Loss:   0.9426
  Val Acc:    75.33%
  Val Top-5:  94.50%
  Val F1 (M): 74.29%

Epoch 15/30
  Train Loss: 0.0725
  Train Acc:  99.83%
  CE Loss:    0.0725
  KD Loss:    6.9988
  Val Loss:   0.9574
  Val Acc:    75.33%
  Val Top-5:  95.17%
  Val F1 (M): 74.78%

Epoch 16/30
  Train Loss: 0.0635
  Train Acc:  99.74%
  CE Loss:    0.0635
  KD Loss:    7.1678
  Val Loss:   0.9619
  Val Acc:    75.50%
  Val Top-5:  94.33%
  Val F1 (M): 74.80%

Epoch 17/30
  Train Loss: 0.0544
  Train Acc:  99.80%
  CE Loss:    0.0544
  KD Loss:    7.2411
  Val Loss:   0.9478
  Val Acc:    75.00%
  Val Top-5:  94.67%
  Val F1 (M): 74.12%

Epoch 18/30
  Train Loss: 0.0479
  Train Acc:  99.91%
  CE Loss:    0.0479
  KD Loss:    7.3659
  Val Loss:   0.9649
  Val Acc:    76.33%
  Val Top-5:  94.67%
  Val F1 (M): 75.53%
  Saved best model to outputs/resnet50_attention_kd/best_model.pth

Epoch 19/30
  Train Loss: 0.0443
  Train Acc:  99.91%
  CE Loss:    0.0443
  KD Loss:    7.4502
  Val Loss:   0.9429
  Val Acc:    76.83%
  Val Top-5:  94.33%
  Val F1 (M): 76.02%
  Saved best model to outputs/resnet50_attention_kd/best_model.pth

Epoch 20/30
  Train Loss: 0.0325
  Train Acc:  99.96%
  CE Loss:    0.0325
  KD Loss:    7.5578
  Val Loss:   0.9442
  Val Acc:    77.00%
  Val Top-5:  94.33%
  Val F1 (M): 76.13%
  Saved best model to outputs/resnet50_attention_kd/best_model.pth

Epoch 21/30
  Train Loss: 0.0336
  Train Acc:  99.91%
  CE Loss:    0.0336
  KD Loss:    7.6901
  Val Loss:   0.9450
  Val Acc:    75.33%
  Val Top-5:  94.83%
  Val F1 (M): 74.36%

Epoch 22/30
  Train Loss: 0.0318
  Train Acc:  99.94%
  CE Loss:    0.0318
  KD Loss:    7.7291
  Val Loss:   0.9350
  Val Acc:    77.17%
  Val Top-5:  94.50%
  Val F1 (M): 76.48%
  Saved best model to outputs/resnet50_attention_kd/best_model.pth

Epoch 23/30
  Train Loss: 0.0282
  Train Acc:  99.98%
  CE Loss:    0.0282
  KD Loss:    7.8083
  Val Loss:   0.9523
  Val Acc:    77.83%
  Val Top-5:  94.17%
  Val F1 (M): 77.07%
  Saved best model to outputs/resnet50_attention_kd/best_model.pth

Epoch 24/30
  Train Loss: 0.0284
  Train Acc:  99.91%
  CE Loss:    0.0284
  KD Loss:    7.8770
  Val Loss:   0.9480
  Val Acc:    75.50%
  Val Top-5:  94.50%
  Val F1 (M): 74.66%

Epoch 25/30
  Train Loss: 0.0253
  Train Acc:  99.91%
  CE Loss:    0.0253
  KD Loss:    7.9525
  Val Loss:   0.9580
  Val Acc:    77.00%
  Val Top-5:  94.50%
  Val F1 (M): 76.27%

Epoch 26/30
  Train Loss: 0.0225
  Train Acc:  99.94%
  CE Loss:    0.0225
  KD Loss:    7.9581
  Val Loss:   0.9616
  Val Acc:    76.83%
  Val Top-5:  94.50%
  Val F1 (M): 76.21%

Epoch 27/30
  Train Loss: 0.0228
  Train Acc:  99.85%
  CE Loss:    0.0228
  KD Loss:    7.9786
  Val Loss:   0.9442
  Val Acc:    76.33%
  Val Top-5:  95.33%
  Val F1 (M): 75.68%

Epoch 28/30
  Train Loss: 0.0220
  Train Acc:  99.89%
  CE Loss:    0.0220
  KD Loss:    7.9884
  Val Loss:   0.9505
  Val Acc:    77.33%
  Val Top-5:  94.50%
  Val F1 (M): 76.69%

Epoch 29/30
  Train Loss: 0.0211
  Train Acc:  99.89%
  CE Loss:    0.0211
  KD Loss:    8.0144
  Val Loss:   0.9287
  Val Acc:    76.50%
  Val Top-5:  95.17%
  Val F1 (M): 75.88%

Epoch 30/30
  Train Loss: 0.0199
  Train Acc:  99.89%
  CE Loss:    0.0199
  KD Loss:    8.0073
  Val Loss:   0.9344
  Val Acc:    76.00%
  Val Top-5:  95.17%
  Val F1 (M): 75.34%
  Test Acc:   77.60%
  Test Top-5: 94.68%
  Test F1 (M):77.68%

============================================================
Training completed in 644.57s
Best validation accuracy: 77.83%
============================================================


Results saved to: outputs/resnet50_attention_kd
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: resnet50_combined_kd
Student Architecture: resnet50
Distillation Type: combined
Device: cuda
Seed: 42

Configuration saved to: outputs/resnet50_combined_kd/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: resnet50
  Total parameters: 23,917,832
  Trainable parameters: 23,917,832

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01

Setting up knowledge distillation...
  Teacher: openai/clip-vit-base-patch32
  Distillation type: combined
  Alpha CE: 1.0
  Alpha KD: 1.0
  Alpha Attention: 0.1
  Attention loss: mse


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 10.1766
  Train Acc:  6.19%
  CE Loss:    4.5884
  KD Loss:    5.5882
  Val Loss:   3.0597
  Val Acc:    24.17%
  Val Top-5:  56.17%
  Val F1 (M): 18.22%
  Saved best model to outputs/resnet50_combined_kd/best_model.pth

Epoch 2/30
  Train Loss: 5.2080
  Train Acc:  36.42%
  CE Loss:    2.7166
  KD Loss:    2.4914
  Val Loss:   1.8189
  Val Acc:    51.00%
  Val Top-5:  86.33%
  Val F1 (M): 47.09%
  Saved best model to outputs/resnet50_combined_kd/best_model.pth

Epoch 3/30
  Train Loss: 3.8347
  Train Acc:  56.01%
  CE Loss:    1.9138
  KD Loss:    1.9209
  Val Loss:   1.4180
  Val Acc:    63.33%
  Val Top-5:  92.50%
  Val F1 (M): 60.41%
  Saved best model to outputs/resnet50_combined_kd/best_model.pth

Epoch 4/30
  Train Loss: 3.2411
  Train Acc:  67.95%
  CE Loss:    1.4941
  KD Loss:    1.7470
  Val Loss:   1.2062
  Val Acc:    68.33%
  Val Top-5:  94.00%
  Val F1 (M): 66.28%
  Saved best model to outputs/resnet50_combined_kd/best_model.pth

Epoch 5/30
  Train Loss: 2.8790
  Train Acc:  73.79%
  CE Loss:    1.2543
  KD Loss:    1.6247
  Val Loss:   1.0962
  Val Acc:    69.17%
  Val Top-5:  95.33%
  Val F1 (M): 67.60%
  Saved best model to outputs/resnet50_combined_kd/best_model.pth

Epoch 6/30
  Train Loss: 2.6447
  Train Acc:  79.02%
  CE Loss:    1.0804
  KD Loss:    1.5644
  Val Loss:   1.0276
  Val Acc:    71.00%
  Val Top-5:  95.33%
  Val F1 (M): 68.90%
  Saved best model to outputs/resnet50_combined_kd/best_model.pth

Epoch 7/30
  Train Loss: 2.4669
  Train Acc:  82.72%
  CE Loss:    0.9540
  KD Loss:    1.5129
  Val Loss:   0.9610
  Val Acc:    74.83%
  Val Top-5:  96.00%
  Val F1 (M): 73.42%
  Saved best model to outputs/resnet50_combined_kd/best_model.pth

Epoch 8/30
  Train Loss: 2.3503
  Train Acc:  85.44%
  CE Loss:    0.8630
  KD Loss:    1.4874
  Val Loss:   0.9379
  Val Acc:    75.67%
  Val Top-5:  95.33%
  Val F1 (M): 73.55%
  Saved best model to outputs/resnet50_combined_kd/best_model.pth

Epoch 9/30
  Train Loss: 2.2117
  Train Acc:  87.82%
  CE Loss:    0.7619
  KD Loss:    1.4498
  Val Loss:   0.8880
  Val Acc:    77.83%
  Val Top-5:  95.83%
  Val F1 (M): 76.44%
  Saved best model to outputs/resnet50_combined_kd/best_model.pth

Epoch 10/30
  Train Loss: 2.1499
  Train Acc:  89.25%
  CE Loss:    0.7100
  KD Loss:    1.4400
  Val Loss:   0.8909
  Val Acc:    76.83%
  Val Top-5:  96.50%
  Val F1 (M): 75.79%

Epoch 11/30
  Train Loss: 2.0587
  Train Acc:  90.76%
  CE Loss:    0.6577
  KD Loss:    1.4010
  Val Loss:   0.8632
  Val Acc:    77.33%
  Val Top-5:  95.83%
  Val F1 (M): 75.65%

Epoch 12/30
  Train Loss: 1.9718
  Train Acc:  92.11%
  CE Loss:    0.6046
  KD Loss:    1.3672
  Val Loss:   0.8584
  Val Acc:    77.33%
  Val Top-5:  96.50%
  Val F1 (M): 76.34%

Epoch 13/30
  Train Loss: 1.9195
  Train Acc:  93.58%
  CE Loss:    0.5651
  KD Loss:    1.3544
  Val Loss:   0.8420
  Val Acc:    78.50%
  Val Top-5:  96.33%
  Val F1 (M): 77.45%
  Saved best model to outputs/resnet50_combined_kd/best_model.pth

Epoch 14/30
  Train Loss: 1.8631
  Train Acc:  93.94%
  CE Loss:    0.5321
  KD Loss:    1.3310
  Val Loss:   0.8228
  Val Acc:    79.50%
  Val Top-5:  95.33%
  Val F1 (M): 78.43%
  Saved best model to outputs/resnet50_combined_kd/best_model.pth

Epoch 15/30
  Train Loss: 1.8208
  Train Acc:  95.16%
  CE Loss:    0.4968
  KD Loss:    1.3240
  Val Loss:   0.8506
  Val Acc:    79.00%
  Val Top-5:  95.83%
  Val F1 (M): 78.22%

Epoch 16/30
  Train Loss: 1.7666
  Train Acc:  95.44%
  CE Loss:    0.4712
  KD Loss:    1.2954
  Val Loss:   0.8408
  Val Acc:    77.50%
  Val Top-5:  95.67%
  Val F1 (M): 76.43%

Epoch 17/30
  Train Loss: 1.7290
  Train Acc:  95.78%
  CE Loss:    0.4499
  KD Loss:    1.2791
  Val Loss:   0.8280
  Val Acc:    78.50%
  Val Top-5:  95.67%
  Val F1 (M): 77.76%

Epoch 18/30
  Train Loss: 1.6933
  Train Acc:  96.13%
  CE Loss:    0.4331
  KD Loss:    1.2603
  Val Loss:   0.8355
  Val Acc:    78.17%
  Val Top-5:  96.00%
  Val F1 (M): 77.58%

Epoch 19/30
  Train Loss: 1.6915
  Train Acc:  96.48%
  CE Loss:    0.4250
  KD Loss:    1.2665
  Val Loss:   0.8192
  Val Acc:    79.33%
  Val Top-5:  96.00%
  Val F1 (M): 78.16%

Epoch 20/30
  Train Loss: 1.6483
  Train Acc:  96.63%
  CE Loss:    0.4021
  KD Loss:    1.2462
  Val Loss:   0.8241
  Val Acc:    79.17%
  Val Top-5:  95.33%
  Val F1 (M): 78.47%

Epoch 21/30
  Train Loss: 1.6289
  Train Acc:  97.17%
  CE Loss:    0.3901
  KD Loss:    1.2388
  Val Loss:   0.8178
  Val Acc:    78.83%
  Val Top-5:  96.33%
  Val F1 (M): 78.02%

Epoch 22/30
  Train Loss: 1.6337
  Train Acc:  97.45%
  CE Loss:    0.3837
  KD Loss:    1.2500
  Val Loss:   0.8156
  Val Acc:    78.50%
  Val Top-5:  96.17%
  Val F1 (M): 77.78%

Epoch 23/30
  Train Loss: 1.5904
  Train Acc:  97.23%
  CE Loss:    0.3721
  KD Loss:    1.2183
  Val Loss:   0.8083
  Val Acc:    79.67%
  Val Top-5:  95.83%
  Val F1 (M): 78.96%
  Saved best model to outputs/resnet50_combined_kd/best_model.pth

Epoch 24/30
  Train Loss: 1.5777
  Train Acc:  97.56%
  CE Loss:    0.3702
  KD Loss:    1.2075
  Val Loss:   0.8211
  Val Acc:    79.17%
  Val Top-5:  96.17%
  Val F1 (M): 78.35%

Epoch 25/30
  Train Loss: 1.5761
  Train Acc:  97.51%
  CE Loss:    0.3634
  KD Loss:    1.2127
  Val Loss:   0.8262
  Val Acc:    78.00%
  Val Top-5:  95.50%
  Val F1 (M): 77.03%

Epoch 26/30
  Train Loss: 1.5695
  Train Acc:  97.51%
  CE Loss:    0.3548
  KD Loss:    1.2147
  Val Loss:   0.8204
  Val Acc:    78.17%
  Val Top-5:  95.67%
  Val F1 (M): 77.09%

Epoch 27/30
  Train Loss: 1.5503
  Train Acc:  97.84%
  CE Loss:    0.3513
  KD Loss:    1.1990
  Val Loss:   0.8218
  Val Acc:    77.50%
  Val Top-5:  95.83%
  Val F1 (M): 76.85%

Epoch 28/30
  Train Loss: 1.5477
  Train Acc:  97.45%
  CE Loss:    0.3513
  KD Loss:    1.1964
  Val Loss:   0.8095
  Val Acc:    79.67%
  Val Top-5:  96.17%
  Val F1 (M): 78.72%

Epoch 29/30
  Train Loss: 1.5353
  Train Acc:  97.73%
  CE Loss:    0.3392
  KD Loss:    1.1960
  Val Loss:   0.8069
  Val Acc:    78.00%
  Val Top-5:  96.33%
  Val F1 (M): 77.35%

Epoch 30/30
  Train Loss: 1.5418
  Train Acc:  97.95%
  CE Loss:    0.3404
  KD Loss:    1.2014
  Val Loss:   0.8087
  Val Acc:    79.17%
  Val Top-5:  96.17%
  Val F1 (M): 78.58%
  Test Acc:   79.65%
  Test Top-5: 95.84%
  Test F1 (M):79.68%

============================================================
Training completed in 645.81s
Best validation accuracy: 79.67%
============================================================


Results saved to: outputs/resnet50_combined_kd
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: vgg16_scratch
Student Architecture: vgg16
Distillation Type: none
Device: cuda
Seed: 42

Configuration saved to: outputs/vgg16_scratch/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: vgg16
  Total parameters: 135,088,392
  Trainable parameters: 135,088,392

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 5.9396
  Train Acc:  0.50%
  Val Loss:   5.2677
  Val Acc:    1.00%
  Val Top-5:  4.00%
  Val F1 (M): 0.32%
  Saved best model to outputs/vgg16_scratch/best_model.pth

Epoch 2/30
  Train Loss: 5.2272
  Train Acc:  0.74%
  Val Loss:   5.0861
  Val Acc:    1.00%
  Val Top-5:  5.00%
  Val F1 (M): 0.07%

Epoch 3/30
  Train Loss: 5.0865
  Train Acc:  1.08%
  Val Loss:   4.9793
  Val Acc:    1.33%
  Val Top-5:  6.17%
  Val F1 (M): 0.23%
  Saved best model to outputs/vgg16_scratch/best_model.pth

Epoch 4/30
  Train Loss: 4.9896
  Train Acc:  1.47%
  Val Loss:   4.9235
  Val Acc:    1.50%
  Val Top-5:  7.67%
  Val F1 (M): 0.45%
  Saved best model to outputs/vgg16_scratch/best_model.pth

Epoch 5/30
  Train Loss: 4.8928
  Train Acc:  1.77%
  Val Loss:   4.8201
  Val Acc:    3.00%
  Val Top-5:  10.17%
  Val F1 (M): 0.70%
  Saved best model to outputs/vgg16_scratch/best_model.pth

Epoch 6/30
  Train Loss: 4.8211
  Train Acc:  2.55%
  Val Loss:   4.7470
  Val Acc:    2.17%
  Val Top-5:  10.83%
  Val F1 (M): 0.71%

Epoch 7/30
  Train Loss: 4.7366
  Train Acc:  2.72%
  Val Loss:   4.6885
  Val Acc:    2.83%
  Val Top-5:  14.67%
  Val F1 (M): 1.55%

Epoch 8/30
  Train Loss: 4.6393
  Train Acc:  3.46%
  Val Loss:   4.6285
  Val Acc:    4.00%
  Val Top-5:  17.67%
  Val F1 (M): 2.37%
  Saved best model to outputs/vgg16_scratch/best_model.pth

Epoch 9/30
  Train Loss: 4.5301
  Train Acc:  3.87%
  Val Loss:   4.5870
  Val Acc:    5.67%
  Val Top-5:  19.67%
  Val F1 (M): 3.17%
  Saved best model to outputs/vgg16_scratch/best_model.pth

Epoch 10/30
  Train Loss: 4.4135
  Train Acc:  4.59%
  Val Loss:   4.5395
  Val Acc:    4.00%
  Val Top-5:  18.17%
  Val F1 (M): 2.75%

Epoch 11/30
  Train Loss: 4.3092
  Train Acc:  6.45%
  Val Loss:   4.6955
  Val Acc:    5.00%
  Val Top-5:  17.83%
  Val F1 (M): 3.35%

Epoch 12/30
  Train Loss: 4.1918
  Train Acc:  7.27%
  Val Loss:   4.4879
  Val Acc:    7.67%
  Val Top-5:  23.17%
  Val F1 (M): 5.28%
  Saved best model to outputs/vgg16_scratch/best_model.pth

Epoch 13/30
  Train Loss: 4.0903
  Train Acc:  8.00%
  Val Loss:   4.5353
  Val Acc:    7.83%
  Val Top-5:  24.00%
  Val F1 (M): 5.42%
  Saved best model to outputs/vgg16_scratch/best_model.pth

Epoch 14/30
  Train Loss: 3.9493
  Train Acc:  9.41%
  Val Loss:   4.3883
  Val Acc:    9.17%
  Val Top-5:  25.50%
  Val F1 (M): 6.24%
  Saved best model to outputs/vgg16_scratch/best_model.pth

Epoch 15/30
  Train Loss: 3.8518
  Train Acc:  10.79%
  Val Loss:   4.3407
  Val Acc:    7.83%
  Val Top-5:  27.17%
  Val F1 (M): 5.53%

Epoch 16/30
  Train Loss: 3.6954
  Train Acc:  13.34%
  Val Loss:   4.3877
  Val Acc:    10.00%
  Val Top-5:  24.67%
  Val F1 (M): 7.58%
  Saved best model to outputs/vgg16_scratch/best_model.pth

Epoch 17/30
  Train Loss: 3.5777
  Train Acc:  14.66%
  Val Loss:   4.2944
  Val Acc:    8.83%
  Val Top-5:  26.33%
  Val F1 (M): 6.86%

Epoch 18/30
  Train Loss: 3.4238
  Train Acc:  17.06%
  Val Loss:   4.3839
  Val Acc:    8.50%
  Val Top-5:  26.17%
  Val F1 (M): 7.49%

Epoch 19/30
  Train Loss: 3.2750
  Train Acc:  19.66%
  Val Loss:   4.4028
  Val Acc:    11.00%
  Val Top-5:  27.00%
  Val F1 (M): 8.84%
  Saved best model to outputs/vgg16_scratch/best_model.pth

Epoch 20/30
  Train Loss: 3.1642
  Train Acc:  22.43%
  Val Loss:   4.5202
  Val Acc:    10.33%
  Val Top-5:  30.17%
  Val F1 (M): 8.70%

Epoch 21/30
  Train Loss: 2.9734
  Train Acc:  24.93%
  Val Loss:   4.5059
  Val Acc:    11.50%
  Val Top-5:  29.67%
  Val F1 (M): 9.36%
  Saved best model to outputs/vgg16_scratch/best_model.pth

Epoch 22/30
  Train Loss: 2.8232
  Train Acc:  28.26%
  Val Loss:   4.6148
  Val Acc:    10.83%
  Val Top-5:  30.17%
  Val F1 (M): 8.93%

Epoch 23/30
  Train Loss: 2.7256
  Train Acc:  29.85%
  Val Loss:   4.6144
  Val Acc:    12.83%
  Val Top-5:  30.83%
  Val F1 (M): 10.91%
  Saved best model to outputs/vgg16_scratch/best_model.pth

Epoch 24/30
  Train Loss: 2.5995
  Train Acc:  32.92%
  Val Loss:   4.5155
  Val Acc:    12.33%
  Val Top-5:  33.00%
  Val F1 (M): 10.92%

Epoch 25/30
  Train Loss: 2.5018
  Train Acc:  34.88%
  Val Loss:   4.5717
  Val Acc:    11.83%
  Val Top-5:  33.17%
  Val F1 (M): 10.11%

Epoch 26/30
  Train Loss: 2.4401
  Train Acc:  36.98%
  Val Loss:   4.6005
  Val Acc:    11.33%
  Val Top-5:  33.00%
  Val F1 (M): 9.89%

Epoch 27/30
  Train Loss: 2.3750
  Train Acc:  38.73%
  Val Loss:   4.5801
  Val Acc:    12.00%
  Val Top-5:  33.67%
  Val F1 (M): 10.72%

Epoch 28/30
  Train Loss: 2.3270
  Train Acc:  39.62%
  Val Loss:   4.6568
  Val Acc:    12.00%
  Val Top-5:  33.83%
  Val F1 (M): 10.56%

Epoch 29/30
  Train Loss: 2.2997
  Train Acc:  40.51%
  Val Loss:   4.6406
  Val Acc:    11.67%
  Val Top-5:  33.50%
  Val F1 (M): 9.86%

Epoch 30/30
  Train Loss: 2.3055
  Train Acc:  39.84%
  Val Loss:   4.6045
  Val Acc:    12.17%
  Val Top-5:  33.67%
  Val F1 (M): 10.39%
  Test Acc:   12.41%
  Test Top-5: 33.03%
  Test F1 (M):11.78%

============================================================
Training completed in 770.12s
Best validation accuracy: 12.83%
============================================================


Results saved to: outputs/vgg16_scratch
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: vgg16_transfer
Student Architecture: vgg16
Distillation Type: none
Device: cuda
Seed: 42

Configuration saved to: outputs/vgg16_transfer/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: vgg16
  Total parameters: 135,088,392
  Trainable parameters: 135,088,392

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 4.1709
  Train Acc:  10.06%
  Val Loss:   3.0402
  Val Acc:    24.17%
  Val Top-5:  57.50%
  Val F1 (M): 18.94%
  Saved best model to outputs/vgg16_transfer/best_model.pth

Epoch 2/30
  Train Loss: 2.6384
  Train Acc:  29.52%
  Val Loss:   2.5516
  Val Acc:    29.33%
  Val Top-5:  71.50%
  Val F1 (M): 25.25%
  Saved best model to outputs/vgg16_transfer/best_model.pth

Epoch 3/30
  Train Loss: 1.9598
  Train Acc:  43.69%
  Val Loss:   2.3382
  Val Acc:    39.33%
  Val Top-5:  73.50%
  Val F1 (M): 35.59%
  Saved best model to outputs/vgg16_transfer/best_model.pth

Epoch 4/30
  Train Loss: 1.4688
  Train Acc:  56.21%
  Val Loss:   2.4925
  Val Acc:    37.67%
  Val Top-5:  75.67%
  Val F1 (M): 33.16%

Epoch 5/30
  Train Loss: 1.1546
  Train Acc:  64.60%
  Val Loss:   2.0778
  Val Acc:    47.17%
  Val Top-5:  81.33%
  Val F1 (M): 43.53%
  Saved best model to outputs/vgg16_transfer/best_model.pth

Epoch 6/30
  Train Loss: 0.9174
  Train Acc:  71.95%
  Val Loss:   2.2890
  Val Acc:    47.33%
  Val Top-5:  80.50%
  Val F1 (M): 44.69%
  Saved best model to outputs/vgg16_transfer/best_model.pth

Epoch 7/30
  Train Loss: 0.7325
  Train Acc:  77.08%
  Val Loss:   2.0598
  Val Acc:    49.00%
  Val Top-5:  82.67%
  Val F1 (M): 47.02%
  Saved best model to outputs/vgg16_transfer/best_model.pth

Epoch 8/30
  Train Loss: 0.6049
  Train Acc:  80.62%
  Val Loss:   2.2631
  Val Acc:    51.33%
  Val Top-5:  82.50%
  Val F1 (M): 49.21%
  Saved best model to outputs/vgg16_transfer/best_model.pth

Epoch 9/30
  Train Loss: 0.4554
  Train Acc:  86.07%
  Val Loss:   2.0439
  Val Acc:    53.00%
  Val Top-5:  85.50%
  Val F1 (M): 50.36%
  Saved best model to outputs/vgg16_transfer/best_model.pth

Epoch 10/30
  Train Loss: 0.3741
  Train Acc:  88.63%
  Val Loss:   2.0244
  Val Acc:    53.67%
  Val Top-5:  85.67%
  Val F1 (M): 50.32%
  Saved best model to outputs/vgg16_transfer/best_model.pth

Epoch 11/30
  Train Loss: 0.3102
  Train Acc:  89.99%
  Val Loss:   2.2691
  Val Acc:    51.00%
  Val Top-5:  83.67%
  Val F1 (M): 49.99%

Epoch 12/30
  Train Loss: 0.2400
  Train Acc:  92.28%
  Val Loss:   2.0572
  Val Acc:    57.33%
  Val Top-5:  86.50%
  Val F1 (M): 55.51%
  Saved best model to outputs/vgg16_transfer/best_model.pth

Epoch 13/30
  Train Loss: 0.1945
  Train Acc:  94.16%
  Val Loss:   2.2286
  Val Acc:    54.17%
  Val Top-5:  86.83%
  Val F1 (M): 52.95%

Epoch 14/30
  Train Loss: 0.1505
  Train Acc:  95.42%
  Val Loss:   2.1936
  Val Acc:    56.67%
  Val Top-5:  84.33%
  Val F1 (M): 55.19%

Epoch 15/30
  Train Loss: 0.1136
  Train Acc:  96.24%
  Val Loss:   2.0899
  Val Acc:    57.83%
  Val Top-5:  87.50%
  Val F1 (M): 56.76%
  Saved best model to outputs/vgg16_transfer/best_model.pth

Epoch 16/30
  Train Loss: 0.0948
  Train Acc:  97.30%
  Val Loss:   2.0730
  Val Acc:    59.33%
  Val Top-5:  88.17%
  Val F1 (M): 57.43%
  Saved best model to outputs/vgg16_transfer/best_model.pth

Epoch 17/30
  Train Loss: 0.0887
  Train Acc:  97.28%
  Val Loss:   2.1736
  Val Acc:    58.00%
  Val Top-5:  86.67%
  Val F1 (M): 56.91%

Epoch 18/30
  Train Loss: 0.0614
  Train Acc:  98.10%
  Val Loss:   2.1420
  Val Acc:    59.83%
  Val Top-5:  89.00%
  Val F1 (M): 59.21%
  Saved best model to outputs/vgg16_transfer/best_model.pth

Epoch 19/30
  Train Loss: 0.0378
  Train Acc:  98.85%
  Val Loss:   2.2650
  Val Acc:    59.67%
  Val Top-5:  88.83%
  Val F1 (M): 58.81%

Epoch 20/30
  Train Loss: 0.0332
  Train Acc:  99.01%
  Val Loss:   2.3077
  Val Acc:    59.50%
  Val Top-5:  87.50%
  Val F1 (M): 58.52%

Epoch 21/30
  Train Loss: 0.0353
  Train Acc:  98.85%
  Val Loss:   2.1777
  Val Acc:    60.50%
  Val Top-5:  88.50%
  Val F1 (M): 59.56%
  Saved best model to outputs/vgg16_transfer/best_model.pth

Epoch 22/30
  Train Loss: 0.0205
  Train Acc:  99.46%
  Val Loss:   2.1835
  Val Acc:    60.50%
  Val Top-5:  88.83%
  Val F1 (M): 59.89%

Epoch 23/30
  Train Loss: 0.0154
  Train Acc:  99.59%
  Val Loss:   2.2205
  Val Acc:    58.67%
  Val Top-5:  89.50%
  Val F1 (M): 57.88%

Epoch 24/30
  Train Loss: 0.0104
  Train Acc:  99.67%
  Val Loss:   2.1665
  Val Acc:    60.17%
  Val Top-5:  89.67%
  Val F1 (M): 59.53%

Epoch 25/30
  Train Loss: 0.0117
  Train Acc:  99.68%
  Val Loss:   2.1100
  Val Acc:    60.00%
  Val Top-5:  89.50%
  Val F1 (M): 58.81%

Epoch 26/30
  Train Loss: 0.0119
  Train Acc:  99.65%
  Val Loss:   2.1032
  Val Acc:    60.50%
  Val Top-5:  89.33%
  Val F1 (M): 59.72%

Epoch 27/30
  Train Loss: 0.0075
  Train Acc:  99.83%
  Val Loss:   2.0923
  Val Acc:    61.67%
  Val Top-5:  89.83%
  Val F1 (M): 60.62%
  Saved best model to outputs/vgg16_transfer/best_model.pth

Epoch 28/30
  Train Loss: 0.0047
  Train Acc:  99.93%
  Val Loss:   2.1042
  Val Acc:    61.50%
  Val Top-5:  90.00%
  Val F1 (M): 60.33%

Epoch 29/30
  Train Loss: 0.0066
  Train Acc:  99.80%
  Val Loss:   2.1065
  Val Acc:    60.83%
  Val Top-5:  89.83%
  Val F1 (M): 59.88%

Epoch 30/30
  Train Loss: 0.0078
  Train Acc:  99.81%
  Val Loss:   2.0987
  Val Acc:    62.00%
  Val Top-5:  90.33%
  Val F1 (M): 60.79%
  Saved best model to outputs/vgg16_transfer/best_model.pth
  Test Acc:   65.26%
  Test Top-5: 89.45%
  Test F1 (M):65.22%

============================================================
Training completed in 777.70s
Best validation accuracy: 62.00%
============================================================


Results saved to: outputs/vgg16_transfer
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: vgg16_logit_kd
Student Architecture: vgg16
Distillation Type: logit
Device: cuda
Seed: 42

Configuration saved to: outputs/vgg16_logit_kd/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: vgg16
  Total parameters: 135,088,392
  Trainable parameters: 135,088,392

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01

Setting up knowledge distillation...
  Teacher: openai/clip-vit-base-patch32
  Distillation type: logit
  Alpha CE: 1.0
  Alpha KD: 1.0


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 6.8234
  Train Acc:  37.03%
  CE Loss:    3.3864
  KD Loss:    3.4370
  Val Loss:   2.3573
  Val Acc:    34.17%
  Val Top-5:  72.00%
  Val F1 (M): 30.63%
  Saved best model to outputs/vgg16_logit_kd/best_model.pth

Epoch 2/30
  Train Loss: 4.4512
  Train Acc:  58.58%
  CE Loss:    2.1080
  KD Loss:    2.3432
  Val Loss:   1.9440
  Val Acc:    44.17%
  Val Top-5:  79.67%
  Val F1 (M): 39.87%
  Saved best model to outputs/vgg16_logit_kd/best_model.pth

Epoch 3/30
  Train Loss: 3.7011
  Train Acc:  71.71%
  CE Loss:    1.6055
  KD Loss:    2.0956
  Val Loss:   1.6166
  Val Acc:    54.83%
  Val Top-5:  87.33%
  Val F1 (M): 51.76%
  Saved best model to outputs/vgg16_logit_kd/best_model.pth

Epoch 4/30
  Train Loss: 3.2258
  Train Acc:  79.35%
  CE Loss:    1.2849
  KD Loss:    1.9409
  Val Loss:   1.4500
  Val Acc:    56.00%
  Val Top-5:  89.33%
  Val F1 (M): 52.99%
  Saved best model to outputs/vgg16_logit_kd/best_model.pth

Epoch 5/30
  Train Loss: 2.8958
  Train Acc:  85.57%
  CE Loss:    1.0532
  KD Loss:    1.8426
  Val Loss:   1.3831
  Val Acc:    59.00%
  Val Top-5:  88.83%
  Val F1 (M): 56.10%
  Saved best model to outputs/vgg16_logit_kd/best_model.pth

Epoch 6/30
  Train Loss: 2.6605
  Train Acc:  89.19%
  CE Loss:    0.9023
  KD Loss:    1.7582
  Val Loss:   1.3921
  Val Acc:    59.00%
  Val Top-5:  88.50%
  Val F1 (M): 56.70%

Epoch 7/30
  Train Loss: 2.4346
  Train Acc:  92.06%
  CE Loss:    0.7599
  KD Loss:    1.6746
  Val Loss:   1.2826
  Val Acc:    64.33%
  Val Top-5:  91.50%
  Val F1 (M): 63.20%
  Saved best model to outputs/vgg16_logit_kd/best_model.pth

Epoch 8/30
  Train Loss: 2.2459
  Train Acc:  94.25%
  CE Loss:    0.6512
  KD Loss:    1.5946
  Val Loss:   1.2961
  Val Acc:    64.83%
  Val Top-5:  89.83%
  Val F1 (M): 62.90%
  Saved best model to outputs/vgg16_logit_kd/best_model.pth

Epoch 9/30
  Train Loss: 2.0867
  Train Acc:  96.28%
  CE Loss:    0.5487
  KD Loss:    1.5381
  Val Loss:   1.2678
  Val Acc:    64.50%
  Val Top-5:  91.83%
  Val F1 (M): 62.27%

Epoch 10/30
  Train Loss: 1.9928
  Train Acc:  97.19%
  CE Loss:    0.4904
  KD Loss:    1.5024
  Val Loss:   1.2030
  Val Acc:    69.67%
  Val Top-5:  91.00%
  Val F1 (M): 68.51%
  Saved best model to outputs/vgg16_logit_kd/best_model.pth

Epoch 11/30
  Train Loss: 1.8870
  Train Acc:  97.99%
  CE Loss:    0.4376
  KD Loss:    1.4493
  Val Loss:   1.1970
  Val Acc:    67.67%
  Val Top-5:  92.17%
  Val F1 (M): 65.58%

Epoch 12/30
  Train Loss: 1.7778
  Train Acc:  98.77%
  CE Loss:    0.3823
  KD Loss:    1.3955
  Val Loss:   1.1518
  Val Acc:    70.17%
  Val Top-5:  91.83%
  Val F1 (M): 68.94%
  Saved best model to outputs/vgg16_logit_kd/best_model.pth

Epoch 13/30
  Train Loss: 1.6863
  Train Acc:  99.03%
  CE Loss:    0.3466
  KD Loss:    1.3397
  Val Loss:   1.1442
  Val Acc:    68.50%
  Val Top-5:  92.33%
  Val F1 (M): 67.62%

Epoch 14/30
  Train Loss: 1.6150
  Train Acc:  99.42%
  CE Loss:    0.3074
  KD Loss:    1.3076
  Val Loss:   1.1517
  Val Acc:    70.00%
  Val Top-5:  92.50%
  Val F1 (M): 68.65%

Epoch 15/30
  Train Loss: 1.5287
  Train Acc:  99.61%
  CE Loss:    0.2829
  KD Loss:    1.2458
  Val Loss:   1.1563
  Val Acc:    68.50%
  Val Top-5:  92.00%
  Val F1 (M): 66.94%

Epoch 16/30
  Train Loss: 1.4891
  Train Acc:  99.59%
  CE Loss:    0.2728
  KD Loss:    1.2163
  Val Loss:   1.1581
  Val Acc:    70.00%
  Val Top-5:  92.83%
  Val F1 (M): 68.44%

Epoch 17/30
  Train Loss: 1.4305
  Train Acc:  99.83%
  CE Loss:    0.2462
  KD Loss:    1.1843
  Val Loss:   1.1459
  Val Acc:    70.67%
  Val Top-5:  93.17%
  Val F1 (M): 69.65%
  Saved best model to outputs/vgg16_logit_kd/best_model.pth

Epoch 18/30
  Train Loss: 1.3708
  Train Acc:  99.89%
  CE Loss:    0.2279
  KD Loss:    1.1429
  Val Loss:   1.1557
  Val Acc:    70.33%
  Val Top-5:  92.50%
  Val F1 (M): 69.41%

Epoch 19/30
  Train Loss: 1.3395
  Train Acc:  99.85%
  CE Loss:    0.2243
  KD Loss:    1.1152
  Val Loss:   1.1332
  Val Acc:    69.33%
  Val Top-5:  92.50%
  Val F1 (M): 68.04%

Epoch 20/30
  Train Loss: 1.2996
  Train Acc:  99.93%
  CE Loss:    0.2139
  KD Loss:    1.0857
  Val Loss:   1.1204
  Val Acc:    71.00%
  Val Top-5:  91.83%
  Val F1 (M): 69.62%
  Saved best model to outputs/vgg16_logit_kd/best_model.pth

Epoch 21/30
  Train Loss: 1.2609
  Train Acc:  99.81%
  CE Loss:    0.2054
  KD Loss:    1.0555
  Val Loss:   1.1300
  Val Acc:    72.17%
  Val Top-5:  91.83%
  Val F1 (M): 71.44%
  Saved best model to outputs/vgg16_logit_kd/best_model.pth

Epoch 22/30
  Train Loss: 1.2324
  Train Acc:  99.83%
  CE Loss:    0.2011
  KD Loss:    1.0313
  Val Loss:   1.1202
  Val Acc:    71.00%
  Val Top-5:  92.00%
  Val F1 (M): 69.78%

Epoch 23/30
  Train Loss: 1.2039
  Train Acc:  99.93%
  CE Loss:    0.1930
  KD Loss:    1.0109
  Val Loss:   1.1104
  Val Acc:    71.17%
  Val Top-5:  92.83%
  Val F1 (M): 70.42%

Epoch 24/30
  Train Loss: 1.1764
  Train Acc:  99.91%
  CE Loss:    0.1855
  KD Loss:    0.9909
  Val Loss:   1.1088
  Val Acc:    72.17%
  Val Top-5:  93.00%
  Val F1 (M): 71.27%

Epoch 25/30
  Train Loss: 1.1644
  Train Acc:  99.81%
  CE Loss:    0.1855
  KD Loss:    0.9789
  Val Loss:   1.1106
  Val Acc:    73.00%
  Val Top-5:  92.17%
  Val F1 (M): 72.43%
  Saved best model to outputs/vgg16_logit_kd/best_model.pth

Epoch 26/30
  Train Loss: 1.1512
  Train Acc:  99.76%
  CE Loss:    0.1822
  KD Loss:    0.9690
  Val Loss:   1.1115
  Val Acc:    71.33%
  Val Top-5:  92.83%
  Val F1 (M): 70.42%

Epoch 27/30
  Train Loss: 1.1363
  Train Acc:  99.87%
  CE Loss:    0.1756
  KD Loss:    0.9607
  Val Loss:   1.1178
  Val Acc:    71.33%
  Val Top-5:  92.50%
  Val F1 (M): 70.59%

Epoch 28/30
  Train Loss: 1.1152
  Train Acc:  99.81%
  CE Loss:    0.1750
  KD Loss:    0.9402
  Val Loss:   1.1264
  Val Acc:    71.67%
  Val Top-5:  92.33%
  Val F1 (M): 70.79%

Epoch 29/30
  Train Loss: 1.1137
  Train Acc:  99.83%
  CE Loss:    0.1735
  KD Loss:    0.9402
  Val Loss:   1.1212
  Val Acc:    71.83%
  Val Top-5:  92.50%
  Val F1 (M): 71.15%

Epoch 30/30
  Train Loss: 1.1145
  Train Acc:  99.87%
  CE Loss:    0.1738
  KD Loss:    0.9408
  Val Loss:   1.1141
  Val Acc:    72.33%
  Val Top-5:  92.50%
  Val F1 (M): 71.57%
  Test Acc:   73.68%
  Test Top-5: 92.84%
  Test F1 (M):73.73%

============================================================
Training completed in 1049.21s
Best validation accuracy: 73.00%
============================================================


Results saved to: outputs/vgg16_logit_kd
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: vgg16_attention_kd
Student Architecture: vgg16
Distillation Type: attention
Device: cuda
Seed: 42

Configuration saved to: outputs/vgg16_attention_kd/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: vgg16
  Total parameters: 135,088,392
  Trainable parameters: 135,088,392

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01

Setting up knowledge distillation...
  Teacher: openai/clip-vit-base-patch32
  Distillation type: attention
  Alpha CE: 1.0
  Alpha KD: 0.0
  Alpha Attention: 0.5
  Attention loss: mse


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 4.1559
  Train Acc:  22.15%
  CE Loss:    4.1559
  KD Loss:    6.1003
  Val Loss:   3.2014
  Val Acc:    20.17%
  Val Top-5:  50.17%
  Val F1 (M): 14.58%
  Saved best model to outputs/vgg16_attention_kd/best_model.pth

Epoch 2/30
  Train Loss: 2.6448
  Train Acc:  49.39%
  CE Loss:    2.6448
  KD Loss:    5.6015
  Val Loss:   2.4586
  Val Acc:    35.50%
  Val Top-5:  69.00%
  Val F1 (M): 31.22%
  Saved best model to outputs/vgg16_attention_kd/best_model.pth

Epoch 3/30
  Train Loss: 1.8994
  Train Acc:  66.78%
  CE Loss:    1.8994
  KD Loss:    6.5202
  Val Loss:   2.2227
  Val Acc:    41.83%
  Val Top-5:  77.00%
  Val F1 (M): 38.54%
  Saved best model to outputs/vgg16_attention_kd/best_model.pth

Epoch 4/30
  Train Loss: 1.4570
  Train Acc:  78.18%
  CE Loss:    1.4570
  KD Loss:    7.9456
  Val Loss:   2.1013
  Val Acc:    46.50%
  Val Top-5:  77.67%
  Val F1 (M): 42.92%
  Saved best model to outputs/vgg16_attention_kd/best_model.pth

Epoch 5/30
  Train Loss: 1.1770
  Train Acc:  83.84%
  CE Loss:    1.1770
  KD Loss:    9.2704
  Val Loss:   1.8546
  Val Acc:    51.50%
  Val Top-5:  85.00%
  Val F1 (M): 48.21%
  Saved best model to outputs/vgg16_attention_kd/best_model.pth

Epoch 6/30
  Train Loss: 0.9513
  Train Acc:  88.90%
  CE Loss:    0.9513
  KD Loss:    11.1430
  Val Loss:   1.9466
  Val Acc:    50.83%
  Val Top-5:  82.33%
  Val F1 (M): 48.81%

Epoch 7/30
  Train Loss: 0.7488
  Train Acc:  92.49%
  CE Loss:    0.7488
  KD Loss:    12.6472
  Val Loss:   1.7753
  Val Acc:    54.00%
  Val Top-5:  86.00%
  Val F1 (M): 51.40%
  Saved best model to outputs/vgg16_attention_kd/best_model.pth

Epoch 8/30
  Train Loss: 0.5877
  Train Acc:  95.09%
  CE Loss:    0.5877
  KD Loss:    14.9438
  Val Loss:   2.0988
  Val Acc:    50.00%
  Val Top-5:  83.33%
  Val F1 (M): 46.69%

Epoch 9/30
  Train Loss: 0.4858
  Train Acc:  96.50%
  CE Loss:    0.4858
  KD Loss:    17.1395
  Val Loss:   1.9685
  Val Acc:    52.17%
  Val Top-5:  84.50%
  Val F1 (M): 51.02%

Epoch 10/30
  Train Loss: 0.4171
  Train Acc:  97.49%
  CE Loss:    0.4171
  KD Loss:    18.5538
  Val Loss:   2.0265
  Val Acc:    54.33%
  Val Top-5:  85.50%
  Val F1 (M): 51.77%
  Saved best model to outputs/vgg16_attention_kd/best_model.pth

Epoch 11/30
  Train Loss: 0.2847
  Train Acc:  99.09%
  CE Loss:    0.2847
  KD Loss:    21.6754
  Val Loss:   2.1740
  Val Acc:    54.50%
  Val Top-5:  84.83%
  Val F1 (M): 53.81%
  Saved best model to outputs/vgg16_attention_kd/best_model.pth

Epoch 12/30
  Train Loss: 0.2636
  Train Acc:  99.20%
  CE Loss:    0.2636
  KD Loss:    23.9460
  Val Loss:   2.1197
  Val Acc:    54.67%
  Val Top-5:  86.00%
  Val F1 (M): 53.64%
  Saved best model to outputs/vgg16_attention_kd/best_model.pth

Epoch 13/30
  Train Loss: 0.1880
  Train Acc:  99.48%
  CE Loss:    0.1880
  KD Loss:    25.6939
  Val Loss:   2.0449
  Val Acc:    59.00%
  Val Top-5:  85.50%
  Val F1 (M): 57.35%
  Saved best model to outputs/vgg16_attention_kd/best_model.pth

Epoch 14/30
  Train Loss: 0.1513
  Train Acc:  99.52%
  CE Loss:    0.1513
  KD Loss:    28.6505
  Val Loss:   2.2003
  Val Acc:    58.00%
  Val Top-5:  85.17%
  Val F1 (M): 56.52%

Epoch 15/30
  Train Loss: 0.1097
  Train Acc:  99.72%
  CE Loss:    0.1097
  KD Loss:    32.3150
  Val Loss:   2.2306
  Val Acc:    57.67%
  Val Top-5:  86.33%
  Val F1 (M): 55.24%

Epoch 16/30
  Train Loss: 0.1109
  Train Acc:  99.87%
  CE Loss:    0.1109
  KD Loss:    32.3103
  Val Loss:   2.1215
  Val Acc:    58.00%
  Val Top-5:  86.17%
  Val F1 (M): 57.46%

Epoch 17/30
  Train Loss: 0.0709
  Train Acc:  99.89%
  CE Loss:    0.0709
  KD Loss:    34.3740
  Val Loss:   2.3578
  Val Acc:    58.33%
  Val Top-5:  86.67%
  Val F1 (M): 56.64%

Epoch 18/30
  Train Loss: 0.0458
  Train Acc:  99.94%
  CE Loss:    0.0458
  KD Loss:    39.9382
  Val Loss:   2.2926
  Val Acc:    59.33%
  Val Top-5:  88.17%
  Val F1 (M): 57.81%
  Saved best model to outputs/vgg16_attention_kd/best_model.pth

Epoch 19/30
  Train Loss: 0.0412
  Train Acc:  99.94%
  CE Loss:    0.0412
  KD Loss:    41.5604
  Val Loss:   2.1810
  Val Acc:    58.67%
  Val Top-5:  87.33%
  Val F1 (M): 56.51%

Epoch 20/30
  Train Loss: 0.0373
  Train Acc:  99.94%
  CE Loss:    0.0373
  KD Loss:    40.9679
  Val Loss:   2.3111
  Val Acc:    59.17%
  Val Top-5:  87.50%
  Val F1 (M): 57.20%

Epoch 21/30
  Train Loss: 0.0301
  Train Acc:  99.94%
  CE Loss:    0.0301
  KD Loss:    44.6673
  Val Loss:   2.2234
  Val Acc:    60.67%
  Val Top-5:  89.33%
  Val F1 (M): 59.72%
  Saved best model to outputs/vgg16_attention_kd/best_model.pth

Epoch 22/30
  Train Loss: 0.0206
  Train Acc:  99.98%
  CE Loss:    0.0206
  KD Loss:    46.9937
  Val Loss:   2.2282
  Val Acc:    61.67%
  Val Top-5:  88.33%
  Val F1 (M): 60.81%
  Saved best model to outputs/vgg16_attention_kd/best_model.pth

Epoch 23/30
  Train Loss: 0.0170
  Train Acc:  99.93%
  CE Loss:    0.0170
  KD Loss:    48.5599
  Val Loss:   2.3942
  Val Acc:    59.83%
  Val Top-5:  88.33%
  Val F1 (M): 59.37%

Epoch 24/30
  Train Loss: 0.0131
  Train Acc:  99.98%
  CE Loss:    0.0131
  KD Loss:    50.5684
  Val Loss:   2.2576
  Val Acc:    61.33%
  Val Top-5:  87.83%
  Val F1 (M): 60.38%

Epoch 25/30
  Train Loss: 0.0100
  Train Acc:  99.98%
  CE Loss:    0.0100
  KD Loss:    52.5236
  Val Loss:   2.2627
  Val Acc:    62.17%
  Val Top-5:  88.00%
  Val F1 (M): 60.58%
  Saved best model to outputs/vgg16_attention_kd/best_model.pth

Epoch 26/30
  Train Loss: 0.0112
  Train Acc:  99.91%
  CE Loss:    0.0112
  KD Loss:    53.3484
  Val Loss:   2.2302
  Val Acc:    62.00%
  Val Top-5:  88.17%
  Val F1 (M): 60.76%

Epoch 27/30
  Train Loss: 0.0050
  Train Acc:  99.94%
  CE Loss:    0.0050
  KD Loss:    53.2858
  Val Loss:   2.2278
  Val Acc:    62.67%
  Val Top-5:  88.50%
  Val F1 (M): 61.39%
  Saved best model to outputs/vgg16_attention_kd/best_model.pth

Epoch 28/30
  Train Loss: 0.0072
  Train Acc:  99.87%
  CE Loss:    0.0072
  KD Loss:    54.4652
  Val Loss:   2.2651
  Val Acc:    61.50%
  Val Top-5:  88.17%
  Val F1 (M): 60.27%

Epoch 29/30
  Train Loss: 0.0069
  Train Acc:  99.80%
  CE Loss:    0.0069
  KD Loss:    54.5375
  Val Loss:   2.2311
  Val Acc:    62.17%
  Val Top-5:  88.50%
  Val F1 (M): 60.65%

Epoch 30/30
  Train Loss: 0.0078
  Train Acc:  99.83%
  CE Loss:    0.0078
  KD Loss:    54.8162
  Val Loss:   2.2612
  Val Acc:    62.33%
  Val Top-5:  88.67%
  Val F1 (M): 60.97%
  Test Acc:   65.90%
  Test Top-5: 89.20%
  Test F1 (M):65.96%

============================================================
Training completed in 1335.70s
Best validation accuracy: 62.67%
============================================================


Results saved to: outputs/vgg16_attention_kd
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: vgg16_combined_kd
Student Architecture: vgg16
Distillation Type: combined
Device: cuda
Seed: 42

Configuration saved to: outputs/vgg16_combined_kd/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: vgg16
  Total parameters: 135,088,392
  Trainable parameters: 135,088,392

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01

Setting up knowledge distillation...
  Teacher: openai/clip-vit-base-patch32
  Distillation type: combined
  Alpha CE: 1.0
  Alpha KD: 1.0
  Alpha Attention: 0.1
  Attention loss: mse


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 6.8234
  Train Acc:  37.03%
  CE Loss:    3.3864
  KD Loss:    3.4370
  Val Loss:   2.3312
  Val Acc:    34.50%
  Val Top-5:  72.83%
  Val F1 (M): 30.95%
  Saved best model to outputs/vgg16_combined_kd/best_model.pth

Epoch 2/30
  Train Loss: 4.4512
  Train Acc:  58.58%
  CE Loss:    2.1080
  KD Loss:    2.3432
  Val Loss:   1.9163
  Val Acc:    45.33%
  Val Top-5:  80.00%
  Val F1 (M): 41.19%
  Saved best model to outputs/vgg16_combined_kd/best_model.pth

Epoch 3/30
  Train Loss: 3.7011
  Train Acc:  71.71%
  CE Loss:    1.6055
  KD Loss:    2.0956
  Val Loss:   1.5957
  Val Acc:    54.67%
  Val Top-5:  87.17%
  Val F1 (M): 51.64%
  Saved best model to outputs/vgg16_combined_kd/best_model.pth

Epoch 4/30
  Train Loss: 3.2258
  Train Acc:  79.35%
  CE Loss:    1.2849
  KD Loss:    1.9409
  Val Loss:   1.4389
  Val Acc:    56.50%
  Val Top-5:  89.00%
  Val F1 (M): 53.51%
  Saved best model to outputs/vgg16_combined_kd/best_model.pth

Epoch 5/30
  Train Loss: 2.8958
  Train Acc:  85.57%
  CE Loss:    1.0532
  KD Loss:    1.8426
  Val Loss:   1.3722
  Val Acc:    58.83%
  Val Top-5:  89.33%
  Val F1 (M): 55.86%
  Saved best model to outputs/vgg16_combined_kd/best_model.pth

Epoch 6/30
  Train Loss: 2.6605
  Train Acc:  89.19%
  CE Loss:    0.9023
  KD Loss:    1.7582
  Val Loss:   1.3716
  Val Acc:    60.00%
  Val Top-5:  88.67%
  Val F1 (M): 57.83%
  Saved best model to outputs/vgg16_combined_kd/best_model.pth

Epoch 7/30
  Train Loss: 2.4346
  Train Acc:  92.06%
  CE Loss:    0.7599
  KD Loss:    1.6746
  Val Loss:   1.2765
  Val Acc:    64.33%
  Val Top-5:  91.50%
  Val F1 (M): 63.26%
  Saved best model to outputs/vgg16_combined_kd/best_model.pth

Epoch 8/30
  Train Loss: 2.2459
  Train Acc:  94.25%
  CE Loss:    0.6512
  KD Loss:    1.5946
  Val Loss:   1.2874
  Val Acc:    64.67%
  Val Top-5:  90.00%
  Val F1 (M): 62.64%
  Saved best model to outputs/vgg16_combined_kd/best_model.pth

Epoch 9/30
  Train Loss: 2.0867
  Train Acc:  96.28%
  CE Loss:    0.5487
  KD Loss:    1.5381
  Val Loss:   1.2643
  Val Acc:    64.33%
  Val Top-5:  91.83%
  Val F1 (M): 62.08%

Epoch 10/30
  Train Loss: 1.9928
  Train Acc:  97.19%
  CE Loss:    0.4904
  KD Loss:    1.5024
  Val Loss:   1.1988
  Val Acc:    69.67%
  Val Top-5:  91.33%
  Val F1 (M): 68.52%
  Saved best model to outputs/vgg16_combined_kd/best_model.pth

Epoch 11/30
  Train Loss: 1.8870
  Train Acc:  97.99%
  CE Loss:    0.4376
  KD Loss:    1.4493
  Val Loss:   1.1906
  Val Acc:    68.17%
  Val Top-5:  92.17%
  Val F1 (M): 66.16%

Epoch 12/30
  Train Loss: 1.7778
  Train Acc:  98.77%
  CE Loss:    0.3823
  KD Loss:    1.3955
  Val Loss:   1.1514
  Val Acc:    70.00%
  Val Top-5:  91.83%
  Val F1 (M): 68.75%
  Saved best model to outputs/vgg16_combined_kd/best_model.pth

Epoch 13/30
  Train Loss: 1.6863
  Train Acc:  99.03%
  CE Loss:    0.3466
  KD Loss:    1.3397
  Val Loss:   1.1424
  Val Acc:    69.33%
  Val Top-5:  92.33%
  Val F1 (M): 68.60%

Epoch 14/30
  Train Loss: 1.6150
  Train Acc:  99.42%
  CE Loss:    0.3074
  KD Loss:    1.3076
  Val Loss:   1.1543
  Val Acc:    70.17%
  Val Top-5:  92.17%
  Val F1 (M): 68.73%
  Saved best model to outputs/vgg16_combined_kd/best_model.pth

Epoch 15/30
  Train Loss: 1.5287
  Train Acc:  99.61%
  CE Loss:    0.2829
  KD Loss:    1.2458
  Val Loss:   1.1578
  Val Acc:    68.67%
  Val Top-5:  92.00%
  Val F1 (M): 67.03%

Epoch 16/30
  Train Loss: 1.4891
  Train Acc:  99.59%
  CE Loss:    0.2728
  KD Loss:    1.2163
  Val Loss:   1.1570
  Val Acc:    69.83%
  Val Top-5:  92.50%
  Val F1 (M): 68.31%

Epoch 17/30
  Train Loss: 1.4305
  Train Acc:  99.83%
  CE Loss:    0.2462
  KD Loss:    1.1843
  Val Loss:   1.1477
  Val Acc:    70.50%
  Val Top-5:  93.00%
  Val F1 (M): 69.43%
  Saved best model to outputs/vgg16_combined_kd/best_model.pth

Epoch 18/30
  Train Loss: 1.3708
  Train Acc:  99.89%
  CE Loss:    0.2279
  KD Loss:    1.1429
  Val Loss:   1.1545
  Val Acc:    70.67%
  Val Top-5:  92.67%
  Val F1 (M): 69.71%
  Saved best model to outputs/vgg16_combined_kd/best_model.pth

Epoch 19/30
  Train Loss: 1.3395
  Train Acc:  99.85%
  CE Loss:    0.2243
  KD Loss:    1.1152
  Val Loss:   1.1349
  Val Acc:    68.67%
  Val Top-5:  92.33%
  Val F1 (M): 67.17%

Epoch 20/30
  Train Loss: 1.2996
  Train Acc:  99.93%
  CE Loss:    0.2139
  KD Loss:    1.0857
  Val Loss:   1.1199
  Val Acc:    71.17%
  Val Top-5:  91.83%
  Val F1 (M): 69.74%
  Saved best model to outputs/vgg16_combined_kd/best_model.pth

Epoch 21/30
  Train Loss: 1.2609
  Train Acc:  99.81%
  CE Loss:    0.2054
  KD Loss:    1.0555
  Val Loss:   1.1322
  Val Acc:    71.67%
  Val Top-5:  91.83%
  Val F1 (M): 70.86%
  Saved best model to outputs/vgg16_combined_kd/best_model.pth

Epoch 22/30
  Train Loss: 1.2324
  Train Acc:  99.83%
  CE Loss:    0.2011
  KD Loss:    1.0313
  Val Loss:   1.1194
  Val Acc:    70.17%
  Val Top-5:  92.33%
  Val F1 (M): 68.92%

Epoch 23/30
  Train Loss: 1.2039
  Train Acc:  99.93%
  CE Loss:    0.1930
  KD Loss:    1.0109
  Val Loss:   1.1107
  Val Acc:    71.33%
  Val Top-5:  92.83%
  Val F1 (M): 70.47%

Epoch 24/30
  Train Loss: 1.1764
  Train Acc:  99.91%
  CE Loss:    0.1855
  KD Loss:    0.9909
  Val Loss:   1.1086
  Val Acc:    72.67%
  Val Top-5:  93.00%
  Val F1 (M): 71.86%
  Saved best model to outputs/vgg16_combined_kd/best_model.pth

Epoch 25/30
  Train Loss: 1.1644
  Train Acc:  99.81%
  CE Loss:    0.1855
  KD Loss:    0.9789
  Val Loss:   1.1109
  Val Acc:    73.17%
  Val Top-5:  91.83%
  Val F1 (M): 72.69%
  Saved best model to outputs/vgg16_combined_kd/best_model.pth

Epoch 26/30
  Train Loss: 1.1512
  Train Acc:  99.76%
  CE Loss:    0.1822
  KD Loss:    0.9690
  Val Loss:   1.1108
  Val Acc:    71.67%
  Val Top-5:  93.00%
  Val F1 (M): 70.72%

Epoch 27/30
  Train Loss: 1.1363
  Train Acc:  99.87%
  CE Loss:    0.1756
  KD Loss:    0.9607
  Val Loss:   1.1204
  Val Acc:    71.50%
  Val Top-5:  92.50%
  Val F1 (M): 70.78%

Epoch 28/30
  Train Loss: 1.1152
  Train Acc:  99.81%
  CE Loss:    0.1750
  KD Loss:    0.9402
  Val Loss:   1.1301
  Val Acc:    72.00%
  Val Top-5:  92.17%
  Val F1 (M): 71.16%

Epoch 29/30
  Train Loss: 1.1137
  Train Acc:  99.83%
  CE Loss:    0.1735
  KD Loss:    0.9402
  Val Loss:   1.1241
  Val Acc:    71.67%
  Val Top-5:  92.50%
  Val F1 (M): 71.04%

Epoch 30/30
  Train Loss: 1.1145
  Train Acc:  99.87%
  CE Loss:    0.1738
  KD Loss:    0.9408
  Val Loss:   1.1132
  Val Acc:    72.00%
  Val Top-5:  92.33%
  Val F1 (M): 71.05%
  Test Acc:   73.61%
  Test Top-5: 92.84%
  Test F1 (M):73.67%

============================================================
Training completed in 1337.69s
Best validation accuracy: 73.17%
============================================================


Results saved to: outputs/vgg16_combined_kd
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: vgg19_scratch
Student Architecture: vgg19
Distillation Type: none
Device: cuda
Seed: 42

Configuration saved to: outputs/vgg19_scratch/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: vgg19
  Total parameters: 140,400,648
  Trainable parameters: 140,400,648

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 5.9426
  Train Acc:  0.50%
  Val Loss:   5.3290
  Val Acc:    0.67%
  Val Top-5:  3.67%
  Val F1 (M): 0.08%
  Saved best model to outputs/vgg19_scratch/best_model.pth

Epoch 2/30
  Train Loss: 5.2663
  Train Acc:  0.87%
  Val Loss:   5.2454
  Val Acc:    1.17%
  Val Top-5:  7.17%
  Val F1 (M): 0.13%
  Saved best model to outputs/vgg19_scratch/best_model.pth

Epoch 3/30
  Train Loss: 5.1539
  Train Acc:  1.36%
  Val Loss:   5.0478
  Val Acc:    2.00%
  Val Top-5:  6.00%
  Val F1 (M): 0.43%
  Saved best model to outputs/vgg19_scratch/best_model.pth

Epoch 4/30
  Train Loss: 5.0327
  Train Acc:  1.32%
  Val Loss:   4.9197
  Val Acc:    2.17%
  Val Top-5:  9.17%
  Val F1 (M): 1.19%
  Saved best model to outputs/vgg19_scratch/best_model.pth

Epoch 5/30
  Train Loss: 4.9090
  Train Acc:  2.01%
  Val Loss:   4.8492
  Val Acc:    3.67%
  Val Top-5:  11.33%
  Val F1 (M): 1.97%
  Saved best model to outputs/vgg19_scratch/best_model.pth

Epoch 6/30
  Train Loss: 4.7957
  Train Acc:  2.18%
  Val Loss:   4.8453
  Val Acc:    2.33%
  Val Top-5:  13.17%
  Val F1 (M): 0.89%

Epoch 7/30
  Train Loss: 4.6963
  Train Acc:  3.48%
  Val Loss:   4.6313
  Val Acc:    4.50%
  Val Top-5:  18.50%
  Val F1 (M): 2.05%
  Saved best model to outputs/vgg19_scratch/best_model.pth

Epoch 8/30
  Train Loss: 4.5664
  Train Acc:  4.17%
  Val Loss:   4.6628
  Val Acc:    4.50%
  Val Top-5:  17.00%
  Val F1 (M): 1.61%

Epoch 9/30
  Train Loss: 4.4358
  Train Acc:  5.45%
  Val Loss:   4.4471
  Val Acc:    5.83%
  Val Top-5:  21.17%
  Val F1 (M): 3.06%
  Saved best model to outputs/vgg19_scratch/best_model.pth

Epoch 10/30
  Train Loss: 4.3157
  Train Acc:  6.31%
  Val Loss:   4.4917
  Val Acc:    7.17%
  Val Top-5:  21.83%
  Val F1 (M): 4.50%
  Saved best model to outputs/vgg19_scratch/best_model.pth

Epoch 11/30
  Train Loss: 4.1952
  Train Acc:  7.59%
  Val Loss:   4.3345
  Val Acc:    6.83%
  Val Top-5:  26.83%
  Val F1 (M): 4.42%

Epoch 12/30
  Train Loss: 4.0633
  Train Acc:  8.85%
  Val Loss:   4.2813
  Val Acc:    9.17%
  Val Top-5:  26.33%
  Val F1 (M): 6.70%
  Saved best model to outputs/vgg19_scratch/best_model.pth

Epoch 13/30
  Train Loss: 3.9079
  Train Acc:  10.68%
  Val Loss:   4.3272
  Val Acc:    7.83%
  Val Top-5:  26.50%
  Val F1 (M): 5.47%

Epoch 14/30
  Train Loss: 3.8010
  Train Acc:  12.00%
  Val Loss:   4.2946
  Val Acc:    9.00%
  Val Top-5:  26.00%
  Val F1 (M): 6.69%

Epoch 15/30
  Train Loss: 3.6556
  Train Acc:  14.25%
  Val Loss:   4.2309
  Val Acc:    11.33%
  Val Top-5:  30.83%
  Val F1 (M): 10.13%
  Saved best model to outputs/vgg19_scratch/best_model.pth

Epoch 16/30
  Train Loss: 3.5229
  Train Acc:  16.72%
  Val Loss:   4.3589
  Val Acc:    8.67%
  Val Top-5:  29.00%
  Val F1 (M): 7.02%

Epoch 17/30
  Train Loss: 3.3359
  Train Acc:  19.29%
  Val Loss:   4.4151
  Val Acc:    8.67%
  Val Top-5:  29.83%
  Val F1 (M): 7.52%

Epoch 18/30
  Train Loss: 3.1838
  Train Acc:  22.36%
  Val Loss:   4.4767
  Val Acc:    10.83%
  Val Top-5:  28.33%
  Val F1 (M): 9.28%

Epoch 19/30
  Train Loss: 3.0177
  Train Acc:  25.99%
  Val Loss:   4.4610
  Val Acc:    10.33%
  Val Top-5:  32.17%
  Val F1 (M): 8.97%

Epoch 20/30
  Train Loss: 2.8318
  Train Acc:  27.77%
  Val Loss:   4.5450
  Val Acc:    12.00%
  Val Top-5:  31.17%
  Val F1 (M): 10.77%
  Saved best model to outputs/vgg19_scratch/best_model.pth

Epoch 21/30
  Train Loss: 2.6143
  Train Acc:  32.81%
  Val Loss:   4.6422
  Val Acc:    13.33%
  Val Top-5:  33.50%
  Val F1 (M): 12.27%
  Saved best model to outputs/vgg19_scratch/best_model.pth

Epoch 22/30
  Train Loss: 2.4637
  Train Acc:  36.90%
  Val Loss:   4.5209
  Val Acc:    14.50%
  Val Top-5:  34.83%
  Val F1 (M): 13.07%
  Saved best model to outputs/vgg19_scratch/best_model.pth

Epoch 23/30
  Train Loss: 2.2682
  Train Acc:  41.03%
  Val Loss:   4.7356
  Val Acc:    13.00%
  Val Top-5:  34.00%
  Val F1 (M): 12.56%

Epoch 24/30
  Train Loss: 2.1045
  Train Acc:  45.31%
  Val Loss:   4.9086
  Val Acc:    13.83%
  Val Top-5:  32.17%
  Val F1 (M): 12.43%

Epoch 25/30
  Train Loss: 1.9809
  Train Acc:  47.43%
  Val Loss:   4.9747
  Val Acc:    13.50%
  Val Top-5:  34.00%
  Val F1 (M): 11.95%

Epoch 26/30
  Train Loss: 1.8607
  Train Acc:  49.48%
  Val Loss:   5.1936
  Val Acc:    14.33%
  Val Top-5:  34.33%
  Val F1 (M): 13.37%

Epoch 27/30
  Train Loss: 1.7898
  Train Acc:  52.06%
  Val Loss:   5.1670
  Val Acc:    13.67%
  Val Top-5:  33.33%
  Val F1 (M): 12.44%

Epoch 28/30
  Train Loss: 1.7326
  Train Acc:  54.11%
  Val Loss:   5.2282
  Val Acc:    13.50%
  Val Top-5:  33.50%
  Val F1 (M): 12.54%

Epoch 29/30
  Train Loss: 1.6984
  Train Acc:  54.85%
  Val Loss:   5.1576
  Val Acc:    14.00%
  Val Top-5:  33.67%
  Val F1 (M): 13.03%

Epoch 30/30
  Train Loss: 1.6879
  Train Acc:  55.12%
  Val Loss:   5.2075
  Val Acc:    13.67%
  Val Top-5:  33.67%
  Val F1 (M): 12.64%
  Test Acc:   12.79%
  Test Top-5: 33.33%
  Test F1 (M):12.56%

============================================================
Training completed in 842.40s
Best validation accuracy: 14.50%
============================================================


Results saved to: outputs/vgg19_scratch
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: vgg19_transfer
Student Architecture: vgg19
Distillation Type: none
Device: cuda
Seed: 42

Configuration saved to: outputs/vgg19_transfer/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: vgg19
  Total parameters: 140,400,648
  Trainable parameters: 140,400,648

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 4.3251
  Train Acc:  7.33%
  Val Loss:   3.5872
  Val Acc:    14.67%
  Val Top-5:  40.50%
  Val F1 (M): 10.16%
  Saved best model to outputs/vgg19_transfer/best_model.pth

Epoch 2/30
  Train Loss: 2.9986
  Train Acc:  22.25%
  Val Loss:   2.9504
  Val Acc:    25.17%
  Val Top-5:  60.33%
  Val F1 (M): 20.44%
  Saved best model to outputs/vgg19_transfer/best_model.pth

Epoch 3/30
  Train Loss: 2.3169
  Train Acc:  34.84%
  Val Loss:   2.5198
  Val Acc:    32.83%
  Val Top-5:  67.67%
  Val F1 (M): 29.91%
  Saved best model to outputs/vgg19_transfer/best_model.pth

Epoch 4/30
  Train Loss: 1.8152
  Train Acc:  47.17%
  Val Loss:   2.5905
  Val Acc:    36.00%
  Val Top-5:  72.00%
  Val F1 (M): 32.30%
  Saved best model to outputs/vgg19_transfer/best_model.pth

Epoch 5/30
  Train Loss: 1.5223
  Train Acc:  55.10%
  Val Loss:   2.2592
  Val Acc:    41.83%
  Val Top-5:  79.33%
  Val F1 (M): 38.76%
  Saved best model to outputs/vgg19_transfer/best_model.pth

Epoch 6/30
  Train Loss: 1.2114
  Train Acc:  62.91%
  Val Loss:   2.2695
  Val Acc:    43.33%
  Val Top-5:  76.50%
  Val F1 (M): 40.74%
  Saved best model to outputs/vgg19_transfer/best_model.pth

Epoch 7/30
  Train Loss: 0.9867
  Train Acc:  69.08%
  Val Loss:   2.1341
  Val Acc:    45.00%
  Val Top-5:  79.50%
  Val F1 (M): 42.03%
  Saved best model to outputs/vgg19_transfer/best_model.pth

Epoch 8/30
  Train Loss: 0.8465
  Train Acc:  72.86%
  Val Loss:   2.3515
  Val Acc:    44.83%
  Val Top-5:  79.50%
  Val F1 (M): 42.54%

Epoch 9/30
  Train Loss: 0.7304
  Train Acc:  77.34%
  Val Loss:   2.1415
  Val Acc:    46.50%
  Val Top-5:  84.17%
  Val F1 (M): 44.30%
  Saved best model to outputs/vgg19_transfer/best_model.pth

Epoch 10/30
  Train Loss: 0.5406
  Train Acc:  82.65%
  Val Loss:   2.3510
  Val Acc:    51.17%
  Val Top-5:  81.00%
  Val F1 (M): 48.98%
  Saved best model to outputs/vgg19_transfer/best_model.pth

Epoch 11/30
  Train Loss: 0.4344
  Train Acc:  86.48%
  Val Loss:   2.1290
  Val Acc:    51.83%
  Val Top-5:  83.50%
  Val F1 (M): 49.82%
  Saved best model to outputs/vgg19_transfer/best_model.pth

Epoch 12/30
  Train Loss: 0.3589
  Train Acc:  88.41%
  Val Loss:   2.3842
  Val Acc:    51.33%
  Val Top-5:  82.83%
  Val F1 (M): 48.95%

Epoch 13/30
  Train Loss: 0.2921
  Train Acc:  90.96%
  Val Loss:   2.2497
  Val Acc:    51.83%
  Val Top-5:  83.83%
  Val F1 (M): 49.74%

Epoch 14/30
  Train Loss: 0.2381
  Train Acc:  92.52%
  Val Loss:   2.4598
  Val Acc:    53.33%
  Val Top-5:  83.33%
  Val F1 (M): 50.88%
  Saved best model to outputs/vgg19_transfer/best_model.pth

Epoch 15/30
  Train Loss: 0.2059
  Train Acc:  93.23%
  Val Loss:   2.6544
  Val Acc:    49.00%
  Val Top-5:  80.83%
  Val F1 (M): 47.39%

Epoch 16/30
  Train Loss: 0.1489
  Train Acc:  94.96%
  Val Loss:   2.5058
  Val Acc:    54.50%
  Val Top-5:  84.00%
  Val F1 (M): 52.90%
  Saved best model to outputs/vgg19_transfer/best_model.pth

Epoch 17/30
  Train Loss: 0.1200
  Train Acc:  96.04%
  Val Loss:   2.2267
  Val Acc:    58.17%
  Val Top-5:  87.17%
  Val F1 (M): 56.68%
  Saved best model to outputs/vgg19_transfer/best_model.pth

Epoch 18/30
  Train Loss: 0.0787
  Train Acc:  97.38%
  Val Loss:   2.4220
  Val Acc:    56.83%
  Val Top-5:  85.17%
  Val F1 (M): 54.87%

Epoch 19/30
  Train Loss: 0.0606
  Train Acc:  98.14%
  Val Loss:   2.3974
  Val Acc:    57.33%
  Val Top-5:  86.67%
  Val F1 (M): 55.84%

Epoch 20/30
  Train Loss: 0.0510
  Train Acc:  98.16%
  Val Loss:   2.4335
  Val Acc:    56.50%
  Val Top-5:  87.17%
  Val F1 (M): 54.93%

Epoch 21/30
  Train Loss: 0.0312
  Train Acc:  99.14%
  Val Loss:   2.5749
  Val Acc:    57.67%
  Val Top-5:  86.83%
  Val F1 (M): 56.11%

Epoch 22/30
  Train Loss: 0.0264
  Train Acc:  99.24%
  Val Loss:   2.4470
  Val Acc:    59.17%
  Val Top-5:  88.50%
  Val F1 (M): 57.90%
  Saved best model to outputs/vgg19_transfer/best_model.pth

Epoch 23/30
  Train Loss: 0.0207
  Train Acc:  99.46%
  Val Loss:   2.4823
  Val Acc:    58.50%
  Val Top-5:  87.67%
  Val F1 (M): 57.15%

Epoch 24/30
  Train Loss: 0.0166
  Train Acc:  99.48%
  Val Loss:   2.4659
  Val Acc:    58.50%
  Val Top-5:  87.50%
  Val F1 (M): 56.51%

Epoch 25/30
  Train Loss: 0.0168
  Train Acc:  99.37%
  Val Loss:   2.4774
  Val Acc:    60.00%
  Val Top-5:  89.17%
  Val F1 (M): 58.40%
  Saved best model to outputs/vgg19_transfer/best_model.pth

Epoch 26/30
  Train Loss: 0.0108
  Train Acc:  99.70%
  Val Loss:   2.5372
  Val Acc:    59.17%
  Val Top-5:  89.17%
  Val F1 (M): 57.53%

Epoch 27/30
  Train Loss: 0.0133
  Train Acc:  99.61%
  Val Loss:   2.5204
  Val Acc:    59.67%
  Val Top-5:  88.00%
  Val F1 (M): 58.05%

Epoch 28/30
  Train Loss: 0.0101
  Train Acc:  99.76%
  Val Loss:   2.4913
  Val Acc:    59.00%
  Val Top-5:  88.83%
  Val F1 (M): 57.31%

Epoch 29/30
  Train Loss: 0.0068
  Train Acc:  99.83%
  Val Loss:   2.5174
  Val Acc:    58.17%
  Val Top-5:  88.50%
  Val F1 (M): 56.41%

Epoch 30/30
  Train Loss: 0.0080
  Train Acc:  99.81%
  Val Loss:   2.4737
  Val Acc:    59.17%
  Val Top-5:  89.33%
  Val F1 (M): 57.30%
  Test Acc:   64.14%
  Test Top-5: 87.95%
  Test F1 (M):64.19%

============================================================
Training completed in 843.55s
Best validation accuracy: 60.00%
============================================================


Results saved to: outputs/vgg19_transfer
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: vgg19_logit_kd
Student Architecture: vgg19
Distillation Type: logit
Device: cuda
Seed: 42

Configuration saved to: outputs/vgg19_logit_kd/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: vgg19
  Total parameters: 140,400,648
  Trainable parameters: 140,400,648

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01

Setting up knowledge distillation...
  Teacher: openai/clip-vit-base-patch32
  Distillation type: logit
  Alpha CE: 1.0
  Alpha KD: 1.0


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 7.0036
  Train Acc:  32.72%
  CE Loss:    3.5044
  KD Loss:    3.4992
  Val Loss:   2.6691
  Val Acc:    27.17%
  Val Top-5:  65.33%
  Val F1 (M): 21.59%
  Saved best model to outputs/vgg19_logit_kd/best_model.pth

Epoch 2/30
  Train Loss: 4.7947
  Train Acc:  52.27%
  CE Loss:    2.3309
  KD Loss:    2.4638
  Val Loss:   2.0628
  Val Acc:    40.50%
  Val Top-5:  80.33%
  Val F1 (M): 35.70%
  Saved best model to outputs/vgg19_logit_kd/best_model.pth

Epoch 3/30
  Train Loss: 3.9627
  Train Acc:  65.55%
  CE Loss:    1.8014
  KD Loss:    2.1612
  Val Loss:   1.8182
  Val Acc:    47.83%
  Val Top-5:  83.33%
  Val F1 (M): 44.05%
  Saved best model to outputs/vgg19_logit_kd/best_model.pth

Epoch 4/30
  Train Loss: 3.4204
  Train Acc:  74.44%
  CE Loss:    1.4474
  KD Loss:    1.9729
  Val Loss:   1.5472
  Val Acc:    56.00%
  Val Top-5:  87.00%
  Val F1 (M): 52.75%
  Saved best model to outputs/vgg19_logit_kd/best_model.pth

Epoch 5/30
  Train Loss: 3.0610
  Train Acc:  82.16%
  CE Loss:    1.1712
  KD Loss:    1.8897
  Val Loss:   1.5776
  Val Acc:    52.83%
  Val Top-5:  86.17%
  Val F1 (M): 50.30%

Epoch 6/30
  Train Loss: 2.8456
  Train Acc:  85.97%
  CE Loss:    1.0225
  KD Loss:    1.8231
  Val Loss:   1.4611
  Val Acc:    56.83%
  Val Top-5:  89.33%
  Val F1 (M): 54.23%
  Saved best model to outputs/vgg19_logit_kd/best_model.pth

Epoch 7/30
  Train Loss: 2.6221
  Train Acc:  89.99%
  CE Loss:    0.8679
  KD Loss:    1.7541
  Val Loss:   1.4604
  Val Acc:    58.50%
  Val Top-5:  88.67%
  Val F1 (M): 56.16%
  Saved best model to outputs/vgg19_logit_kd/best_model.pth

Epoch 8/30
  Train Loss: 2.4385
  Train Acc:  92.30%
  CE Loss:    0.7559
  KD Loss:    1.6826
  Val Loss:   1.3876
  Val Acc:    63.17%
  Val Top-5:  89.50%
  Val F1 (M): 62.08%
  Saved best model to outputs/vgg19_logit_kd/best_model.pth

Epoch 9/30
  Train Loss: 2.2290
  Train Acc:  94.83%
  CE Loss:    0.6331
  KD Loss:    1.5959
  Val Loss:   1.3290
  Val Acc:    64.67%
  Val Top-5:  90.33%
  Val F1 (M): 62.65%
  Saved best model to outputs/vgg19_logit_kd/best_model.pth

Epoch 10/30
  Train Loss: 2.0928
  Train Acc:  96.58%
  CE Loss:    0.5482
  KD Loss:    1.5446
  Val Loss:   1.2977
  Val Acc:    62.33%
  Val Top-5:  91.33%
  Val F1 (M): 60.86%

Epoch 11/30
  Train Loss: 1.9489
  Train Acc:  97.34%
  CE Loss:    0.4709
  KD Loss:    1.4779
  Val Loss:   1.3220
  Val Acc:    64.83%
  Val Top-5:  90.33%
  Val F1 (M): 63.09%
  Saved best model to outputs/vgg19_logit_kd/best_model.pth

Epoch 12/30
  Train Loss: 1.8523
  Train Acc:  98.21%
  CE Loss:    0.4160
  KD Loss:    1.4363
  Val Loss:   1.2541
  Val Acc:    67.67%
  Val Top-5:  90.50%
  Val F1 (M): 66.51%
  Saved best model to outputs/vgg19_logit_kd/best_model.pth

Epoch 13/30
  Train Loss: 1.7612
  Train Acc:  98.60%
  CE Loss:    0.3756
  KD Loss:    1.3856
  Val Loss:   1.2501
  Val Acc:    66.00%
  Val Top-5:  91.17%
  Val F1 (M): 64.58%

Epoch 14/30
  Train Loss: 1.6735
  Train Acc:  99.14%
  CE Loss:    0.3404
  KD Loss:    1.3330
  Val Loss:   1.2030
  Val Acc:    66.83%
  Val Top-5:  90.17%
  Val F1 (M): 65.98%

Epoch 15/30
  Train Loss: 1.6337
  Train Acc:  99.39%
  CE Loss:    0.3240
  KD Loss:    1.3097
  Val Loss:   1.2364
  Val Acc:    66.00%
  Val Top-5:  90.67%
  Val F1 (M): 65.03%

Epoch 16/30
  Train Loss: 1.5422
  Train Acc:  99.57%
  CE Loss:    0.2810
  KD Loss:    1.2612
  Val Loss:   1.1961
  Val Acc:    67.33%
  Val Top-5:  93.17%
  Val F1 (M): 66.44%

Epoch 17/30
  Train Loss: 1.4580
  Train Acc:  99.68%
  CE Loss:    0.2560
  KD Loss:    1.2020
  Val Loss:   1.2015
  Val Acc:    67.83%
  Val Top-5:  92.17%
  Val F1 (M): 65.97%
  Saved best model to outputs/vgg19_logit_kd/best_model.pth

Epoch 18/30
  Train Loss: 1.4274
  Train Acc:  99.85%
  CE Loss:    0.2441
  KD Loss:    1.1834
  Val Loss:   1.2070
  Val Acc:    67.17%
  Val Top-5:  91.67%
  Val F1 (M): 65.97%

Epoch 19/30
  Train Loss: 1.3767
  Train Acc:  99.78%
  CE Loss:    0.2287
  KD Loss:    1.1480
  Val Loss:   1.2106
  Val Acc:    67.67%
  Val Top-5:  92.00%
  Val F1 (M): 66.51%

Epoch 20/30
  Train Loss: 1.3469
  Train Acc:  99.80%
  CE Loss:    0.2186
  KD Loss:    1.1283
  Val Loss:   1.1948
  Val Acc:    69.50%
  Val Top-5:  92.50%
  Val F1 (M): 68.48%
  Saved best model to outputs/vgg19_logit_kd/best_model.pth

Epoch 21/30
  Train Loss: 1.3077
  Train Acc:  99.78%
  CE Loss:    0.2149
  KD Loss:    1.0928
  Val Loss:   1.1815
  Val Acc:    68.33%
  Val Top-5:  92.17%
  Val F1 (M): 66.80%

Epoch 22/30
  Train Loss: 1.2604
  Train Acc:  99.80%
  CE Loss:    0.2033
  KD Loss:    1.0571
  Val Loss:   1.1744
  Val Acc:    68.33%
  Val Top-5:  91.67%
  Val F1 (M): 67.19%

Epoch 23/30
  Train Loss: 1.2411
  Train Acc:  99.78%
  CE Loss:    0.1997
  KD Loss:    1.0413
  Val Loss:   1.1895
  Val Acc:    69.17%
  Val Top-5:  92.00%
  Val F1 (M): 68.06%

Epoch 24/30
  Train Loss: 1.2142
  Train Acc:  99.87%
  CE Loss:    0.1893
  KD Loss:    1.0249
  Val Loss:   1.1620
  Val Acc:    70.00%
  Val Top-5:  92.50%
  Val F1 (M): 69.27%
  Saved best model to outputs/vgg19_logit_kd/best_model.pth

Epoch 25/30
  Train Loss: 1.1800
  Train Acc:  99.87%
  CE Loss:    0.1834
  KD Loss:    0.9966
  Val Loss:   1.1606
  Val Acc:    70.00%
  Val Top-5:  92.33%
  Val F1 (M): 69.02%

Epoch 26/30
  Train Loss: 1.1813
  Train Acc:  99.87%
  CE Loss:    0.1821
  KD Loss:    0.9992
  Val Loss:   1.1510
  Val Acc:    70.00%
  Val Top-5:  92.33%
  Val F1 (M): 68.95%

Epoch 27/30
  Train Loss: 1.1558
  Train Acc:  99.81%
  CE Loss:    0.1802
  KD Loss:    0.9756
  Val Loss:   1.1743
  Val Acc:    69.17%
  Val Top-5:  92.17%
  Val F1 (M): 68.02%

Epoch 28/30
  Train Loss: 1.1559
  Train Acc:  99.80%
  CE Loss:    0.1751
  KD Loss:    0.9809
  Val Loss:   1.1653
  Val Acc:    69.83%
  Val Top-5:  92.17%
  Val F1 (M): 68.80%

Epoch 29/30
  Train Loss: 1.1523
  Train Acc:  99.83%
  CE Loss:    0.1783
  KD Loss:    0.9740
  Val Loss:   1.1630
  Val Acc:    70.17%
  Val Top-5:  92.33%
  Val F1 (M): 69.17%
  Saved best model to outputs/vgg19_logit_kd/best_model.pth

Epoch 30/30
  Train Loss: 1.1415
  Train Acc:  99.87%
  CE Loss:    0.1772
  KD Loss:    0.9643
  Val Loss:   1.1675
  Val Acc:    69.67%
  Val Top-5:  92.00%
  Val F1 (M): 68.66%
  Test Acc:   72.75%
  Test Top-5: 92.49%
  Test F1 (M):72.90%

============================================================
Training completed in 1136.38s
Best validation accuracy: 70.17%
============================================================


Results saved to: outputs/vgg19_logit_kd
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: vgg19_attention_kd
Student Architecture: vgg19
Distillation Type: attention
Device: cuda
Seed: 42

Configuration saved to: outputs/vgg19_attention_kd/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: vgg19
  Total parameters: 140,400,648
  Trainable parameters: 140,400,648

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01

Setting up knowledge distillation...
  Teacher: openai/clip-vit-base-patch32
  Distillation type: attention
  Alpha CE: 1.0
  Alpha KD: 0.0
  Alpha Attention: 0.5
  Attention loss: mse


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 4.3968
  Train Acc:  17.22%
  CE Loss:    4.3968
  KD Loss:    6.3448
  Val Loss:   3.6105
  Val Acc:    15.17%
  Val Top-5:  41.83%
  Val F1 (M): 9.87%
  Saved best model to outputs/vgg19_attention_kd/best_model.pth

Epoch 2/30
  Train Loss: 3.0475
  Train Acc:  37.89%
  CE Loss:    3.0475
  KD Loss:    5.3932
  Val Loss:   2.7805
  Val Acc:    24.33%
  Val Top-5:  63.50%
  Val F1 (M): 19.18%
  Saved best model to outputs/vgg19_attention_kd/best_model.pth

Epoch 3/30
  Train Loss: 2.3867
  Train Acc:  52.96%
  CE Loss:    2.3867
  KD Loss:    5.8742
  Val Loss:   2.5802
  Val Acc:    33.17%
  Val Top-5:  69.50%
  Val F1 (M): 29.89%
  Saved best model to outputs/vgg19_attention_kd/best_model.pth

Epoch 4/30
  Train Loss: 1.8820
  Train Acc:  65.62%
  CE Loss:    1.8820
  KD Loss:    6.9417
  Val Loss:   2.3067
  Val Acc:    38.67%
  Val Top-5:  75.00%
  Val F1 (M): 36.03%
  Saved best model to outputs/vgg19_attention_kd/best_model.pth

Epoch 5/30
  Train Loss: 1.5379
  Train Acc:  74.40%
  CE Loss:    1.5379
  KD Loss:    7.8774
  Val Loss:   2.0769
  Val Acc:    43.67%
  Val Top-5:  79.00%
  Val F1 (M): 40.21%
  Saved best model to outputs/vgg19_attention_kd/best_model.pth

Epoch 6/30
  Train Loss: 1.2361
  Train Acc:  81.51%
  CE Loss:    1.2361
  KD Loss:    9.5104
  Val Loss:   2.1508
  Val Acc:    45.50%
  Val Top-5:  79.17%
  Val F1 (M): 43.30%
  Saved best model to outputs/vgg19_attention_kd/best_model.pth

Epoch 7/30
  Train Loss: 1.0257
  Train Acc:  86.31%
  CE Loss:    1.0257
  KD Loss:    10.8274
  Val Loss:   2.0866
  Val Acc:    49.00%
  Val Top-5:  81.33%
  Val F1 (M): 46.17%
  Saved best model to outputs/vgg19_attention_kd/best_model.pth

Epoch 8/30
  Train Loss: 0.8599
  Train Acc:  89.69%
  CE Loss:    0.8599
  KD Loss:    12.0096
  Val Loss:   2.0261
  Val Acc:    49.50%
  Val Top-5:  82.67%
  Val F1 (M): 46.99%
  Saved best model to outputs/vgg19_attention_kd/best_model.pth

Epoch 9/30
  Train Loss: 0.6967
  Train Acc:  92.84%
  CE Loss:    0.6967
  KD Loss:    13.7576
  Val Loss:   2.1310
  Val Acc:    51.83%
  Val Top-5:  82.00%
  Val F1 (M): 50.42%
  Saved best model to outputs/vgg19_attention_kd/best_model.pth

Epoch 10/30
  Train Loss: 0.5461
  Train Acc:  95.03%
  CE Loss:    0.5461
  KD Loss:    16.2428
  Val Loss:   2.0868
  Val Acc:    55.00%
  Val Top-5:  82.50%
  Val F1 (M): 53.84%
  Saved best model to outputs/vgg19_attention_kd/best_model.pth

Epoch 11/30
  Train Loss: 0.4690
  Train Acc:  96.65%
  CE Loss:    0.4690
  KD Loss:    17.2997
  Val Loss:   2.0416
  Val Acc:    51.00%
  Val Top-5:  81.83%
  Val F1 (M): 49.75%

Epoch 12/30
  Train Loss: 0.3652
  Train Acc:  97.62%
  CE Loss:    0.3652
  KD Loss:    19.5107
  Val Loss:   2.2558
  Val Acc:    51.83%
  Val Top-5:  84.00%
  Val F1 (M): 49.89%

Epoch 13/30
  Train Loss: 0.3225
  Train Acc:  98.14%
  CE Loss:    0.3225
  KD Loss:    21.2717
  Val Loss:   2.1200
  Val Acc:    54.50%
  Val Top-5:  84.00%
  Val F1 (M): 52.36%

Epoch 14/30
  Train Loss: 0.2488
  Train Acc:  99.03%
  CE Loss:    0.2488
  KD Loss:    23.5295
  Val Loss:   2.0792
  Val Acc:    53.17%
  Val Top-5:  84.17%
  Val F1 (M): 51.69%

Epoch 15/30
  Train Loss: 0.1809
  Train Acc:  99.31%
  CE Loss:    0.1809
  KD Loss:    25.8602
  Val Loss:   2.1567
  Val Acc:    56.33%
  Val Top-5:  85.00%
  Val F1 (M): 54.99%
  Saved best model to outputs/vgg19_attention_kd/best_model.pth

Epoch 16/30
  Train Loss: 0.1356
  Train Acc:  99.57%
  CE Loss:    0.1356
  KD Loss:    30.6832
  Val Loss:   2.0672
  Val Acc:    57.00%
  Val Top-5:  86.00%
  Val F1 (M): 55.97%
  Saved best model to outputs/vgg19_attention_kd/best_model.pth

Epoch 17/30
  Train Loss: 0.1229
  Train Acc:  99.67%
  CE Loss:    0.1229
  KD Loss:    30.3063
  Val Loss:   2.1652
  Val Acc:    56.00%
  Val Top-5:  86.00%
  Val F1 (M): 54.96%

Epoch 18/30
  Train Loss: 0.0825
  Train Acc:  99.72%
  CE Loss:    0.0825
  KD Loss:    33.5237
  Val Loss:   2.3092
  Val Acc:    57.67%
  Val Top-5:  84.83%
  Val F1 (M): 56.54%
  Saved best model to outputs/vgg19_attention_kd/best_model.pth

Epoch 19/30
  Train Loss: 0.0650
  Train Acc:  99.85%
  CE Loss:    0.0650
  KD Loss:    38.4805
  Val Loss:   2.4130
  Val Acc:    57.67%
  Val Top-5:  85.17%
  Val F1 (M): 56.28%

Epoch 20/30
  Train Loss: 0.0584
  Train Acc:  99.89%
  CE Loss:    0.0584
  KD Loss:    40.0367
  Val Loss:   2.3088
  Val Acc:    56.67%
  Val Top-5:  87.33%
  Val F1 (M): 55.35%

Epoch 21/30
  Train Loss: 0.0417
  Train Acc:  99.89%
  CE Loss:    0.0417
  KD Loss:    41.5664
  Val Loss:   2.1620
  Val Acc:    59.50%
  Val Top-5:  88.00%
  Val F1 (M): 58.90%
  Saved best model to outputs/vgg19_attention_kd/best_model.pth

Epoch 22/30
  Train Loss: 0.0353
  Train Acc:  99.83%
  CE Loss:    0.0353
  KD Loss:    43.6180
  Val Loss:   2.2663
  Val Acc:    58.50%
  Val Top-5:  86.83%
  Val F1 (M): 57.78%

Epoch 23/30
  Train Loss: 0.0228
  Train Acc:  99.94%
  CE Loss:    0.0228
  KD Loss:    44.9570
  Val Loss:   2.2248
  Val Acc:    60.33%
  Val Top-5:  86.83%
  Val F1 (M): 59.68%
  Saved best model to outputs/vgg19_attention_kd/best_model.pth

Epoch 24/30
  Train Loss: 0.0199
  Train Acc:  99.93%
  CE Loss:    0.0199
  KD Loss:    46.6309
  Val Loss:   2.2625
  Val Acc:    59.33%
  Val Top-5:  86.67%
  Val F1 (M): 58.36%

Epoch 25/30
  Train Loss: 0.0150
  Train Acc:  99.93%
  CE Loss:    0.0150
  KD Loss:    49.1167
  Val Loss:   2.2319
  Val Acc:    61.50%
  Val Top-5:  87.67%
  Val F1 (M): 60.42%
  Saved best model to outputs/vgg19_attention_kd/best_model.pth

Epoch 26/30
  Train Loss: 0.0129
  Train Acc:  99.81%
  CE Loss:    0.0129
  KD Loss:    51.2155
  Val Loss:   2.2943
  Val Acc:    59.50%
  Val Top-5:  87.67%
  Val F1 (M): 58.81%

Epoch 27/30
  Train Loss: 0.0117
  Train Acc:  99.83%
  CE Loss:    0.0117
  KD Loss:    51.8968
  Val Loss:   2.2363
  Val Acc:    60.50%
  Val Top-5:  87.17%
  Val F1 (M): 60.06%

Epoch 28/30
  Train Loss: 0.0085
  Train Acc:  99.85%
  CE Loss:    0.0085
  KD Loss:    52.8685
  Val Loss:   2.2900
  Val Acc:    60.50%
  Val Top-5:  87.17%
  Val F1 (M): 59.74%

Epoch 29/30
  Train Loss: 0.0081
  Train Acc:  99.87%
  CE Loss:    0.0081
  KD Loss:    53.4295
  Val Loss:   2.2860
  Val Acc:    61.50%
  Val Top-5:  86.33%
  Val F1 (M): 60.73%

Epoch 30/30
  Train Loss: 0.0093
  Train Acc:  99.83%
  CE Loss:    0.0093
  KD Loss:    54.0738
  Val Loss:   2.3079
  Val Acc:    60.00%
  Val Top-5:  86.67%
  Val F1 (M): 59.68%
  Test Acc:   62.41%
  Test Top-5: 87.88%
  Test F1 (M):62.66%

============================================================
Training completed in 1435.77s
Best validation accuracy: 61.50%
============================================================


Results saved to: outputs/vgg19_attention_kd
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: vgg19_combined_kd
Student Architecture: vgg19
Distillation Type: combined
Device: cuda
Seed: 42

Configuration saved to: outputs/vgg19_combined_kd/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: vgg19
  Total parameters: 140,400,648
  Trainable parameters: 140,400,648

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01

Setting up knowledge distillation...
  Teacher: openai/clip-vit-base-patch32
  Distillation type: combined
  Alpha CE: 1.0
  Alpha KD: 1.0
  Alpha Attention: 0.1
  Attention loss: mse


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 7.0036
  Train Acc:  32.72%
  CE Loss:    3.5044
  KD Loss:    3.4992
  Val Loss:   2.6579
  Val Acc:    26.50%
  Val Top-5:  66.00%
  Val F1 (M): 21.09%
  Saved best model to outputs/vgg19_combined_kd/best_model.pth

Epoch 2/30
  Train Loss: 4.7947
  Train Acc:  52.27%
  CE Loss:    2.3309
  KD Loss:    2.4638
  Val Loss:   2.0458
  Val Acc:    40.67%
  Val Top-5:  80.33%
  Val F1 (M): 35.71%
  Saved best model to outputs/vgg19_combined_kd/best_model.pth

Epoch 3/30
  Train Loss: 3.9627
  Train Acc:  65.55%
  CE Loss:    1.8014
  KD Loss:    2.1612
  Val Loss:   1.7979
  Val Acc:    49.17%
  Val Top-5:  84.00%
  Val F1 (M): 45.49%
  Saved best model to outputs/vgg19_combined_kd/best_model.pth

Epoch 4/30
  Train Loss: 3.4204
  Train Acc:  74.44%
  CE Loss:    1.4474
  KD Loss:    1.9729
  Val Loss:   1.5425
  Val Acc:    56.67%
  Val Top-5:  87.33%
  Val F1 (M): 53.66%
  Saved best model to outputs/vgg19_combined_kd/best_model.pth

Epoch 5/30
  Train Loss: 3.0610
  Train Acc:  82.16%
  CE Loss:    1.1712
  KD Loss:    1.8897
  Val Loss:   1.5679
  Val Acc:    52.17%
  Val Top-5:  86.33%
  Val F1 (M): 49.72%

Epoch 6/30
  Train Loss: 2.8456
  Train Acc:  85.97%
  CE Loss:    1.0225
  KD Loss:    1.8231
  Val Loss:   1.4482
  Val Acc:    57.50%
  Val Top-5:  89.17%
  Val F1 (M): 55.12%
  Saved best model to outputs/vgg19_combined_kd/best_model.pth

Epoch 7/30
  Train Loss: 2.6221
  Train Acc:  89.99%
  CE Loss:    0.8679
  KD Loss:    1.7541
  Val Loss:   1.4575
  Val Acc:    58.67%
  Val Top-5:  88.83%
  Val F1 (M): 56.31%
  Saved best model to outputs/vgg19_combined_kd/best_model.pth

Epoch 8/30
  Train Loss: 2.4385
  Train Acc:  92.30%
  CE Loss:    0.7559
  KD Loss:    1.6826
  Val Loss:   1.3782
  Val Acc:    63.50%
  Val Top-5:  89.33%
  Val F1 (M): 62.56%
  Saved best model to outputs/vgg19_combined_kd/best_model.pth

Epoch 9/30
  Train Loss: 2.2290
  Train Acc:  94.83%
  CE Loss:    0.6331
  KD Loss:    1.5959
  Val Loss:   1.3229
  Val Acc:    65.17%
  Val Top-5:  90.83%
  Val F1 (M): 63.17%
  Saved best model to outputs/vgg19_combined_kd/best_model.pth

Epoch 10/30
  Train Loss: 2.0928
  Train Acc:  96.58%
  CE Loss:    0.5482
  KD Loss:    1.5446
  Val Loss:   1.2944
  Val Acc:    62.67%
  Val Top-5:  91.50%
  Val F1 (M): 61.30%

Epoch 11/30
  Train Loss: 1.9489
  Train Acc:  97.34%
  CE Loss:    0.4709
  KD Loss:    1.4779
  Val Loss:   1.3216
  Val Acc:    64.50%
  Val Top-5:  90.17%
  Val F1 (M): 62.61%

Epoch 12/30
  Train Loss: 1.8523
  Train Acc:  98.21%
  CE Loss:    0.4160
  KD Loss:    1.4363
  Val Loss:   1.2533
  Val Acc:    67.50%
  Val Top-5:  90.67%
  Val F1 (M): 66.50%
  Saved best model to outputs/vgg19_combined_kd/best_model.pth

Epoch 13/30
  Train Loss: 1.7612
  Train Acc:  98.60%
  CE Loss:    0.3756
  KD Loss:    1.3856
  Val Loss:   1.2462
  Val Acc:    66.33%
  Val Top-5:  91.50%
  Val F1 (M): 65.09%

Epoch 14/30
  Train Loss: 1.6735
  Train Acc:  99.14%
  CE Loss:    0.3404
  KD Loss:    1.3330
  Val Loss:   1.2027
  Val Acc:    66.67%
  Val Top-5:  90.17%
  Val F1 (M): 65.79%

Epoch 15/30
  Train Loss: 1.6337
  Train Acc:  99.39%
  CE Loss:    0.3240
  KD Loss:    1.3097
  Val Loss:   1.2366
  Val Acc:    66.17%
  Val Top-5:  90.67%
  Val F1 (M): 65.27%

Epoch 16/30
  Train Loss: 1.5422
  Train Acc:  99.57%
  CE Loss:    0.2810
  KD Loss:    1.2612
  Val Loss:   1.1954
  Val Acc:    67.17%
  Val Top-5:  92.83%
  Val F1 (M): 66.26%

Epoch 17/30
  Train Loss: 1.4580
  Train Acc:  99.68%
  CE Loss:    0.2560
  KD Loss:    1.2020
  Val Loss:   1.1981
  Val Acc:    67.50%
  Val Top-5:  92.17%
  Val F1 (M): 65.79%

Epoch 18/30
  Train Loss: 1.4274
  Train Acc:  99.85%
  CE Loss:    0.2441
  KD Loss:    1.1834
  Val Loss:   1.2062
  Val Acc:    67.17%
  Val Top-5:  91.50%
  Val F1 (M): 65.73%

Epoch 19/30
  Train Loss: 1.3767
  Train Acc:  99.78%
  CE Loss:    0.2287
  KD Loss:    1.1480
  Val Loss:   1.2101
  Val Acc:    68.17%
  Val Top-5:  92.17%
  Val F1 (M): 67.11%
  Saved best model to outputs/vgg19_combined_kd/best_model.pth

Epoch 20/30
  Train Loss: 1.3469
  Train Acc:  99.80%
  CE Loss:    0.2186
  KD Loss:    1.1283
  Val Loss:   1.1964
  Val Acc:    69.00%
  Val Top-5:  92.83%
  Val F1 (M): 67.85%
  Saved best model to outputs/vgg19_combined_kd/best_model.pth

Epoch 21/30
  Train Loss: 1.3077
  Train Acc:  99.78%
  CE Loss:    0.2149
  KD Loss:    1.0928
  Val Loss:   1.1833
  Val Acc:    68.33%
  Val Top-5:  92.17%
  Val F1 (M): 66.82%

Epoch 22/30
  Train Loss: 1.2604
  Train Acc:  99.80%
  CE Loss:    0.2033
  KD Loss:    1.0571
  Val Loss:   1.1769
  Val Acc:    68.83%
  Val Top-5:  91.83%
  Val F1 (M): 67.61%

Epoch 23/30
  Train Loss: 1.2411
  Train Acc:  99.78%
  CE Loss:    0.1997
  KD Loss:    1.0413
  Val Loss:   1.1933
  Val Acc:    69.50%
  Val Top-5:  91.83%
  Val F1 (M): 68.39%
  Saved best model to outputs/vgg19_combined_kd/best_model.pth

Epoch 24/30
  Train Loss: 1.2142
  Train Acc:  99.87%
  CE Loss:    0.1893
  KD Loss:    1.0249
  Val Loss:   1.1628
  Val Acc:    69.83%
  Val Top-5:  92.67%
  Val F1 (M): 68.89%
  Saved best model to outputs/vgg19_combined_kd/best_model.pth

Epoch 25/30
  Train Loss: 1.1800
  Train Acc:  99.87%
  CE Loss:    0.1834
  KD Loss:    0.9966
  Val Loss:   1.1621
  Val Acc:    69.83%
  Val Top-5:  92.33%
  Val F1 (M): 68.92%

Epoch 26/30
  Train Loss: 1.1813
  Train Acc:  99.87%
  CE Loss:    0.1821
  KD Loss:    0.9992
  Val Loss:   1.1510
  Val Acc:    70.17%
  Val Top-5:  92.33%
  Val F1 (M): 69.13%
  Saved best model to outputs/vgg19_combined_kd/best_model.pth

Epoch 27/30
  Train Loss: 1.1558
  Train Acc:  99.81%
  CE Loss:    0.1802
  KD Loss:    0.9756
  Val Loss:   1.1794
  Val Acc:    69.00%
  Val Top-5:  92.17%
  Val F1 (M): 67.74%

Epoch 28/30
  Train Loss: 1.1559
  Train Acc:  99.80%
  CE Loss:    0.1751
  KD Loss:    0.9809
  Val Loss:   1.1678
  Val Acc:    69.83%
  Val Top-5:  92.33%
  Val F1 (M): 68.76%

Epoch 29/30
  Train Loss: 1.1523
  Train Acc:  99.83%
  CE Loss:    0.1783
  KD Loss:    0.9740
  Val Loss:   1.1649
  Val Acc:    69.83%
  Val Top-5:  92.33%
  Val F1 (M): 68.75%

Epoch 30/30
  Train Loss: 1.1415
  Train Acc:  99.87%
  CE Loss:    0.1772
  KD Loss:    0.9643
  Val Loss:   1.1711
  Val Acc:    69.83%
  Val Top-5:  92.00%
  Val F1 (M): 68.83%
  Test Acc:   72.73%
  Test Top-5: 92.47%
  Test F1 (M):72.90%

============================================================
Training completed in 1432.41s
Best validation accuracy: 70.17%
============================================================


Results saved to: outputs/vgg19_combined_kd
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: mobilenetv3_small_scratch
Student Architecture: mobilenetv3_small
Distillation Type: none
Device: cuda
Seed: 42

Configuration saved to: outputs/mobilenetv3_small_scratch/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: mobilenetv3_small
  Total parameters: 1,722,856
  Trainable parameters: 1,722,856

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 5.2953
  Train Acc:  0.60%
  Val Loss:   5.1740
  Val Acc:    1.33%
  Val Top-5:  5.00%
  Val F1 (M): 0.21%
  Saved best model to outputs/mobilenetv3_small_scratch/best_model.pth

Epoch 2/30
  Train Loss: 5.1302
  Train Acc:  1.02%
  Val Loss:   4.9944
  Val Acc:    1.33%
  Val Top-5:  8.67%
  Val F1 (M): 0.66%

Epoch 3/30
  Train Loss: 4.9767
  Train Acc:  2.01%
  Val Loss:   4.8243
  Val Acc:    1.83%
  Val Top-5:  10.00%
  Val F1 (M): 0.81%
  Saved best model to outputs/mobilenetv3_small_scratch/best_model.pth

Epoch 4/30
  Train Loss: 4.8187
  Train Acc:  2.79%
  Val Loss:   4.6661
  Val Acc:    3.00%
  Val Top-5:  13.67%
  Val F1 (M): 1.25%
  Saved best model to outputs/mobilenetv3_small_scratch/best_model.pth

Epoch 5/30
  Train Loss: 4.6597
  Train Acc:  3.81%
  Val Loss:   4.4977
  Val Acc:    4.67%
  Val Top-5:  20.00%
  Val F1 (M): 2.22%
  Saved best model to outputs/mobilenetv3_small_scratch/best_model.pth

Epoch 6/30
  Train Loss: 4.5178
  Train Acc:  4.39%
  Val Loss:   4.3911
  Val Acc:    5.00%
  Val Top-5:  23.17%
  Val F1 (M): 2.68%
  Saved best model to outputs/mobilenetv3_small_scratch/best_model.pth

Epoch 7/30
  Train Loss: 4.3635
  Train Acc:  6.19%
  Val Loss:   4.3182
  Val Acc:    5.67%
  Val Top-5:  24.33%
  Val F1 (M): 3.48%
  Saved best model to outputs/mobilenetv3_small_scratch/best_model.pth

Epoch 8/30
  Train Loss: 4.2714
  Train Acc:  7.05%
  Val Loss:   4.1625
  Val Acc:    7.83%
  Val Top-5:  28.33%
  Val F1 (M): 5.37%
  Saved best model to outputs/mobilenetv3_small_scratch/best_model.pth

Epoch 9/30
  Train Loss: 4.1339
  Train Acc:  8.91%
  Val Loss:   4.0967
  Val Acc:    9.33%
  Val Top-5:  29.67%
  Val F1 (M): 6.29%
  Saved best model to outputs/mobilenetv3_small_scratch/best_model.pth

Epoch 10/30
  Train Loss: 4.0092
  Train Acc:  10.27%
  Val Loss:   4.0393
  Val Acc:    11.00%
  Val Top-5:  31.83%
  Val F1 (M): 8.11%
  Saved best model to outputs/mobilenetv3_small_scratch/best_model.pth

Epoch 11/30
  Train Loss: 3.9209
  Train Acc:  10.45%
  Val Loss:   3.9852
  Val Acc:    12.67%
  Val Top-5:  32.83%
  Val F1 (M): 9.35%
  Saved best model to outputs/mobilenetv3_small_scratch/best_model.pth

Epoch 12/30
  Train Loss: 3.8225
  Train Acc:  12.91%
  Val Loss:   3.9250
  Val Acc:    12.17%
  Val Top-5:  35.00%
  Val F1 (M): 8.72%

Epoch 13/30
  Train Loss: 3.7259
  Train Acc:  13.47%
  Val Loss:   3.9142
  Val Acc:    12.33%
  Val Top-5:  34.50%
  Val F1 (M): 9.38%

Epoch 14/30
  Train Loss: 3.6458
  Train Acc:  15.14%
  Val Loss:   3.8424
  Val Acc:    15.83%
  Val Top-5:  37.17%
  Val F1 (M): 12.90%
  Saved best model to outputs/mobilenetv3_small_scratch/best_model.pth

Epoch 15/30
  Train Loss: 3.5426
  Train Acc:  16.87%
  Val Loss:   3.8346
  Val Acc:    15.00%
  Val Top-5:  39.67%
  Val F1 (M): 12.38%

Epoch 16/30
  Train Loss: 3.4545
  Train Acc:  18.19%
  Val Loss:   3.7892
  Val Acc:    14.17%
  Val Top-5:  40.00%
  Val F1 (M): 11.61%

Epoch 17/30
  Train Loss: 3.4100
  Train Acc:  18.94%
  Val Loss:   3.7428
  Val Acc:    16.17%
  Val Top-5:  39.00%
  Val F1 (M): 13.30%
  Saved best model to outputs/mobilenetv3_small_scratch/best_model.pth

Epoch 18/30
  Train Loss: 3.3199
  Train Acc:  20.44%
  Val Loss:   3.7132
  Val Acc:    17.00%
  Val Top-5:  42.67%
  Val F1 (M): 14.57%
  Saved best model to outputs/mobilenetv3_small_scratch/best_model.pth

Epoch 19/30
  Train Loss: 3.2790
  Train Acc:  21.73%
  Val Loss:   3.6814
  Val Acc:    18.00%
  Val Top-5:  41.50%
  Val F1 (M): 15.75%
  Saved best model to outputs/mobilenetv3_small_scratch/best_model.pth

Epoch 20/30
  Train Loss: 3.2123
  Train Acc:  21.95%
  Val Loss:   3.6695
  Val Acc:    16.83%
  Val Top-5:  42.67%
  Val F1 (M): 14.77%

Epoch 21/30
  Train Loss: 3.1592
  Train Acc:  22.69%
  Val Loss:   3.6663
  Val Acc:    18.33%
  Val Top-5:  42.50%
  Val F1 (M): 16.00%
  Saved best model to outputs/mobilenetv3_small_scratch/best_model.pth

Epoch 22/30
  Train Loss: 3.1127
  Train Acc:  23.08%
  Val Loss:   3.6757
  Val Acc:    18.17%
  Val Top-5:  42.67%
  Val F1 (M): 15.71%

Epoch 23/30
  Train Loss: 3.0738
  Train Acc:  25.56%
  Val Loss:   3.6816
  Val Acc:    17.83%
  Val Top-5:  42.17%
  Val F1 (M): 16.07%

Epoch 24/30
  Train Loss: 3.0621
  Train Acc:  24.80%
  Val Loss:   3.6804
  Val Acc:    18.17%
  Val Top-5:  41.83%
  Val F1 (M): 15.80%

Epoch 25/30
  Train Loss: 3.0125
  Train Acc:  25.99%
  Val Loss:   3.6673
  Val Acc:    19.33%
  Val Top-5:  44.17%
  Val F1 (M): 17.18%
  Saved best model to outputs/mobilenetv3_small_scratch/best_model.pth

Epoch 26/30
  Train Loss: 3.0019
  Train Acc:  25.99%
  Val Loss:   3.6465
  Val Acc:    18.00%
  Val Top-5:  44.17%
  Val F1 (M): 15.63%

Epoch 27/30
  Train Loss: 2.9678
  Train Acc:  26.47%
  Val Loss:   3.6709
  Val Acc:    19.33%
  Val Top-5:  43.67%
  Val F1 (M): 17.23%

Epoch 28/30
  Train Loss: 2.9705
  Train Acc:  27.18%
  Val Loss:   3.6613
  Val Acc:    19.17%
  Val Top-5:  43.50%
  Val F1 (M): 16.82%

Epoch 29/30
  Train Loss: 2.9537
  Train Acc:  26.71%
  Val Loss:   3.6563
  Val Acc:    20.50%
  Val Top-5:  43.67%
  Val F1 (M): 17.48%
  Saved best model to outputs/mobilenetv3_small_scratch/best_model.pth

Epoch 30/30
  Train Loss: 2.9738
  Train Acc:  26.21%
  Val Loss:   3.6379
  Val Acc:    19.33%
  Val Top-5:  44.33%
  Val F1 (M): 17.24%
  Test Acc:   17.95%
  Test Top-5: 43.11%
  Test F1 (M):16.93%

============================================================
Training completed in 322.18s
Best validation accuracy: 20.50%
============================================================


Results saved to: outputs/mobilenetv3_small_scratch
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: mobilenetv3_small_transfer
Student Architecture: mobilenetv3_small
Distillation Type: none
Device: cuda
Seed: 42

Configuration saved to: outputs/mobilenetv3_small_transfer/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: mobilenetv3_small
  Total parameters: 1,722,856
  Trainable parameters: 1,722,856

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 4.6353
  Train Acc:  6.29%
  Val Loss:   3.6509
  Val Acc:    13.67%
  Val Top-5:  40.17%
  Val F1 (M): 10.11%
  Saved best model to outputs/mobilenetv3_small_transfer/best_model.pth

Epoch 2/30
  Train Loss: 2.9834
  Train Acc:  26.60%
  Val Loss:   2.6755
  Val Acc:    32.83%
  Val Top-5:  62.83%
  Val F1 (M): 28.89%
  Saved best model to outputs/mobilenetv3_small_transfer/best_model.pth

Epoch 3/30
  Train Loss: 2.1544
  Train Acc:  42.09%
  Val Loss:   2.7385
  Val Acc:    32.50%
  Val Top-5:  63.50%
  Val F1 (M): 29.72%

Epoch 4/30
  Train Loss: 1.6369
  Train Acc:  54.63%
  Val Loss:   2.0409
  Val Acc:    48.00%
  Val Top-5:  78.33%
  Val F1 (M): 45.88%
  Saved best model to outputs/mobilenetv3_small_transfer/best_model.pth

Epoch 5/30
  Train Loss: 1.2802
  Train Acc:  63.97%
  Val Loss:   2.1317
  Val Acc:    44.00%
  Val Top-5:  73.67%
  Val F1 (M): 40.75%

Epoch 6/30
  Train Loss: 1.0105
  Train Acc:  70.13%
  Val Loss:   2.1445
  Val Acc:    45.33%
  Val Top-5:  77.83%
  Val F1 (M): 42.98%

Epoch 7/30
  Train Loss: 0.8238
  Train Acc:  75.26%
  Val Loss:   1.9914
  Val Acc:    50.17%
  Val Top-5:  80.00%
  Val F1 (M): 48.77%
  Saved best model to outputs/mobilenetv3_small_transfer/best_model.pth

Epoch 8/30
  Train Loss: 0.6225
  Train Acc:  81.06%
  Val Loss:   1.9015
  Val Acc:    53.00%
  Val Top-5:  82.83%
  Val F1 (M): 50.51%
  Saved best model to outputs/mobilenetv3_small_transfer/best_model.pth

Epoch 9/30
  Train Loss: 0.4734
  Train Acc:  85.77%
  Val Loss:   2.0010
  Val Acc:    51.50%
  Val Top-5:  80.83%
  Val F1 (M): 49.31%

Epoch 10/30
  Train Loss: 0.3808
  Train Acc:  89.10%
  Val Loss:   2.0099
  Val Acc:    53.17%
  Val Top-5:  81.00%
  Val F1 (M): 51.19%
  Saved best model to outputs/mobilenetv3_small_transfer/best_model.pth

Epoch 11/30
  Train Loss: 0.2831
  Train Acc:  91.63%
  Val Loss:   1.9441
  Val Acc:    54.17%
  Val Top-5:  81.33%
  Val F1 (M): 52.10%
  Saved best model to outputs/mobilenetv3_small_transfer/best_model.pth

Epoch 12/30
  Train Loss: 0.2396
  Train Acc:  93.19%
  Val Loss:   2.1225
  Val Acc:    54.33%
  Val Top-5:  81.50%
  Val F1 (M): 52.38%
  Saved best model to outputs/mobilenetv3_small_transfer/best_model.pth

Epoch 13/30
  Train Loss: 0.1862
  Train Acc:  95.18%
  Val Loss:   1.9308
  Val Acc:    58.00%
  Val Top-5:  84.00%
  Val F1 (M): 56.41%
  Saved best model to outputs/mobilenetv3_small_transfer/best_model.pth

Epoch 14/30
  Train Loss: 0.1409
  Train Acc:  96.48%
  Val Loss:   2.0008
  Val Acc:    57.67%
  Val Top-5:  82.67%
  Val F1 (M): 55.98%

Epoch 15/30
  Train Loss: 0.1089
  Train Acc:  97.23%
  Val Loss:   1.9250
  Val Acc:    59.83%
  Val Top-5:  84.17%
  Val F1 (M): 58.89%
  Saved best model to outputs/mobilenetv3_small_transfer/best_model.pth

Epoch 16/30
  Train Loss: 0.0906
  Train Acc:  97.77%
  Val Loss:   1.8916
  Val Acc:    56.83%
  Val Top-5:  86.00%
  Val F1 (M): 54.59%

Epoch 17/30
  Train Loss: 0.0746
  Train Acc:  98.33%
  Val Loss:   1.8956
  Val Acc:    60.33%
  Val Top-5:  83.67%
  Val F1 (M): 58.83%
  Saved best model to outputs/mobilenetv3_small_transfer/best_model.pth

Epoch 18/30
  Train Loss: 0.0457
  Train Acc:  99.14%
  Val Loss:   1.8459
  Val Acc:    60.67%
  Val Top-5:  86.17%
  Val F1 (M): 59.02%
  Saved best model to outputs/mobilenetv3_small_transfer/best_model.pth

Epoch 19/30
  Train Loss: 0.0370
  Train Acc:  99.31%
  Val Loss:   1.7732
  Val Acc:    62.67%
  Val Top-5:  86.50%
  Val F1 (M): 61.52%
  Saved best model to outputs/mobilenetv3_small_transfer/best_model.pth

Epoch 20/30
  Train Loss: 0.0322
  Train Acc:  99.40%
  Val Loss:   1.8148
  Val Acc:    61.00%
  Val Top-5:  86.17%
  Val F1 (M): 59.00%

Epoch 21/30
  Train Loss: 0.0283
  Train Acc:  99.59%
  Val Loss:   1.8044
  Val Acc:    62.83%
  Val Top-5:  86.83%
  Val F1 (M): 61.73%
  Saved best model to outputs/mobilenetv3_small_transfer/best_model.pth

Epoch 22/30
  Train Loss: 0.0258
  Train Acc:  99.57%
  Val Loss:   1.8282
  Val Acc:    63.50%
  Val Top-5:  86.00%
  Val F1 (M): 62.00%
  Saved best model to outputs/mobilenetv3_small_transfer/best_model.pth

Epoch 23/30
  Train Loss: 0.0222
  Train Acc:  99.57%
  Val Loss:   1.7926
  Val Acc:    63.17%
  Val Top-5:  87.33%
  Val F1 (M): 62.27%

Epoch 24/30
  Train Loss: 0.0216
  Train Acc:  99.59%
  Val Loss:   1.8129
  Val Acc:    64.33%
  Val Top-5:  86.33%
  Val F1 (M): 63.44%
  Saved best model to outputs/mobilenetv3_small_transfer/best_model.pth

Epoch 25/30
  Train Loss: 0.0154
  Train Acc:  99.81%
  Val Loss:   1.8095
  Val Acc:    64.50%
  Val Top-5:  86.67%
  Val F1 (M): 63.02%
  Saved best model to outputs/mobilenetv3_small_transfer/best_model.pth

Epoch 26/30
  Train Loss: 0.0152
  Train Acc:  99.85%
  Val Loss:   1.7618
  Val Acc:    65.00%
  Val Top-5:  87.17%
  Val F1 (M): 63.80%
  Saved best model to outputs/mobilenetv3_small_transfer/best_model.pth

Epoch 27/30
  Train Loss: 0.0118
  Train Acc:  99.93%
  Val Loss:   1.7735
  Val Acc:    64.50%
  Val Top-5:  87.33%
  Val F1 (M): 63.19%

Epoch 28/30
  Train Loss: 0.0152
  Train Acc:  99.78%
  Val Loss:   1.7649
  Val Acc:    63.50%
  Val Top-5:  87.00%
  Val F1 (M): 62.42%

Epoch 29/30
  Train Loss: 0.0136
  Train Acc:  99.83%
  Val Loss:   1.7728
  Val Acc:    64.00%
  Val Top-5:  86.83%
  Val F1 (M): 62.83%

Epoch 30/30
  Train Loss: 0.0129
  Train Acc:  99.85%
  Val Loss:   1.7658
  Val Acc:    64.33%
  Val Top-5:  86.67%
  Val F1 (M): 63.02%
  Test Acc:   63.08%
  Test Top-5: 86.61%
  Test F1 (M):63.27%

============================================================
Training completed in 322.98s
Best validation accuracy: 65.00%
============================================================


Results saved to: outputs/mobilenetv3_small_transfer
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: mobilenetv3_small_logit_kd
Student Architecture: mobilenetv3_small
Distillation Type: logit
Device: cuda
Seed: 42

Configuration saved to: outputs/mobilenetv3_small_logit_kd/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: mobilenetv3_small
  Total parameters: 1,722,856
  Trainable parameters: 1,722,856

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01

Setting up knowledge distillation...
  Teacher: openai/clip-vit-base-patch32
  Distillation type: logit
  Alpha CE: 1.0
  Alpha KD: 1.0


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 8.7417
  Train Acc:  16.15%
  CE Loss:    4.1577
  KD Loss:    4.5840
  Val Loss:   2.8561
  Val Acc:    25.33%
  Val Top-5:  60.67%
  Val F1 (M): 21.22%
  Saved best model to outputs/mobilenetv3_small_logit_kd/best_model.pth

Epoch 2/30
  Train Loss: 5.3906
  Train Acc:  41.72%
  CE Loss:    2.6340
  KD Loss:    2.7566
  Val Loss:   2.1326
  Val Acc:    41.00%
  Val Top-5:  74.83%
  Val F1 (M): 37.24%
  Saved best model to outputs/mobilenetv3_small_logit_kd/best_model.pth

Epoch 3/30
  Train Loss: 4.2866
  Train Acc:  57.85%
  CE Loss:    1.9732
  KD Loss:    2.3133
  Val Loss:   1.7810
  Val Acc:    50.83%
  Val Top-5:  82.17%
  Val F1 (M): 47.56%
  Saved best model to outputs/mobilenetv3_small_logit_kd/best_model.pth

Epoch 4/30
  Train Loss: 3.7535
  Train Acc:  66.74%
  CE Loss:    1.6088
  KD Loss:    2.1448
  Val Loss:   1.5783
  Val Acc:    55.33%
  Val Top-5:  84.50%
  Val F1 (M): 53.32%
  Saved best model to outputs/mobilenetv3_small_logit_kd/best_model.pth

Epoch 5/30
  Train Loss: 3.4058
  Train Acc:  72.60%
  CE Loss:    1.3880
  KD Loss:    2.0178
  Val Loss:   1.6383
  Val Acc:    54.00%
  Val Top-5:  83.67%
  Val F1 (M): 52.47%

Epoch 6/30
  Train Loss: 3.0841
  Train Acc:  78.76%
  CE Loss:    1.1837
  KD Loss:    1.9005
  Val Loss:   1.4895
  Val Acc:    57.83%
  Val Top-5:  86.33%
  Val F1 (M): 55.67%
  Saved best model to outputs/mobilenetv3_small_logit_kd/best_model.pth

Epoch 7/30
  Train Loss: 2.9067
  Train Acc:  82.09%
  CE Loss:    1.0570
  KD Loss:    1.8497
  Val Loss:   1.4303
  Val Acc:    61.67%
  Val Top-5:  87.50%
  Val F1 (M): 60.35%
  Saved best model to outputs/mobilenetv3_small_logit_kd/best_model.pth

Epoch 8/30
  Train Loss: 2.7436
  Train Acc:  84.91%
  CE Loss:    0.9507
  KD Loss:    1.7930
  Val Loss:   1.3304
  Val Acc:    65.50%
  Val Top-5:  89.33%
  Val F1 (M): 64.29%
  Saved best model to outputs/mobilenetv3_small_logit_kd/best_model.pth

Epoch 9/30
  Train Loss: 2.5536
  Train Acc:  88.50%
  CE Loss:    0.8262
  KD Loss:    1.7275
  Val Loss:   1.3125
  Val Acc:    62.67%
  Val Top-5:  89.83%
  Val F1 (M): 61.12%

Epoch 10/30
  Train Loss: 2.4595
  Train Acc:  90.23%
  CE Loss:    0.7578
  KD Loss:    1.7017
  Val Loss:   1.2861
  Val Acc:    66.00%
  Val Top-5:  89.83%
  Val F1 (M): 65.25%
  Saved best model to outputs/mobilenetv3_small_logit_kd/best_model.pth

Epoch 11/30
  Train Loss: 2.3253
  Train Acc:  92.35%
  CE Loss:    0.6790
  KD Loss:    1.6463
  Val Loss:   1.2868
  Val Acc:    66.33%
  Val Top-5:  89.83%
  Val F1 (M): 64.65%
  Saved best model to outputs/mobilenetv3_small_logit_kd/best_model.pth

Epoch 12/30
  Train Loss: 2.2653
  Train Acc:  93.36%
  CE Loss:    0.6313
  KD Loss:    1.6340
  Val Loss:   1.2816
  Val Acc:    63.83%
  Val Top-5:  90.50%
  Val F1 (M): 62.55%

Epoch 13/30
  Train Loss: 2.1567
  Train Acc:  95.18%
  CE Loss:    0.5679
  KD Loss:    1.5888
  Val Loss:   1.2455
  Val Acc:    66.17%
  Val Top-5:  91.67%
  Val F1 (M): 65.11%

Epoch 14/30
  Train Loss: 2.0537
  Train Acc:  95.76%
  CE Loss:    0.5231
  KD Loss:    1.5306
  Val Loss:   1.2073
  Val Acc:    66.17%
  Val Top-5:  91.67%
  Val F1 (M): 65.13%

Epoch 15/30
  Train Loss: 1.9802
  Train Acc:  96.58%
  CE Loss:    0.4807
  KD Loss:    1.4996
  Val Loss:   1.2492
  Val Acc:    65.83%
  Val Top-5:  91.17%
  Val F1 (M): 65.26%

Epoch 16/30
  Train Loss: 1.9042
  Train Acc:  97.08%
  CE Loss:    0.4511
  KD Loss:    1.4531
  Val Loss:   1.2333
  Val Acc:    66.83%
  Val Top-5:  91.17%
  Val F1 (M): 66.19%
  Saved best model to outputs/mobilenetv3_small_logit_kd/best_model.pth

Epoch 17/30
  Train Loss: 1.8459
  Train Acc:  97.62%
  CE Loss:    0.4214
  KD Loss:    1.4246
  Val Loss:   1.2197
  Val Acc:    67.33%
  Val Top-5:  90.67%
  Val F1 (M): 66.29%
  Saved best model to outputs/mobilenetv3_small_logit_kd/best_model.pth

Epoch 18/30
  Train Loss: 1.8139
  Train Acc:  97.99%
  CE Loss:    0.4033
  KD Loss:    1.4107
  Val Loss:   1.2070
  Val Acc:    67.17%
  Val Top-5:  90.67%
  Val F1 (M): 66.53%

Epoch 19/30
  Train Loss: 1.7581
  Train Acc:  98.18%
  CE Loss:    0.3750
  KD Loss:    1.3831
  Val Loss:   1.2041
  Val Acc:    68.50%
  Val Top-5:  90.50%
  Val F1 (M): 67.52%
  Saved best model to outputs/mobilenetv3_small_logit_kd/best_model.pth

Epoch 20/30
  Train Loss: 1.7468
  Train Acc:  98.53%
  CE Loss:    0.3648
  KD Loss:    1.3820
  Val Loss:   1.1705
  Val Acc:    69.67%
  Val Top-5:  90.33%
  Val F1 (M): 68.94%
  Saved best model to outputs/mobilenetv3_small_logit_kd/best_model.pth

Epoch 21/30
  Train Loss: 1.7000
  Train Acc:  98.49%
  CE Loss:    0.3432
  KD Loss:    1.3568
  Val Loss:   1.1874
  Val Acc:    68.00%
  Val Top-5:  89.83%
  Val F1 (M): 66.88%

Epoch 22/30
  Train Loss: 1.6632
  Train Acc:  98.36%
  CE Loss:    0.3387
  KD Loss:    1.3245
  Val Loss:   1.1628
  Val Acc:    69.50%
  Val Top-5:  92.00%
  Val F1 (M): 68.75%

Epoch 23/30
  Train Loss: 1.6205
  Train Acc:  98.68%
  CE Loss:    0.3198
  KD Loss:    1.3007
  Val Loss:   1.1838
  Val Acc:    69.83%
  Val Top-5:  91.33%
  Val F1 (M): 69.31%
  Saved best model to outputs/mobilenetv3_small_logit_kd/best_model.pth

Epoch 24/30
  Train Loss: 1.6048
  Train Acc:  98.74%
  CE Loss:    0.3176
  KD Loss:    1.2872
  Val Loss:   1.1655
  Val Acc:    69.83%
  Val Top-5:  93.00%
  Val F1 (M): 69.33%

Epoch 25/30
  Train Loss: 1.6001
  Train Acc:  98.62%
  CE Loss:    0.3118
  KD Loss:    1.2883
  Val Loss:   1.1630
  Val Acc:    70.00%
  Val Top-5:  90.67%
  Val F1 (M): 69.02%
  Saved best model to outputs/mobilenetv3_small_logit_kd/best_model.pth

Epoch 26/30
  Train Loss: 1.5634
  Train Acc:  98.98%
  CE Loss:    0.2991
  KD Loss:    1.2643
  Val Loss:   1.1722
  Val Acc:    70.00%
  Val Top-5:  91.33%
  Val F1 (M): 69.63%

Epoch 27/30
  Train Loss: 1.5701
  Train Acc:  98.87%
  CE Loss:    0.2981
  KD Loss:    1.2720
  Val Loss:   1.1624
  Val Acc:    69.67%
  Val Top-5:  91.33%
  Val F1 (M): 68.95%

Epoch 28/30
  Train Loss: 1.5587
  Train Acc:  98.75%
  CE Loss:    0.2998
  KD Loss:    1.2589
  Val Loss:   1.1736
  Val Acc:    69.17%
  Val Top-5:  90.67%
  Val F1 (M): 68.28%

Epoch 29/30
  Train Loss: 1.5596
  Train Acc:  98.59%
  CE Loss:    0.2998
  KD Loss:    1.2598
  Val Loss:   1.1705
  Val Acc:    69.33%
  Val Top-5:  91.33%
  Val F1 (M): 68.69%

Epoch 30/30
  Train Loss: 1.5524
  Train Acc:  98.75%
  CE Loss:    0.2904
  KD Loss:    1.2620
  Val Loss:   1.1724
  Val Acc:    70.00%
  Val Top-5:  90.67%
  Val F1 (M): 69.28%
  Test Acc:   70.68%
  Test Top-5: 90.66%
  Test F1 (M):70.75%

============================================================
Training completed in 348.79s
Best validation accuracy: 70.00%
============================================================


Results saved to: outputs/mobilenetv3_small_logit_kd
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: mobilenetv3_small_attention_kd
Student Architecture: mobilenetv3_small
Distillation Type: attention
Device: cuda
Seed: 42

Configuration saved to: outputs/mobilenetv3_small_attention_kd/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: mobilenetv3_small
  Total parameters: 1,722,856
  Trainable parameters: 1,722,856

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01

Setting up knowledge distillation...
  Teacher: openai/clip-vit-base-patch32
  Distillation type: attention
  Alpha CE: 1.0
  Alpha KD: 0.0
  Alpha Attention: 0.5
  Attention loss: mse


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 4.7271
  Train Acc:  10.99%
  CE Loss:    4.7271
  KD Loss:    7.1329
  Val Loss:   3.6534
  Val Acc:    15.83%
  Val Top-5:  41.67%
  Val F1 (M): 11.36%
  Saved best model to outputs/mobilenetv3_small_attention_kd/best_model.pth

Epoch 2/30
  Train Loss: 3.0966
  Train Acc:  36.29%
  CE Loss:    3.0966
  KD Loss:    5.4546
  Val Loss:   2.6708
  Val Acc:    31.50%
  Val Top-5:  64.17%
  Val F1 (M): 26.86%
  Saved best model to outputs/mobilenetv3_small_attention_kd/best_model.pth

Epoch 3/30
  Train Loss: 2.1916
  Train Acc:  54.63%
  CE Loss:    2.1916
  KD Loss:    5.1699
  Val Loss:   2.2491
  Val Acc:    44.00%
  Val Top-5:  72.83%
  Val F1 (M): 39.52%
  Saved best model to outputs/mobilenetv3_small_attention_kd/best_model.pth

Epoch 4/30
  Train Loss: 1.6521
  Train Acc:  67.08%
  CE Loss:    1.6521
  KD Loss:    5.3735
  Val Loss:   2.0453
  Val Acc:    46.17%
  Val Top-5:  75.67%
  Val F1 (M): 42.63%
  Saved best model to outputs/mobilenetv3_small_attention_kd/best_model.pth

Epoch 5/30
  Train Loss: 1.3094
  Train Acc:  76.12%
  CE Loss:    1.3094
  KD Loss:    5.5704
  Val Loss:   2.0115
  Val Acc:    48.17%
  Val Top-5:  79.50%
  Val F1 (M): 45.55%
  Saved best model to outputs/mobilenetv3_small_attention_kd/best_model.pth

Epoch 6/30
  Train Loss: 1.0311
  Train Acc:  82.57%
  CE Loss:    1.0311
  KD Loss:    5.9776
  Val Loss:   1.8911
  Val Acc:    54.50%
  Val Top-5:  82.33%
  Val F1 (M): 52.30%
  Saved best model to outputs/mobilenetv3_small_attention_kd/best_model.pth

Epoch 7/30
  Train Loss: 0.8414
  Train Acc:  87.33%
  CE Loss:    0.8414
  KD Loss:    6.3709
  Val Loss:   1.8531
  Val Acc:    55.17%
  Val Top-5:  79.67%
  Val F1 (M): 53.80%
  Saved best model to outputs/mobilenetv3_small_attention_kd/best_model.pth

Epoch 8/30
  Train Loss: 0.6441
  Train Acc:  92.04%
  CE Loss:    0.6441
  KD Loss:    6.8212
  Val Loss:   1.8665
  Val Acc:    54.33%
  Val Top-5:  82.50%
  Val F1 (M): 52.46%

Epoch 9/30
  Train Loss: 0.4919
  Train Acc:  94.74%
  CE Loss:    0.4919
  KD Loss:    7.4355
  Val Loss:   1.8082
  Val Acc:    54.33%
  Val Top-5:  84.83%
  Val F1 (M): 52.14%

Epoch 10/30
  Train Loss: 0.3922
  Train Acc:  96.67%
  CE Loss:    0.3922
  KD Loss:    7.9513
  Val Loss:   1.9810
  Val Acc:    54.50%
  Val Top-5:  82.67%
  Val F1 (M): 53.18%

Epoch 11/30
  Train Loss: 0.3174
  Train Acc:  97.79%
  CE Loss:    0.3174
  KD Loss:    8.2778
  Val Loss:   1.8959
  Val Acc:    56.50%
  Val Top-5:  84.17%
  Val F1 (M): 55.23%
  Saved best model to outputs/mobilenetv3_small_attention_kd/best_model.pth

Epoch 12/30
  Train Loss: 0.2382
  Train Acc:  98.81%
  CE Loss:    0.2382
  KD Loss:    8.8371
  Val Loss:   1.9188
  Val Acc:    54.33%
  Val Top-5:  83.50%
  Val F1 (M): 53.51%

Epoch 13/30
  Train Loss: 0.1663
  Train Acc:  99.20%
  CE Loss:    0.1663
  KD Loss:    9.4984
  Val Loss:   1.8708
  Val Acc:    57.83%
  Val Top-5:  85.00%
  Val F1 (M): 56.80%
  Saved best model to outputs/mobilenetv3_small_attention_kd/best_model.pth

Epoch 14/30
  Train Loss: 0.1398
  Train Acc:  99.37%
  CE Loss:    0.1398
  KD Loss:    9.8933
  Val Loss:   1.8304
  Val Acc:    59.67%
  Val Top-5:  84.50%
  Val F1 (M): 57.81%
  Saved best model to outputs/mobilenetv3_small_attention_kd/best_model.pth

Epoch 15/30
  Train Loss: 0.1167
  Train Acc:  99.61%
  CE Loss:    0.1167
  KD Loss:    10.3478
  Val Loss:   1.9779
  Val Acc:    56.67%
  Val Top-5:  84.50%
  Val F1 (M): 54.87%

Epoch 16/30
  Train Loss: 0.0790
  Train Acc:  99.85%
  CE Loss:    0.0790
  KD Loss:    10.9207
  Val Loss:   1.8057
  Val Acc:    57.50%
  Val Top-5:  85.33%
  Val F1 (M): 55.57%

Epoch 17/30
  Train Loss: 0.0663
  Train Acc:  99.85%
  CE Loss:    0.0663
  KD Loss:    11.3059
  Val Loss:   1.8613
  Val Acc:    59.50%
  Val Top-5:  85.17%
  Val F1 (M): 57.95%

Epoch 18/30
  Train Loss: 0.0602
  Train Acc:  99.89%
  CE Loss:    0.0602
  KD Loss:    11.6832
  Val Loss:   1.9158
  Val Acc:    58.00%
  Val Top-5:  86.00%
  Val F1 (M): 56.93%

Epoch 19/30
  Train Loss: 0.0435
  Train Acc:  99.96%
  CE Loss:    0.0435
  KD Loss:    11.9588
  Val Loss:   1.9175
  Val Acc:    60.00%
  Val Top-5:  85.17%
  Val F1 (M): 58.32%
  Saved best model to outputs/mobilenetv3_small_attention_kd/best_model.pth

Epoch 20/30
  Train Loss: 0.0309
  Train Acc:  99.94%
  CE Loss:    0.0309
  KD Loss:    12.3440
  Val Loss:   1.9156
  Val Acc:    60.33%
  Val Top-5:  84.67%
  Val F1 (M): 58.68%
  Saved best model to outputs/mobilenetv3_small_attention_kd/best_model.pth

Epoch 21/30
  Train Loss: 0.0314
  Train Acc:  99.96%
  CE Loss:    0.0314
  KD Loss:    12.6017
  Val Loss:   1.9671
  Val Acc:    59.83%
  Val Top-5:  84.50%
  Val F1 (M): 58.67%

Epoch 22/30
  Train Loss: 0.0274
  Train Acc:  99.87%
  CE Loss:    0.0274
  KD Loss:    12.7737
  Val Loss:   1.8742
  Val Acc:    59.00%
  Val Top-5:  85.33%
  Val F1 (M): 57.87%

Epoch 23/30
  Train Loss: 0.0229
  Train Acc:  99.93%
  CE Loss:    0.0229
  KD Loss:    12.9530
  Val Loss:   1.9013
  Val Acc:    60.33%
  Val Top-5:  85.50%
  Val F1 (M): 59.39%

Epoch 24/30
  Train Loss: 0.0203
  Train Acc:  99.87%
  CE Loss:    0.0203
  KD Loss:    13.2336
  Val Loss:   1.8284
  Val Acc:    62.00%
  Val Top-5:  85.17%
  Val F1 (M): 61.14%
  Saved best model to outputs/mobilenetv3_small_attention_kd/best_model.pth

Epoch 25/30
  Train Loss: 0.0169
  Train Acc:  99.91%
  CE Loss:    0.0169
  KD Loss:    13.2625
  Val Loss:   1.8531
  Val Acc:    61.33%
  Val Top-5:  85.67%
  Val F1 (M): 60.43%

Epoch 26/30
  Train Loss: 0.0124
  Train Acc:  99.98%
  CE Loss:    0.0124
  KD Loss:    13.3612
  Val Loss:   1.8593
  Val Acc:    60.33%
  Val Top-5:  86.17%
  Val F1 (M): 59.49%

Epoch 27/30
  Train Loss: 0.0148
  Train Acc:  99.85%
  CE Loss:    0.0148
  KD Loss:    13.4943
  Val Loss:   1.8501
  Val Acc:    59.67%
  Val Top-5:  86.33%
  Val F1 (M): 58.76%

Epoch 28/30
  Train Loss: 0.0133
  Train Acc:  99.89%
  CE Loss:    0.0133
  KD Loss:    13.5204
  Val Loss:   1.8644
  Val Acc:    61.00%
  Val Top-5:  85.67%
  Val F1 (M): 59.75%

Epoch 29/30
  Train Loss: 0.0136
  Train Acc:  99.89%
  CE Loss:    0.0136
  KD Loss:    13.4884
  Val Loss:   1.8582
  Val Acc:    60.00%
  Val Top-5:  85.83%
  Val F1 (M): 58.88%

Epoch 30/30
  Train Loss: 0.0123
  Train Acc:  99.85%
  CE Loss:    0.0123
  KD Loss:    13.5126
  Val Loss:   1.8983
  Val Acc:    60.50%
  Val Top-5:  85.17%
  Val F1 (M): 59.16%
  Test Acc:   61.53%
  Test Top-5: 85.38%
  Test F1 (M):61.54%

============================================================
Training completed in 375.68s
Best validation accuracy: 62.00%
============================================================


Results saved to: outputs/mobilenetv3_small_attention_kd
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: mobilenetv3_small_combined_kd
Student Architecture: mobilenetv3_small
Distillation Type: combined
Device: cuda
Seed: 42

Configuration saved to: outputs/mobilenetv3_small_combined_kd/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: mobilenetv3_small
  Total parameters: 1,722,856
  Trainable parameters: 1,722,856

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01

Setting up knowledge distillation...
  Teacher: openai/clip-vit-base-patch32
  Distillation type: combined
  Alpha CE: 1.0
  Alpha KD: 1.0
  Alpha Attention: 0.1
  Attention loss: mse


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 8.7417
  Train Acc:  16.15%
  CE Loss:    4.1577
  KD Loss:    4.5840
  Val Loss:   2.8263
  Val Acc:    25.00%
  Val Top-5:  60.67%
  Val F1 (M): 20.65%
  Saved best model to outputs/mobilenetv3_small_combined_kd/best_model.pth

Epoch 2/30
  Train Loss: 5.3906
  Train Acc:  41.72%
  CE Loss:    2.6340
  KD Loss:    2.7566
  Val Loss:   2.1035
  Val Acc:    42.83%
  Val Top-5:  75.17%
  Val F1 (M): 39.35%
  Saved best model to outputs/mobilenetv3_small_combined_kd/best_model.pth

Epoch 3/30
  Train Loss: 4.2866
  Train Acc:  57.85%
  CE Loss:    1.9732
  KD Loss:    2.3133
  Val Loss:   1.7678
  Val Acc:    50.17%
  Val Top-5:  82.00%
  Val F1 (M): 46.85%
  Saved best model to outputs/mobilenetv3_small_combined_kd/best_model.pth

Epoch 4/30
  Train Loss: 3.7535
  Train Acc:  66.74%
  CE Loss:    1.6088
  KD Loss:    2.1448
  Val Loss:   1.5708
  Val Acc:    56.67%
  Val Top-5:  85.50%
  Val F1 (M): 54.65%
  Saved best model to outputs/mobilenetv3_small_combined_kd/best_model.pth

Epoch 5/30
  Train Loss: 3.4058
  Train Acc:  72.60%
  CE Loss:    1.3880
  KD Loss:    2.0178
  Val Loss:   1.6163
  Val Acc:    54.17%
  Val Top-5:  84.83%
  Val F1 (M): 53.11%

Epoch 6/30
  Train Loss: 3.0841
  Train Acc:  78.76%
  CE Loss:    1.1837
  KD Loss:    1.9005
  Val Loss:   1.4526
  Val Acc:    59.33%
  Val Top-5:  86.33%
  Val F1 (M): 57.22%
  Saved best model to outputs/mobilenetv3_small_combined_kd/best_model.pth

Epoch 7/30
  Train Loss: 2.9067
  Train Acc:  82.09%
  CE Loss:    1.0570
  KD Loss:    1.8497
  Val Loss:   1.4192
  Val Acc:    62.33%
  Val Top-5:  87.67%
  Val F1 (M): 60.79%
  Saved best model to outputs/mobilenetv3_small_combined_kd/best_model.pth

Epoch 8/30
  Train Loss: 2.7436
  Train Acc:  84.91%
  CE Loss:    0.9507
  KD Loss:    1.7930
  Val Loss:   1.3293
  Val Acc:    65.67%
  Val Top-5:  88.67%
  Val F1 (M): 64.55%
  Saved best model to outputs/mobilenetv3_small_combined_kd/best_model.pth

Epoch 9/30
  Train Loss: 2.5536
  Train Acc:  88.50%
  CE Loss:    0.8262
  KD Loss:    1.7275
  Val Loss:   1.3016
  Val Acc:    63.67%
  Val Top-5:  89.83%
  Val F1 (M): 62.10%

Epoch 10/30
  Train Loss: 2.4595
  Train Acc:  90.23%
  CE Loss:    0.7578
  KD Loss:    1.7017
  Val Loss:   1.2858
  Val Acc:    66.00%
  Val Top-5:  90.00%
  Val F1 (M): 65.44%
  Saved best model to outputs/mobilenetv3_small_combined_kd/best_model.pth

Epoch 11/30
  Train Loss: 2.3253
  Train Acc:  92.35%
  CE Loss:    0.6790
  KD Loss:    1.6463
  Val Loss:   1.2865
  Val Acc:    66.83%
  Val Top-5:  90.17%
  Val F1 (M): 65.03%
  Saved best model to outputs/mobilenetv3_small_combined_kd/best_model.pth

Epoch 12/30
  Train Loss: 2.2653
  Train Acc:  93.36%
  CE Loss:    0.6313
  KD Loss:    1.6340
  Val Loss:   1.2846
  Val Acc:    64.00%
  Val Top-5:  90.50%
  Val F1 (M): 62.65%

Epoch 13/30
  Train Loss: 2.1567
  Train Acc:  95.18%
  CE Loss:    0.5679
  KD Loss:    1.5888
  Val Loss:   1.2481
  Val Acc:    66.00%
  Val Top-5:  91.17%
  Val F1 (M): 65.07%

Epoch 14/30
  Train Loss: 2.0537
  Train Acc:  95.76%
  CE Loss:    0.5231
  KD Loss:    1.5306
  Val Loss:   1.2044
  Val Acc:    66.33%
  Val Top-5:  91.17%
  Val F1 (M): 65.33%

Epoch 15/30
  Train Loss: 1.9802
  Train Acc:  96.58%
  CE Loss:    0.4807
  KD Loss:    1.4996
  Val Loss:   1.2497
  Val Acc:    66.33%
  Val Top-5:  90.83%
  Val F1 (M): 65.63%

Epoch 16/30
  Train Loss: 1.9042
  Train Acc:  97.08%
  CE Loss:    0.4511
  KD Loss:    1.4531
  Val Loss:   1.2383
  Val Acc:    66.83%
  Val Top-5:  90.83%
  Val F1 (M): 66.00%

Epoch 17/30
  Train Loss: 1.8459
  Train Acc:  97.62%
  CE Loss:    0.4214
  KD Loss:    1.4246
  Val Loss:   1.2191
  Val Acc:    67.83%
  Val Top-5:  90.67%
  Val F1 (M): 66.78%
  Saved best model to outputs/mobilenetv3_small_combined_kd/best_model.pth

Epoch 18/30
  Train Loss: 1.8139
  Train Acc:  97.99%
  CE Loss:    0.4033
  KD Loss:    1.4107
  Val Loss:   1.2073
  Val Acc:    67.00%
  Val Top-5:  90.50%
  Val F1 (M): 66.11%

Epoch 19/30
  Train Loss: 1.7581
  Train Acc:  98.18%
  CE Loss:    0.3750
  KD Loss:    1.3831
  Val Loss:   1.2024
  Val Acc:    69.00%
  Val Top-5:  90.83%
  Val F1 (M): 68.12%
  Saved best model to outputs/mobilenetv3_small_combined_kd/best_model.pth

Epoch 20/30
  Train Loss: 1.7468
  Train Acc:  98.53%
  CE Loss:    0.3648
  KD Loss:    1.3820
  Val Loss:   1.1752
  Val Acc:    69.83%
  Val Top-5:  90.17%
  Val F1 (M): 69.05%
  Saved best model to outputs/mobilenetv3_small_combined_kd/best_model.pth

Epoch 21/30
  Train Loss: 1.7000
  Train Acc:  98.49%
  CE Loss:    0.3432
  KD Loss:    1.3568
  Val Loss:   1.1946
  Val Acc:    67.67%
  Val Top-5:  89.33%
  Val F1 (M): 66.53%

Epoch 22/30
  Train Loss: 1.6632
  Train Acc:  98.36%
  CE Loss:    0.3387
  KD Loss:    1.3245
  Val Loss:   1.1668
  Val Acc:    69.83%
  Val Top-5:  91.83%
  Val F1 (M): 69.21%

Epoch 23/30
  Train Loss: 1.6205
  Train Acc:  98.68%
  CE Loss:    0.3198
  KD Loss:    1.3007
  Val Loss:   1.1882
  Val Acc:    69.50%
  Val Top-5:  91.17%
  Val F1 (M): 69.18%

Epoch 24/30
  Train Loss: 1.6048
  Train Acc:  98.74%
  CE Loss:    0.3176
  KD Loss:    1.2872
  Val Loss:   1.1685
  Val Acc:    69.50%
  Val Top-5:  93.00%
  Val F1 (M): 68.96%

Epoch 25/30
  Train Loss: 1.6001
  Train Acc:  98.62%
  CE Loss:    0.3118
  KD Loss:    1.2883
  Val Loss:   1.1675
  Val Acc:    70.33%
  Val Top-5:  90.83%
  Val F1 (M): 69.57%
  Saved best model to outputs/mobilenetv3_small_combined_kd/best_model.pth

Epoch 26/30
  Train Loss: 1.5634
  Train Acc:  98.98%
  CE Loss:    0.2991
  KD Loss:    1.2643
  Val Loss:   1.1765
  Val Acc:    69.33%
  Val Top-5:  91.50%
  Val F1 (M): 68.83%

Epoch 27/30
  Train Loss: 1.5701
  Train Acc:  98.87%
  CE Loss:    0.2981
  KD Loss:    1.2720
  Val Loss:   1.1685
  Val Acc:    68.83%
  Val Top-5:  91.33%
  Val F1 (M): 67.94%

Epoch 28/30
  Train Loss: 1.5587
  Train Acc:  98.75%
  CE Loss:    0.2998
  KD Loss:    1.2589
  Val Loss:   1.1824
  Val Acc:    69.00%
  Val Top-5:  90.83%
  Val F1 (M): 68.01%

Epoch 29/30
  Train Loss: 1.5596
  Train Acc:  98.59%
  CE Loss:    0.2998
  KD Loss:    1.2598
  Val Loss:   1.1778
  Val Acc:    68.83%
  Val Top-5:  91.17%
  Val F1 (M): 68.24%

Epoch 30/30
  Train Loss: 1.5524
  Train Acc:  98.75%
  CE Loss:    0.2904
  KD Loss:    1.2620
  Val Loss:   1.1783
  Val Acc:    70.17%
  Val Top-5:  90.17%
  Val F1 (M): 69.27%
  Test Acc:   70.68%
  Test Top-5: 90.89%
  Test F1 (M):70.72%

============================================================
Training completed in 374.31s
Best validation accuracy: 70.33%
============================================================


Results saved to: outputs/mobilenetv3_small_combined_kd
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: mobilenetv3_large_scratch
Student Architecture: mobilenetv3_large
Distillation Type: none
Device: cuda
Seed: 42

Configuration saved to: outputs/mobilenetv3_large_scratch/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: mobilenetv3_large
  Total parameters: 4,458,232
  Trainable parameters: 4,458,232

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 5.3357
  Train Acc:  0.84%
  Val Loss:   5.1792
  Val Acc:    0.83%
  Val Top-5:  5.00%
  Val F1 (M): 0.09%
  Saved best model to outputs/mobilenetv3_large_scratch/best_model.pth

Epoch 2/30
  Train Loss: 5.1465
  Train Acc:  1.28%
  Val Loss:   4.9388
  Val Acc:    3.50%
  Val Top-5:  11.00%
  Val F1 (M): 0.84%
  Saved best model to outputs/mobilenetv3_large_scratch/best_model.pth

Epoch 3/30
  Train Loss: 4.9478
  Train Acc:  2.27%
  Val Loss:   4.7984
  Val Acc:    2.00%
  Val Top-5:  11.00%
  Val F1 (M): 0.68%

Epoch 4/30
  Train Loss: 4.7758
  Train Acc:  3.18%
  Val Loss:   4.6181
  Val Acc:    3.67%
  Val Top-5:  17.50%
  Val F1 (M): 1.98%
  Saved best model to outputs/mobilenetv3_large_scratch/best_model.pth

Epoch 5/30
  Train Loss: 4.5917
  Train Acc:  3.89%
  Val Loss:   4.4683
  Val Acc:    5.83%
  Val Top-5:  19.83%
  Val F1 (M): 3.61%
  Saved best model to outputs/mobilenetv3_large_scratch/best_model.pth

Epoch 6/30
  Train Loss: 4.3714
  Train Acc:  5.69%
  Val Loss:   4.3870
  Val Acc:    6.33%
  Val Top-5:  23.67%
  Val F1 (M): 4.24%
  Saved best model to outputs/mobilenetv3_large_scratch/best_model.pth

Epoch 7/30
  Train Loss: 4.1961
  Train Acc:  8.04%
  Val Loss:   4.0848
  Val Acc:    11.50%
  Val Top-5:  31.67%
  Val F1 (M): 8.34%
  Saved best model to outputs/mobilenetv3_large_scratch/best_model.pth

Epoch 8/30
  Train Loss: 4.0010
  Train Acc:  10.64%
  Val Loss:   3.9435
  Val Acc:    13.83%
  Val Top-5:  33.50%
  Val F1 (M): 9.85%
  Saved best model to outputs/mobilenetv3_large_scratch/best_model.pth

Epoch 9/30
  Train Loss: 3.8204
  Train Acc:  12.41%
  Val Loss:   3.8473
  Val Acc:    12.83%
  Val Top-5:  36.67%
  Val F1 (M): 9.14%

Epoch 10/30
  Train Loss: 3.6600
  Train Acc:  14.77%
  Val Loss:   3.8417
  Val Acc:    15.00%
  Val Top-5:  35.50%
  Val F1 (M): 12.16%
  Saved best model to outputs/mobilenetv3_large_scratch/best_model.pth

Epoch 11/30
  Train Loss: 3.5175
  Train Acc:  17.69%
  Val Loss:   3.6654
  Val Acc:    16.00%
  Val Top-5:  40.17%
  Val F1 (M): 13.72%
  Saved best model to outputs/mobilenetv3_large_scratch/best_model.pth

Epoch 12/30
  Train Loss: 3.3572
  Train Acc:  20.50%
  Val Loss:   3.6120
  Val Acc:    16.33%
  Val Top-5:  41.83%
  Val F1 (M): 13.20%
  Saved best model to outputs/mobilenetv3_large_scratch/best_model.pth

Epoch 13/30
  Train Loss: 3.1983
  Train Acc:  22.95%
  Val Loss:   3.5850
  Val Acc:    16.83%
  Val Top-5:  44.83%
  Val F1 (M): 13.76%
  Saved best model to outputs/mobilenetv3_large_scratch/best_model.pth

Epoch 14/30
  Train Loss: 3.0742
  Train Acc:  24.65%
  Val Loss:   3.5537
  Val Acc:    18.00%
  Val Top-5:  44.83%
  Val F1 (M): 15.46%
  Saved best model to outputs/mobilenetv3_large_scratch/best_model.pth

Epoch 15/30
  Train Loss: 2.9654
  Train Acc:  27.10%
  Val Loss:   3.4500
  Val Acc:    18.83%
  Val Top-5:  47.33%
  Val F1 (M): 17.03%
  Saved best model to outputs/mobilenetv3_large_scratch/best_model.pth

Epoch 16/30
  Train Loss: 2.8044
  Train Acc:  29.20%
  Val Loss:   3.3915
  Val Acc:    21.67%
  Val Top-5:  48.17%
  Val F1 (M): 19.39%
  Saved best model to outputs/mobilenetv3_large_scratch/best_model.pth

Epoch 17/30
  Train Loss: 2.6833
  Train Acc:  31.73%
  Val Loss:   3.4737
  Val Acc:    20.33%
  Val Top-5:  49.33%
  Val F1 (M): 18.23%

Epoch 18/30
  Train Loss: 2.5721
  Train Acc:  34.52%
  Val Loss:   3.3648
  Val Acc:    24.17%
  Val Top-5:  49.50%
  Val F1 (M): 22.10%
  Saved best model to outputs/mobilenetv3_large_scratch/best_model.pth

Epoch 19/30
  Train Loss: 2.4899
  Train Acc:  35.71%
  Val Loss:   3.3826
  Val Acc:    24.33%
  Val Top-5:  50.00%
  Val F1 (M): 21.84%
  Saved best model to outputs/mobilenetv3_large_scratch/best_model.pth

Epoch 20/30
  Train Loss: 2.3905
  Train Acc:  38.28%
  Val Loss:   3.3850
  Val Acc:    24.00%
  Val Top-5:  50.50%
  Val F1 (M): 21.64%

Epoch 21/30
  Train Loss: 2.2971
  Train Acc:  40.36%
  Val Loss:   3.3994
  Val Acc:    22.67%
  Val Top-5:  49.50%
  Val F1 (M): 20.71%

Epoch 22/30
  Train Loss: 2.2365
  Train Acc:  41.63%
  Val Loss:   3.4167
  Val Acc:    23.00%
  Val Top-5:  50.67%
  Val F1 (M): 20.87%

Epoch 23/30
  Train Loss: 2.1325
  Train Acc:  43.94%
  Val Loss:   3.4106
  Val Acc:    23.33%
  Val Top-5:  52.17%
  Val F1 (M): 21.12%

Epoch 24/30
  Train Loss: 2.0870
  Train Acc:  45.55%
  Val Loss:   3.4077
  Val Acc:    24.67%
  Val Top-5:  51.83%
  Val F1 (M): 22.51%
  Saved best model to outputs/mobilenetv3_large_scratch/best_model.pth

Epoch 25/30
  Train Loss: 2.0362
  Train Acc:  46.47%
  Val Loss:   3.4345
  Val Acc:    24.33%
  Val Top-5:  52.33%
  Val F1 (M): 21.80%

Epoch 26/30
  Train Loss: 2.0050
  Train Acc:  48.18%
  Val Loss:   3.4009
  Val Acc:    24.17%
  Val Top-5:  51.67%
  Val F1 (M): 22.44%

Epoch 27/30
  Train Loss: 1.9999
  Train Acc:  47.79%
  Val Loss:   3.3893
  Val Acc:    24.83%
  Val Top-5:  51.83%
  Val F1 (M): 22.94%
  Saved best model to outputs/mobilenetv3_large_scratch/best_model.pth

Epoch 28/30
  Train Loss: 1.9402
  Train Acc:  48.96%
  Val Loss:   3.3824
  Val Acc:    24.83%
  Val Top-5:  52.67%
  Val F1 (M): 22.75%

Epoch 29/30
  Train Loss: 1.9595
  Train Acc:  49.29%
  Val Loss:   3.3871
  Val Acc:    25.00%
  Val Top-5:  51.17%
  Val F1 (M): 23.23%
  Saved best model to outputs/mobilenetv3_large_scratch/best_model.pth

Epoch 30/30
  Train Loss: 1.9357
  Train Acc:  48.96%
  Val Loss:   3.4229
  Val Acc:    24.83%
  Val Top-5:  51.50%
  Val F1 (M): 22.82%
  Test Acc:   24.68%
  Test Top-5: 52.04%
  Test F1 (M):24.12%

============================================================
Training completed in 334.92s
Best validation accuracy: 25.00%
============================================================


Results saved to: outputs/mobilenetv3_large_scratch
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: mobilenetv3_large_transfer
Student Architecture: mobilenetv3_large
Distillation Type: none
Device: cuda
Seed: 42

Configuration saved to: outputs/mobilenetv3_large_transfer/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: mobilenetv3_large
  Total parameters: 4,458,232
  Trainable parameters: 4,458,232

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 3.9904
  Train Acc:  16.95%
  Val Loss:   2.1492
  Val Acc:    44.00%
  Val Top-5:  76.17%
  Val F1 (M): 39.19%
  Saved best model to outputs/mobilenetv3_large_transfer/best_model.pth

Epoch 2/30
  Train Loss: 1.5814
  Train Acc:  58.24%
  Val Loss:   1.4138
  Val Acc:    58.67%
  Val Top-5:  88.67%
  Val F1 (M): 56.31%
  Saved best model to outputs/mobilenetv3_large_transfer/best_model.pth

Epoch 3/30
  Train Loss: 0.8491
  Train Acc:  76.28%
  Val Loss:   1.2783
  Val Acc:    64.67%
  Val Top-5:  89.67%
  Val F1 (M): 62.57%
  Saved best model to outputs/mobilenetv3_large_transfer/best_model.pth

Epoch 4/30
  Train Loss: 0.4951
  Train Acc:  85.86%
  Val Loss:   1.2525
  Val Acc:    65.00%
  Val Top-5:  90.83%
  Val F1 (M): 63.20%
  Saved best model to outputs/mobilenetv3_large_transfer/best_model.pth

Epoch 5/30
  Train Loss: 0.3012
  Train Acc:  91.76%
  Val Loss:   1.2352
  Val Acc:    64.50%
  Val Top-5:  91.67%
  Val F1 (M): 63.04%

Epoch 6/30
  Train Loss: 0.2143
  Train Acc:  94.07%
  Val Loss:   1.3588
  Val Acc:    66.50%
  Val Top-5:  90.83%
  Val F1 (M): 64.89%
  Saved best model to outputs/mobilenetv3_large_transfer/best_model.pth

Epoch 7/30
  Train Loss: 0.1471
  Train Acc:  96.11%
  Val Loss:   1.3296
  Val Acc:    66.50%
  Val Top-5:  89.67%
  Val F1 (M): 65.10%

Epoch 8/30
  Train Loss: 0.0985
  Train Acc:  97.66%
  Val Loss:   1.3020
  Val Acc:    69.50%
  Val Top-5:  91.33%
  Val F1 (M): 67.87%
  Saved best model to outputs/mobilenetv3_large_transfer/best_model.pth

Epoch 9/30
  Train Loss: 0.0724
  Train Acc:  98.62%
  Val Loss:   1.3262
  Val Acc:    67.67%
  Val Top-5:  92.00%
  Val F1 (M): 66.81%

Epoch 10/30
  Train Loss: 0.0632
  Train Acc:  98.59%
  Val Loss:   1.4306
  Val Acc:    67.83%
  Val Top-5:  90.17%
  Val F1 (M): 66.72%

Epoch 11/30
  Train Loss: 0.0537
  Train Acc:  98.83%
  Val Loss:   1.4350
  Val Acc:    67.17%
  Val Top-5:  90.67%
  Val F1 (M): 66.07%

Epoch 12/30
  Train Loss: 0.0505
  Train Acc:  98.72%
  Val Loss:   1.4983
  Val Acc:    68.33%
  Val Top-5:  90.50%
  Val F1 (M): 67.14%

Epoch 13/30
  Train Loss: 0.0466
  Train Acc:  98.96%
  Val Loss:   1.4366
  Val Acc:    68.17%
  Val Top-5:  91.17%
  Val F1 (M): 66.76%

Epoch 14/30
  Train Loss: 0.0351
  Train Acc:  99.31%
  Val Loss:   1.3964
  Val Acc:    68.50%
  Val Top-5:  91.00%
  Val F1 (M): 67.18%

Epoch 15/30
  Train Loss: 0.0246
  Train Acc:  99.42%
  Val Loss:   1.4268
  Val Acc:    68.17%
  Val Top-5:  91.00%
  Val F1 (M): 66.85%

Epoch 16/30
  Train Loss: 0.0207
  Train Acc:  99.59%
  Val Loss:   1.4130
  Val Acc:    69.83%
  Val Top-5:  91.50%
  Val F1 (M): 68.93%
  Saved best model to outputs/mobilenetv3_large_transfer/best_model.pth

Epoch 17/30
  Train Loss: 0.0143
  Train Acc:  99.83%
  Val Loss:   1.4096
  Val Acc:    69.00%
  Val Top-5:  92.17%
  Val F1 (M): 67.79%

Epoch 18/30
  Train Loss: 0.0145
  Train Acc:  99.72%
  Val Loss:   1.4079
  Val Acc:    69.83%
  Val Top-5:  91.17%
  Val F1 (M): 68.65%

Epoch 19/30
  Train Loss: 0.0132
  Train Acc:  99.81%
  Val Loss:   1.3948
  Val Acc:    70.33%
  Val Top-5:  91.50%
  Val F1 (M): 69.27%
  Saved best model to outputs/mobilenetv3_large_transfer/best_model.pth

Epoch 20/30
  Train Loss: 0.0108
  Train Acc:  99.81%
  Val Loss:   1.3860
  Val Acc:    69.67%
  Val Top-5:  91.50%
  Val F1 (M): 68.32%

Epoch 21/30
  Train Loss: 0.0096
  Train Acc:  99.80%
  Val Loss:   1.3976
  Val Acc:    70.83%
  Val Top-5:  91.50%
  Val F1 (M): 69.42%
  Saved best model to outputs/mobilenetv3_large_transfer/best_model.pth

Epoch 22/30
  Train Loss: 0.0070
  Train Acc:  99.87%
  Val Loss:   1.4205
  Val Acc:    70.17%
  Val Top-5:  91.00%
  Val F1 (M): 68.91%

Epoch 23/30
  Train Loss: 0.0070
  Train Acc:  99.91%
  Val Loss:   1.4207
  Val Acc:    70.00%
  Val Top-5:  91.33%
  Val F1 (M): 68.59%

Epoch 24/30
  Train Loss: 0.0061
  Train Acc:  99.93%
  Val Loss:   1.4022
  Val Acc:    70.50%
  Val Top-5:  91.67%
  Val F1 (M): 69.40%

Epoch 25/30
  Train Loss: 0.0060
  Train Acc:  99.91%
  Val Loss:   1.4011
  Val Acc:    70.33%
  Val Top-5:  91.67%
  Val F1 (M): 69.44%

Epoch 26/30
  Train Loss: 0.0055
  Train Acc:  99.87%
  Val Loss:   1.4207
  Val Acc:    70.17%
  Val Top-5:  91.50%
  Val F1 (M): 69.12%

Epoch 27/30
  Train Loss: 0.0047
  Train Acc:  100.00%
  Val Loss:   1.4178
  Val Acc:    71.17%
  Val Top-5:  91.67%
  Val F1 (M): 70.40%
  Saved best model to outputs/mobilenetv3_large_transfer/best_model.pth

Epoch 28/30
  Train Loss: 0.0051
  Train Acc:  99.93%
  Val Loss:   1.4046
  Val Acc:    71.17%
  Val Top-5:  92.33%
  Val F1 (M): 69.89%

Epoch 29/30
  Train Loss: 0.0047
  Train Acc:  99.94%
  Val Loss:   1.4347
  Val Acc:    71.17%
  Val Top-5:  91.33%
  Val F1 (M): 70.21%

Epoch 30/30
  Train Loss: 0.0042
  Train Acc:  99.94%
  Val Loss:   1.4243
  Val Acc:    71.33%
  Val Top-5:  91.67%
  Val F1 (M): 70.29%
  Saved best model to outputs/mobilenetv3_large_transfer/best_model.pth
  Test Acc:   72.54%
  Test Top-5: 91.85%
  Test F1 (M):72.66%

============================================================
Training completed in 335.36s
Best validation accuracy: 71.33%
============================================================


Results saved to: outputs/mobilenetv3_large_transfer
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: mobilenetv3_large_logit_kd
Student Architecture: mobilenetv3_large
Distillation Type: logit
Device: cuda
Seed: 42

Configuration saved to: outputs/mobilenetv3_large_logit_kd/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: mobilenetv3_large
  Total parameters: 4,458,232
  Trainable parameters: 4,458,232

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01

Setting up knowledge distillation...
  Teacher: openai/clip-vit-base-patch32
  Distillation type: logit
  Alpha CE: 1.0
  Alpha KD: 1.0


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 7.6607
  Train Acc:  25.32%
  CE Loss:    3.5866
  KD Loss:    4.0741
  Val Loss:   1.8566
  Val Acc:    47.83%
  Val Top-5:  82.00%
  Val F1 (M): 44.77%
  Saved best model to outputs/mobilenetv3_large_logit_kd/best_model.pth

Epoch 2/30
  Train Loss: 3.7279
  Train Acc:  64.81%
  CE Loss:    1.6454
  KD Loss:    2.0826
  Val Loss:   1.3531
  Val Acc:    61.67%
  Val Top-5:  90.83%
  Val F1 (M): 58.79%
  Saved best model to outputs/mobilenetv3_large_logit_kd/best_model.pth

Epoch 3/30
  Train Loss: 2.9876
  Train Acc:  78.31%
  CE Loss:    1.1531
  KD Loss:    1.8345
  Val Loss:   1.1996
  Val Acc:    67.17%
  Val Top-5:  92.67%
  Val F1 (M): 65.56%
  Saved best model to outputs/mobilenetv3_large_logit_kd/best_model.pth

Epoch 4/30
  Train Loss: 2.6153
  Train Acc:  85.57%
  CE Loss:    0.8986
  KD Loss:    1.7167
  Val Loss:   1.1299
  Val Acc:    67.17%
  Val Top-5:  93.50%
  Val F1 (M): 65.34%

Epoch 5/30
  Train Loss: 2.3914
  Train Acc:  90.12%
  CE Loss:    0.7419
  KD Loss:    1.6496
  Val Loss:   1.0824
  Val Acc:    70.17%
  Val Top-5:  92.67%
  Val F1 (M): 68.37%
  Saved best model to outputs/mobilenetv3_large_logit_kd/best_model.pth

Epoch 6/30
  Train Loss: 2.1961
  Train Acc:  93.21%
  CE Loss:    0.6361
  KD Loss:    1.5600
  Val Loss:   1.0534
  Val Acc:    69.00%
  Val Top-5:  93.33%
  Val F1 (M): 67.50%

Epoch 7/30
  Train Loss: 2.0500
  Train Acc:  95.59%
  CE Loss:    0.5396
  KD Loss:    1.5104
  Val Loss:   1.0408
  Val Acc:    71.83%
  Val Top-5:  94.00%
  Val F1 (M): 70.66%
  Saved best model to outputs/mobilenetv3_large_logit_kd/best_model.pth

Epoch 8/30
  Train Loss: 1.9333
  Train Acc:  97.04%
  CE Loss:    0.4774
  KD Loss:    1.4559
  Val Loss:   1.0341
  Val Acc:    72.00%
  Val Top-5:  94.17%
  Val F1 (M): 71.06%
  Saved best model to outputs/mobilenetv3_large_logit_kd/best_model.pth

Epoch 9/30
  Train Loss: 1.8643
  Train Acc:  97.41%
  CE Loss:    0.4426
  KD Loss:    1.4217
  Val Loss:   1.0150
  Val Acc:    74.33%
  Val Top-5:  93.83%
  Val F1 (M): 73.34%
  Saved best model to outputs/mobilenetv3_large_logit_kd/best_model.pth

Epoch 10/30
  Train Loss: 1.7881
  Train Acc:  98.12%
  CE Loss:    0.4071
  KD Loss:    1.3810
  Val Loss:   1.0118
  Val Acc:    72.17%
  Val Top-5:  93.83%
  Val F1 (M): 70.79%

Epoch 11/30
  Train Loss: 1.7351
  Train Acc:  98.64%
  CE Loss:    0.3702
  KD Loss:    1.3649
  Val Loss:   1.0098
  Val Acc:    73.67%
  Val Top-5:  94.50%
  Val F1 (M): 72.54%

Epoch 12/30
  Train Loss: 1.6867
  Train Acc:  98.83%
  CE Loss:    0.3553
  KD Loss:    1.3314
  Val Loss:   0.9966
  Val Acc:    73.50%
  Val Top-5:  93.67%
  Val F1 (M): 72.09%

Epoch 13/30
  Train Loss: 1.6101
  Train Acc:  98.98%
  CE Loss:    0.3259
  KD Loss:    1.2842
  Val Loss:   1.0006
  Val Acc:    73.00%
  Val Top-5:  93.33%
  Val F1 (M): 71.81%

Epoch 14/30
  Train Loss: 1.5722
  Train Acc:  98.75%
  CE Loss:    0.3182
  KD Loss:    1.2540
  Val Loss:   1.0069
  Val Acc:    72.67%
  Val Top-5:  93.83%
  Val F1 (M): 71.05%

Epoch 15/30
  Train Loss: 1.5312
  Train Acc:  99.22%
  CE Loss:    0.2984
  KD Loss:    1.2328
  Val Loss:   1.0108
  Val Acc:    73.00%
  Val Top-5:  94.33%
  Val F1 (M): 72.46%

Epoch 16/30
  Train Loss: 1.5147
  Train Acc:  99.33%
  CE Loss:    0.2908
  KD Loss:    1.2239
  Val Loss:   0.9845
  Val Acc:    75.33%
  Val Top-5:  94.00%
  Val F1 (M): 74.44%
  Saved best model to outputs/mobilenetv3_large_logit_kd/best_model.pth

Epoch 17/30
  Train Loss: 1.4943
  Train Acc:  99.40%
  CE Loss:    0.2853
  KD Loss:    1.2090
  Val Loss:   0.9686
  Val Acc:    73.00%
  Val Top-5:  94.33%
  Val F1 (M): 71.88%

Epoch 18/30
  Train Loss: 1.4542
  Train Acc:  99.50%
  CE Loss:    0.2682
  KD Loss:    1.1860
  Val Loss:   0.9822
  Val Acc:    74.17%
  Val Top-5:  94.67%
  Val F1 (M): 72.95%

Epoch 19/30
  Train Loss: 1.4283
  Train Acc:  99.33%
  CE Loss:    0.2666
  KD Loss:    1.1617
  Val Loss:   0.9959
  Val Acc:    73.83%
  Val Top-5:  94.67%
  Val F1 (M): 72.70%

Epoch 20/30
  Train Loss: 1.4114
  Train Acc:  99.57%
  CE Loss:    0.2560
  KD Loss:    1.1555
  Val Loss:   1.0023
  Val Acc:    73.50%
  Val Top-5:  93.67%
  Val F1 (M): 72.25%

Epoch 21/30
  Train Loss: 1.4003
  Train Acc:  99.39%
  CE Loss:    0.2522
  KD Loss:    1.1481
  Val Loss:   1.0103
  Val Acc:    72.83%
  Val Top-5:  93.67%
  Val F1 (M): 71.56%

Epoch 22/30
  Train Loss: 1.3764
  Train Acc:  99.61%
  CE Loss:    0.2441
  KD Loss:    1.1323
  Val Loss:   0.9948
  Val Acc:    73.17%
  Val Top-5:  94.50%
  Val F1 (M): 71.99%

Epoch 23/30
  Train Loss: 1.3665
  Train Acc:  99.46%
  CE Loss:    0.2491
  KD Loss:    1.1175
  Val Loss:   1.0000
  Val Acc:    73.83%
  Val Top-5:  94.17%
  Val F1 (M): 72.88%

Epoch 24/30
  Train Loss: 1.3349
  Train Acc:  99.57%
  CE Loss:    0.2393
  KD Loss:    1.0956
  Val Loss:   0.9848
  Val Acc:    75.67%
  Val Top-5:  94.50%
  Val F1 (M): 74.55%
  Saved best model to outputs/mobilenetv3_large_logit_kd/best_model.pth

Epoch 25/30
  Train Loss: 1.3381
  Train Acc:  99.65%
  CE Loss:    0.2375
  KD Loss:    1.1005
  Val Loss:   0.9905
  Val Acc:    74.83%
  Val Top-5:  94.50%
  Val F1 (M): 73.46%

Epoch 26/30
  Train Loss: 1.3275
  Train Acc:  99.57%
  CE Loss:    0.2379
  KD Loss:    1.0895
  Val Loss:   1.0015
  Val Acc:    74.67%
  Val Top-5:  94.67%
  Val F1 (M): 73.52%

Epoch 27/30
  Train Loss: 1.3138
  Train Acc:  99.46%
  CE Loss:    0.2349
  KD Loss:    1.0789
  Val Loss:   0.9890
  Val Acc:    75.67%
  Val Top-5:  94.67%
  Val F1 (M): 74.58%

Epoch 28/30
  Train Loss: 1.3117
  Train Acc:  99.59%
  CE Loss:    0.2328
  KD Loss:    1.0789
  Val Loss:   0.9955
  Val Acc:    74.17%
  Val Top-5:  94.50%
  Val F1 (M): 73.15%

Epoch 29/30
  Train Loss: 1.3040
  Train Acc:  99.61%
  CE Loss:    0.2308
  KD Loss:    1.0732
  Val Loss:   1.0060
  Val Acc:    73.67%
  Val Top-5:  94.33%
  Val F1 (M): 72.33%

Epoch 30/30
  Train Loss: 1.3080
  Train Acc:  99.61%
  CE Loss:    0.2285
  KD Loss:    1.0795
  Val Loss:   0.9884
  Val Acc:    74.50%
  Val Top-5:  94.50%
  Val F1 (M): 73.31%
  Test Acc:   76.53%
  Test Top-5: 94.11%
  Test F1 (M):76.47%

============================================================
Training completed in 361.79s
Best validation accuracy: 75.67%
============================================================


Results saved to: outputs/mobilenetv3_large_logit_kd
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: mobilenetv3_large_attention_kd
Student Architecture: mobilenetv3_large
Distillation Type: attention
Device: cuda
Seed: 42

Configuration saved to: outputs/mobilenetv3_large_attention_kd/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: mobilenetv3_large
  Total parameters: 4,458,232
  Trainable parameters: 4,458,232

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01

Setting up knowledge distillation...
  Teacher: openai/clip-vit-base-patch32
  Distillation type: attention
  Alpha CE: 1.0
  Alpha KD: 0.0
  Alpha Attention: 0.5
  Attention loss: mse


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 4.0137
  Train Acc:  23.85%
  CE Loss:    4.0137
  KD Loss:    6.5342
  Val Loss:   2.1579
  Val Acc:    43.67%
  Val Top-5:  76.67%
  Val F1 (M): 40.40%
  Saved best model to outputs/mobilenetv3_large_attention_kd/best_model.pth

Epoch 2/30
  Train Loss: 1.5707
  Train Acc:  69.25%
  CE Loss:    1.5707
  KD Loss:    4.8655
  Val Loss:   1.5603
  Val Acc:    56.67%
  Val Top-5:  86.50%
  Val F1 (M): 54.10%
  Saved best model to outputs/mobilenetv3_large_attention_kd/best_model.pth

Epoch 3/30
  Train Loss: 0.8135
  Train Acc:  86.03%
  CE Loss:    0.8135
  KD Loss:    5.0970
  Val Loss:   1.3352
  Val Acc:    62.33%
  Val Top-5:  88.50%
  Val F1 (M): 60.96%
  Saved best model to outputs/mobilenetv3_large_attention_kd/best_model.pth

Epoch 4/30
  Train Loss: 0.4967
  Train Acc:  94.05%
  CE Loss:    0.4967
  KD Loss:    5.6888
  Val Loss:   1.3095
  Val Acc:    64.67%
  Val Top-5:  89.33%
  Val F1 (M): 61.89%
  Saved best model to outputs/mobilenetv3_large_attention_kd/best_model.pth

Epoch 5/30
  Train Loss: 0.3201
  Train Acc:  97.60%
  CE Loss:    0.3201
  KD Loss:    6.3866
  Val Loss:   1.3127
  Val Acc:    65.50%
  Val Top-5:  88.33%
  Val F1 (M): 64.02%
  Saved best model to outputs/mobilenetv3_large_attention_kd/best_model.pth

Epoch 6/30
  Train Loss: 0.1959
  Train Acc:  99.16%
  CE Loss:    0.1959
  KD Loss:    7.1052
  Val Loss:   1.3387
  Val Acc:    66.67%
  Val Top-5:  90.00%
  Val F1 (M): 65.15%
  Saved best model to outputs/mobilenetv3_large_attention_kd/best_model.pth

Epoch 7/30
  Train Loss: 0.1294
  Train Acc:  99.67%
  CE Loss:    0.1294
  KD Loss:    7.7150
  Val Loss:   1.3565
  Val Acc:    67.67%
  Val Top-5:  89.83%
  Val F1 (M): 66.54%
  Saved best model to outputs/mobilenetv3_large_attention_kd/best_model.pth

Epoch 8/30
  Train Loss: 0.0985
  Train Acc:  99.83%
  CE Loss:    0.0985
  KD Loss:    8.3471
  Val Loss:   1.3796
  Val Acc:    67.50%
  Val Top-5:  90.00%
  Val F1 (M): 65.92%

Epoch 9/30
  Train Loss: 0.0940
  Train Acc:  99.91%
  CE Loss:    0.0940
  KD Loss:    8.9860
  Val Loss:   1.4078
  Val Acc:    68.83%
  Val Top-5:  91.00%
  Val F1 (M): 68.06%
  Saved best model to outputs/mobilenetv3_large_attention_kd/best_model.pth

Epoch 10/30
  Train Loss: 0.0706
  Train Acc:  99.98%
  CE Loss:    0.0706
  KD Loss:    9.3067
  Val Loss:   1.4578
  Val Acc:    67.33%
  Val Top-5:  89.50%
  Val F1 (M): 66.02%

Epoch 11/30
  Train Loss: 0.0567
  Train Acc:  99.98%
  CE Loss:    0.0567
  KD Loss:    9.8816
  Val Loss:   1.4915
  Val Acc:    65.83%
  Val Top-5:  90.33%
  Val F1 (M): 63.99%

Epoch 12/30
  Train Loss: 0.0491
  Train Acc:  100.00%
  CE Loss:    0.0491
  KD Loss:    10.2595
  Val Loss:   1.3941
  Val Acc:    67.00%
  Val Top-5:  92.17%
  Val F1 (M): 66.22%

Epoch 13/30
  Train Loss: 0.0438
  Train Acc:  99.96%
  CE Loss:    0.0438
  KD Loss:    10.4936
  Val Loss:   1.4532
  Val Acc:    67.33%
  Val Top-5:  90.00%
  Val F1 (M): 65.72%

Epoch 14/30
  Train Loss: 0.0283
  Train Acc:  100.00%
  CE Loss:    0.0283
  KD Loss:    11.0788
  Val Loss:   1.3793
  Val Acc:    70.00%
  Val Top-5:  90.33%
  Val F1 (M): 68.72%
  Saved best model to outputs/mobilenetv3_large_attention_kd/best_model.pth

Epoch 15/30
  Train Loss: 0.0244
  Train Acc:  99.98%
  CE Loss:    0.0244
  KD Loss:    11.5037
  Val Loss:   1.4182
  Val Acc:    69.00%
  Val Top-5:  90.83%
  Val F1 (M): 67.53%

Epoch 16/30
  Train Loss: 0.0220
  Train Acc:  99.96%
  CE Loss:    0.0220
  KD Loss:    11.6761
  Val Loss:   1.3821
  Val Acc:    69.33%
  Val Top-5:  90.50%
  Val F1 (M): 68.09%

Epoch 17/30
  Train Loss: 0.0170
  Train Acc:  100.00%
  CE Loss:    0.0170
  KD Loss:    12.1138
  Val Loss:   1.4027
  Val Acc:    69.17%
  Val Top-5:  91.00%
  Val F1 (M): 68.26%

Epoch 18/30
  Train Loss: 0.0111
  Train Acc:  100.00%
  CE Loss:    0.0111
  KD Loss:    12.5307
  Val Loss:   1.4510
  Val Acc:    69.67%
  Val Top-5:  91.00%
  Val F1 (M): 68.84%

Epoch 19/30
  Train Loss: 0.0081
  Train Acc:  100.00%
  CE Loss:    0.0081
  KD Loss:    12.9026
  Val Loss:   1.4387
  Val Acc:    70.00%
  Val Top-5:  90.50%
  Val F1 (M): 68.73%

Epoch 20/30
  Train Loss: 0.0091
  Train Acc:  100.00%
  CE Loss:    0.0091
  KD Loss:    13.2046
  Val Loss:   1.4251
  Val Acc:    69.00%
  Val Top-5:  91.00%
  Val F1 (M): 67.34%

Epoch 21/30
  Train Loss: 0.0084
  Train Acc:  99.98%
  CE Loss:    0.0084
  KD Loss:    13.3459
  Val Loss:   1.4473
  Val Acc:    68.17%
  Val Top-5:  91.17%
  Val F1 (M): 66.48%

Epoch 22/30
  Train Loss: 0.0068
  Train Acc:  100.00%
  CE Loss:    0.0068
  KD Loss:    13.4686
  Val Loss:   1.4845
  Val Acc:    70.00%
  Val Top-5:  90.17%
  Val F1 (M): 68.56%

Epoch 23/30
  Train Loss: 0.0081
  Train Acc:  99.98%
  CE Loss:    0.0081
  KD Loss:    13.6348
  Val Loss:   1.4489
  Val Acc:    70.33%
  Val Top-5:  90.33%
  Val F1 (M): 69.38%
  Saved best model to outputs/mobilenetv3_large_attention_kd/best_model.pth

Epoch 24/30
  Train Loss: 0.0072
  Train Acc:  99.98%
  CE Loss:    0.0072
  KD Loss:    13.6022
  Val Loss:   1.4242
  Val Acc:    70.67%
  Val Top-5:  91.00%
  Val F1 (M): 69.20%
  Saved best model to outputs/mobilenetv3_large_attention_kd/best_model.pth

Epoch 25/30
  Train Loss: 0.0048
  Train Acc:  100.00%
  CE Loss:    0.0048
  KD Loss:    13.7482
  Val Loss:   1.3903
  Val Acc:    70.83%
  Val Top-5:  91.33%
  Val F1 (M): 69.80%
  Saved best model to outputs/mobilenetv3_large_attention_kd/best_model.pth

Epoch 26/30
  Train Loss: 0.0049
  Train Acc:  99.98%
  CE Loss:    0.0049
  KD Loss:    13.8421
  Val Loss:   1.4132
  Val Acc:    71.00%
  Val Top-5:  90.83%
  Val F1 (M): 69.88%
  Saved best model to outputs/mobilenetv3_large_attention_kd/best_model.pth

Epoch 27/30
  Train Loss: 0.0047
  Train Acc:  99.98%
  CE Loss:    0.0047
  KD Loss:    13.8564
  Val Loss:   1.4118
  Val Acc:    71.33%
  Val Top-5:  90.83%
  Val F1 (M): 70.58%
  Saved best model to outputs/mobilenetv3_large_attention_kd/best_model.pth

Epoch 28/30
  Train Loss: 0.0046
  Train Acc:  99.98%
  CE Loss:    0.0046
  KD Loss:    13.9030
  Val Loss:   1.3860
  Val Acc:    71.83%
  Val Top-5:  90.67%
  Val F1 (M): 70.58%
  Saved best model to outputs/mobilenetv3_large_attention_kd/best_model.pth

Epoch 29/30
  Train Loss: 0.0041
  Train Acc:  99.96%
  CE Loss:    0.0041
  KD Loss:    14.0138
  Val Loss:   1.4139
  Val Acc:    70.67%
  Val Top-5:  89.67%
  Val F1 (M): 69.43%

Epoch 30/30
  Train Loss: 0.0042
  Train Acc:  99.94%
  CE Loss:    0.0042
  KD Loss:    14.0497
  Val Loss:   1.4086
  Val Acc:    71.33%
  Val Top-5:  90.83%
  Val F1 (M): 70.23%
  Test Acc:   72.04%
  Test Top-5: 91.75%
  Test F1 (M):72.01%

============================================================
Training completed in 413.64s
Best validation accuracy: 71.83%
============================================================


Results saved to: outputs/mobilenetv3_large_attention_kd
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: mobilenetv3_large_combined_kd
Student Architecture: mobilenetv3_large
Distillation Type: combined
Device: cuda
Seed: 42

Configuration saved to: outputs/mobilenetv3_large_combined_kd/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: mobilenetv3_large
  Total parameters: 4,458,232
  Trainable parameters: 4,458,232

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01

Setting up knowledge distillation...
  Teacher: openai/clip-vit-base-patch32
  Distillation type: combined
  Alpha CE: 1.0
  Alpha KD: 1.0
  Alpha Attention: 0.1
  Attention loss: mse


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 7.6607
  Train Acc:  25.32%
  CE Loss:    3.5866
  KD Loss:    4.0741
  Val Loss:   1.8589
  Val Acc:    47.17%
  Val Top-5:  82.17%
  Val F1 (M): 44.34%
  Saved best model to outputs/mobilenetv3_large_combined_kd/best_model.pth

Epoch 2/30
  Train Loss: 3.7279
  Train Acc:  64.81%
  CE Loss:    1.6454
  KD Loss:    2.0826
  Val Loss:   1.3553
  Val Acc:    61.83%
  Val Top-5:  90.33%
  Val F1 (M): 59.00%
  Saved best model to outputs/mobilenetv3_large_combined_kd/best_model.pth

Epoch 3/30
  Train Loss: 2.9876
  Train Acc:  78.31%
  CE Loss:    1.1531
  KD Loss:    1.8345
  Val Loss:   1.2058
  Val Acc:    66.83%
  Val Top-5:  92.33%
  Val F1 (M): 65.36%
  Saved best model to outputs/mobilenetv3_large_combined_kd/best_model.pth

Epoch 4/30
  Train Loss: 2.6153
  Train Acc:  85.57%
  CE Loss:    0.8986
  KD Loss:    1.7167
  Val Loss:   1.1347
  Val Acc:    66.00%
  Val Top-5:  93.17%
  Val F1 (M): 63.88%

Epoch 5/30
  Train Loss: 2.3914
  Train Acc:  90.12%
  CE Loss:    0.7419
  KD Loss:    1.6496
  Val Loss:   1.0860
  Val Acc:    70.33%
  Val Top-5:  92.17%
  Val F1 (M): 68.71%
  Saved best model to outputs/mobilenetv3_large_combined_kd/best_model.pth

Epoch 6/30
  Train Loss: 2.1961
  Train Acc:  93.21%
  CE Loss:    0.6361
  KD Loss:    1.5600
  Val Loss:   1.0546
  Val Acc:    68.83%
  Val Top-5:  93.33%
  Val F1 (M): 67.28%

Epoch 7/30
  Train Loss: 2.0500
  Train Acc:  95.59%
  CE Loss:    0.5396
  KD Loss:    1.5104
  Val Loss:   1.0407
  Val Acc:    72.00%
  Val Top-5:  93.83%
  Val F1 (M): 70.76%
  Saved best model to outputs/mobilenetv3_large_combined_kd/best_model.pth

Epoch 8/30
  Train Loss: 1.9333
  Train Acc:  97.04%
  CE Loss:    0.4774
  KD Loss:    1.4559
  Val Loss:   1.0399
  Val Acc:    72.00%
  Val Top-5:  94.17%
  Val F1 (M): 71.05%

Epoch 9/30
  Train Loss: 1.8643
  Train Acc:  97.41%
  CE Loss:    0.4426
  KD Loss:    1.4217
  Val Loss:   1.0191
  Val Acc:    73.67%
  Val Top-5:  93.67%
  Val F1 (M): 72.69%
  Saved best model to outputs/mobilenetv3_large_combined_kd/best_model.pth

Epoch 10/30
  Train Loss: 1.7881
  Train Acc:  98.12%
  CE Loss:    0.4071
  KD Loss:    1.3810
  Val Loss:   1.0166
  Val Acc:    72.17%
  Val Top-5:  94.00%
  Val F1 (M): 70.82%

Epoch 11/30
  Train Loss: 1.7351
  Train Acc:  98.64%
  CE Loss:    0.3702
  KD Loss:    1.3649
  Val Loss:   1.0197
  Val Acc:    72.67%
  Val Top-5:  93.67%
  Val F1 (M): 71.55%

Epoch 12/30
  Train Loss: 1.6867
  Train Acc:  98.83%
  CE Loss:    0.3553
  KD Loss:    1.3314
  Val Loss:   1.0029
  Val Acc:    73.67%
  Val Top-5:  93.50%
  Val F1 (M): 72.22%

Epoch 13/30
  Train Loss: 1.6101
  Train Acc:  98.98%
  CE Loss:    0.3259
  KD Loss:    1.2842
  Val Loss:   1.0071
  Val Acc:    72.83%
  Val Top-5:  93.17%
  Val F1 (M): 71.43%

Epoch 14/30
  Train Loss: 1.5722
  Train Acc:  98.75%
  CE Loss:    0.3182
  KD Loss:    1.2540
  Val Loss:   1.0103
  Val Acc:    72.67%
  Val Top-5:  93.67%
  Val F1 (M): 71.08%

Epoch 15/30
  Train Loss: 1.5312
  Train Acc:  99.22%
  CE Loss:    0.2984
  KD Loss:    1.2328
  Val Loss:   1.0127
  Val Acc:    72.67%
  Val Top-5:  94.50%
  Val F1 (M): 72.17%

Epoch 16/30
  Train Loss: 1.5147
  Train Acc:  99.33%
  CE Loss:    0.2908
  KD Loss:    1.2239
  Val Loss:   0.9936
  Val Acc:    74.67%
  Val Top-5:  94.17%
  Val F1 (M): 73.77%
  Saved best model to outputs/mobilenetv3_large_combined_kd/best_model.pth

Epoch 17/30
  Train Loss: 1.4943
  Train Acc:  99.40%
  CE Loss:    0.2853
  KD Loss:    1.2090
  Val Loss:   0.9672
  Val Acc:    73.17%
  Val Top-5:  94.00%
  Val F1 (M): 72.03%

Epoch 18/30
  Train Loss: 1.4542
  Train Acc:  99.50%
  CE Loss:    0.2682
  KD Loss:    1.1860
  Val Loss:   0.9837
  Val Acc:    73.83%
  Val Top-5:  94.50%
  Val F1 (M): 72.58%

Epoch 19/30
  Train Loss: 1.4283
  Train Acc:  99.33%
  CE Loss:    0.2666
  KD Loss:    1.1617
  Val Loss:   1.0006
  Val Acc:    73.67%
  Val Top-5:  94.67%
  Val F1 (M): 72.46%

Epoch 20/30
  Train Loss: 1.4114
  Train Acc:  99.57%
  CE Loss:    0.2560
  KD Loss:    1.1555
  Val Loss:   1.0081
  Val Acc:    73.50%
  Val Top-5:  93.83%
  Val F1 (M): 72.27%

Epoch 21/30
  Train Loss: 1.4003
  Train Acc:  99.39%
  CE Loss:    0.2522
  KD Loss:    1.1481
  Val Loss:   1.0188
  Val Acc:    73.00%
  Val Top-5:  93.33%
  Val F1 (M): 71.68%

Epoch 22/30
  Train Loss: 1.3764
  Train Acc:  99.61%
  CE Loss:    0.2441
  KD Loss:    1.1323
  Val Loss:   1.0016
  Val Acc:    72.67%
  Val Top-5:  94.17%
  Val F1 (M): 71.50%

Epoch 23/30
  Train Loss: 1.3665
  Train Acc:  99.46%
  CE Loss:    0.2491
  KD Loss:    1.1175
  Val Loss:   1.0044
  Val Acc:    74.00%
  Val Top-5:  94.17%
  Val F1 (M): 73.09%

Epoch 24/30
  Train Loss: 1.3349
  Train Acc:  99.57%
  CE Loss:    0.2393
  KD Loss:    1.0956
  Val Loss:   0.9874
  Val Acc:    75.50%
  Val Top-5:  94.50%
  Val F1 (M): 74.34%
  Saved best model to outputs/mobilenetv3_large_combined_kd/best_model.pth

Epoch 25/30
  Train Loss: 1.3381
  Train Acc:  99.65%
  CE Loss:    0.2375
  KD Loss:    1.1005
  Val Loss:   0.9905
  Val Acc:    75.17%
  Val Top-5:  94.17%
  Val F1 (M): 73.90%

Epoch 26/30
  Train Loss: 1.3275
  Train Acc:  99.57%
  CE Loss:    0.2379
  KD Loss:    1.0895
  Val Loss:   1.0057
  Val Acc:    74.67%
  Val Top-5:  94.50%
  Val F1 (M): 73.54%

Epoch 27/30
  Train Loss: 1.3138
  Train Acc:  99.46%
  CE Loss:    0.2349
  KD Loss:    1.0789
  Val Loss:   0.9933
  Val Acc:    75.00%
  Val Top-5:  94.67%
  Val F1 (M): 74.02%

Epoch 28/30
  Train Loss: 1.3117
  Train Acc:  99.59%
  CE Loss:    0.2328
  KD Loss:    1.0789
  Val Loss:   0.9989
  Val Acc:    73.83%
  Val Top-5:  94.33%
  Val F1 (M): 72.64%

Epoch 29/30
  Train Loss: 1.3040
  Train Acc:  99.61%
  CE Loss:    0.2308
  KD Loss:    1.0732
  Val Loss:   1.0147
  Val Acc:    73.83%
  Val Top-5:  94.50%
  Val F1 (M): 72.45%

Epoch 30/30
  Train Loss: 1.3080
  Train Acc:  99.61%
  CE Loss:    0.2285
  KD Loss:    1.0795
  Val Loss:   0.9928
  Val Acc:    74.50%
  Val Top-5:  94.50%
  Val F1 (M): 73.30%
  Test Acc:   76.44%
  Test Top-5: 94.05%
  Test F1 (M):76.37%

============================================================
Training completed in 414.99s
Best validation accuracy: 75.50%
============================================================


Results saved to: outputs/mobilenetv3_large_combined_kd
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: efficientnet_b0_scratch
Student Architecture: efficientnet_b0
Distillation Type: none
Device: cuda
Seed: 42

Configuration saved to: outputs/efficientnet_b0_scratch/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: efficientnet_b0
  Total parameters: 4,263,748
  Trainable parameters: 4,263,748

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 5.4006
  Train Acc:  0.63%
  Val Loss:   7.5214
  Val Acc:    1.00%
  Val Top-5:  6.17%
  Val F1 (M): 0.36%
  Saved best model to outputs/efficientnet_b0_scratch/best_model.pth

Epoch 2/30
  Train Loss: 5.1775
  Train Acc:  1.15%
  Val Loss:   5.4145
  Val Acc:    0.83%
  Val Top-5:  7.83%
  Val F1 (M): 0.31%

Epoch 3/30
  Train Loss: 4.9963
  Train Acc:  1.73%
  Val Loss:   5.3273
  Val Acc:    3.00%
  Val Top-5:  10.67%
  Val F1 (M): 1.12%
  Saved best model to outputs/efficientnet_b0_scratch/best_model.pth

Epoch 4/30
  Train Loss: 4.7899
  Train Acc:  3.16%
  Val Loss:   5.0826
  Val Acc:    4.00%
  Val Top-5:  16.17%
  Val F1 (M): 1.62%
  Saved best model to outputs/efficientnet_b0_scratch/best_model.pth

Epoch 5/30
  Train Loss: 4.5616
  Train Acc:  4.45%
  Val Loss:   4.6368
  Val Acc:    5.50%
  Val Top-5:  20.67%
  Val F1 (M): 3.50%
  Saved best model to outputs/efficientnet_b0_scratch/best_model.pth

Epoch 6/30
  Train Loss: 4.3664
  Train Acc:  6.27%
  Val Loss:   4.3326
  Val Acc:    8.67%
  Val Top-5:  25.83%
  Val F1 (M): 5.53%
  Saved best model to outputs/efficientnet_b0_scratch/best_model.pth

Epoch 7/30
  Train Loss: 4.1466
  Train Acc:  9.06%
  Val Loss:   4.1632
  Val Acc:    9.17%
  Val Top-5:  29.17%
  Val F1 (M): 6.50%
  Saved best model to outputs/efficientnet_b0_scratch/best_model.pth

Epoch 8/30
  Train Loss: 3.9719
  Train Acc:  11.12%
  Val Loss:   4.0469
  Val Acc:    11.83%
  Val Top-5:  33.67%
  Val F1 (M): 7.88%
  Saved best model to outputs/efficientnet_b0_scratch/best_model.pth

Epoch 9/30
  Train Loss: 3.7827
  Train Acc:  13.02%
  Val Loss:   3.8935
  Val Acc:    13.50%
  Val Top-5:  36.67%
  Val F1 (M): 10.05%
  Saved best model to outputs/efficientnet_b0_scratch/best_model.pth

Epoch 10/30
  Train Loss: 3.6246
  Train Acc:  15.94%
  Val Loss:   3.7663
  Val Acc:    15.83%
  Val Top-5:  37.00%
  Val F1 (M): 11.66%
  Saved best model to outputs/efficientnet_b0_scratch/best_model.pth

Epoch 11/30
  Train Loss: 3.4800
  Train Acc:  18.19%
  Val Loss:   3.6862
  Val Acc:    16.50%
  Val Top-5:  41.67%
  Val F1 (M): 12.87%
  Saved best model to outputs/efficientnet_b0_scratch/best_model.pth

Epoch 12/30
  Train Loss: 3.2872
  Train Acc:  20.59%
  Val Loss:   3.6759
  Val Acc:    18.50%
  Val Top-5:  43.00%
  Val F1 (M): 15.46%
  Saved best model to outputs/efficientnet_b0_scratch/best_model.pth

Epoch 13/30
  Train Loss: 3.1396
  Train Acc:  24.13%
  Val Loss:   3.4868
  Val Acc:    21.33%
  Val Top-5:  47.00%
  Val F1 (M): 17.70%
  Saved best model to outputs/efficientnet_b0_scratch/best_model.pth

Epoch 14/30
  Train Loss: 2.9687
  Train Acc:  27.33%
  Val Loss:   3.4515
  Val Acc:    22.17%
  Val Top-5:  48.17%
  Val F1 (M): 19.02%
  Saved best model to outputs/efficientnet_b0_scratch/best_model.pth

Epoch 15/30
  Train Loss: 2.8363
  Train Acc:  29.78%
  Val Loss:   3.4049
  Val Acc:    22.33%
  Val Top-5:  49.33%
  Val F1 (M): 19.11%
  Saved best model to outputs/efficientnet_b0_scratch/best_model.pth

Epoch 16/30
  Train Loss: 2.6949
  Train Acc:  32.78%
  Val Loss:   3.3884
  Val Acc:    23.83%
  Val Top-5:  50.50%
  Val F1 (M): 21.43%
  Saved best model to outputs/efficientnet_b0_scratch/best_model.pth

Epoch 17/30
  Train Loss: 2.5806
  Train Acc:  35.44%
  Val Loss:   3.3183
  Val Acc:    23.33%
  Val Top-5:  52.67%
  Val F1 (M): 20.97%

Epoch 18/30
  Train Loss: 2.4624
  Train Acc:  37.57%
  Val Loss:   3.3029
  Val Acc:    24.00%
  Val Top-5:  51.67%
  Val F1 (M): 20.88%
  Saved best model to outputs/efficientnet_b0_scratch/best_model.pth

Epoch 19/30
  Train Loss: 2.3311
  Train Acc:  40.14%
  Val Loss:   3.3034
  Val Acc:    23.67%
  Val Top-5:  51.00%
  Val F1 (M): 21.31%

Epoch 20/30
  Train Loss: 2.2391
  Train Acc:  42.84%
  Val Loss:   3.2416
  Val Acc:    23.50%
  Val Top-5:  53.33%
  Val F1 (M): 21.37%

Epoch 21/30
  Train Loss: 2.1299
  Train Acc:  46.09%
  Val Loss:   3.2249
  Val Acc:    25.17%
  Val Top-5:  52.17%
  Val F1 (M): 22.97%
  Saved best model to outputs/efficientnet_b0_scratch/best_model.pth

Epoch 22/30
  Train Loss: 2.0539
  Train Acc:  47.02%
  Val Loss:   3.1869
  Val Acc:    24.00%
  Val Top-5:  53.33%
  Val F1 (M): 21.67%

Epoch 23/30
  Train Loss: 1.9777
  Train Acc:  50.20%
  Val Loss:   3.1971
  Val Acc:    26.17%
  Val Top-5:  52.67%
  Val F1 (M): 24.15%
  Saved best model to outputs/efficientnet_b0_scratch/best_model.pth

Epoch 24/30
  Train Loss: 1.9247
  Train Acc:  50.74%
  Val Loss:   3.1929
  Val Acc:    25.50%
  Val Top-5:  53.50%
  Val F1 (M): 23.05%

Epoch 25/30
  Train Loss: 1.8730
  Train Acc:  52.66%
  Val Loss:   3.1835
  Val Acc:    26.00%
  Val Top-5:  54.33%
  Val F1 (M): 23.54%

Epoch 26/30
  Train Loss: 1.8146
  Train Acc:  54.39%
  Val Loss:   3.1944
  Val Acc:    26.83%
  Val Top-5:  53.83%
  Val F1 (M): 24.88%
  Saved best model to outputs/efficientnet_b0_scratch/best_model.pth

Epoch 27/30
  Train Loss: 1.7856
  Train Acc:  56.25%
  Val Loss:   3.1940
  Val Acc:    26.00%
  Val Top-5:  53.83%
  Val F1 (M): 24.05%

Epoch 28/30
  Train Loss: 1.7795
  Train Acc:  55.65%
  Val Loss:   3.2054
  Val Acc:    26.33%
  Val Top-5:  54.00%
  Val F1 (M): 24.30%

Epoch 29/30
  Train Loss: 1.7519
  Train Acc:  55.77%
  Val Loss:   3.1747
  Val Acc:    26.50%
  Val Top-5:  53.67%
  Val F1 (M): 24.59%

Epoch 30/30
  Train Loss: 1.7514
  Train Acc:  56.49%
  Val Loss:   3.1921
  Val Acc:    26.50%
  Val Top-5:  54.33%
  Val F1 (M): 24.22%
  Test Acc:   26.67%
  Test Top-5: 54.35%
  Test F1 (M):25.80%

============================================================
Training completed in 348.94s
Best validation accuracy: 26.83%
============================================================


Results saved to: outputs/efficientnet_b0_scratch
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: efficientnet_b0_transfer
Student Architecture: efficientnet_b0
Distillation Type: none
Device: cuda
Seed: 42

Configuration saved to: outputs/efficientnet_b0_transfer/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: efficientnet_b0
  Total parameters: 4,263,748
  Trainable parameters: 4,263,748

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 4.1366
  Train Acc:  16.78%
  Val Loss:   2.3583
  Val Acc:    42.67%
  Val Top-5:  77.00%
  Val F1 (M): 37.92%
  Saved best model to outputs/efficientnet_b0_transfer/best_model.pth

Epoch 2/30
  Train Loss: 1.7284
  Train Acc:  59.17%
  Val Loss:   1.4035
  Val Acc:    60.50%
  Val Top-5:  90.17%
  Val F1 (M): 58.32%
  Saved best model to outputs/efficientnet_b0_transfer/best_model.pth

Epoch 3/30
  Train Loss: 0.8951
  Train Acc:  78.18%
  Val Loss:   1.1546
  Val Acc:    65.50%
  Val Top-5:  91.50%
  Val F1 (M): 64.40%
  Saved best model to outputs/efficientnet_b0_transfer/best_model.pth

Epoch 4/30
  Train Loss: 0.5232
  Train Acc:  87.46%
  Val Loss:   1.0772
  Val Acc:    72.33%
  Val Top-5:  93.67%
  Val F1 (M): 70.97%
  Saved best model to outputs/efficientnet_b0_transfer/best_model.pth

Epoch 5/30
  Train Loss: 0.2943
  Train Acc:  93.69%
  Val Loss:   1.0428
  Val Acc:    70.33%
  Val Top-5:  94.00%
  Val F1 (M): 68.85%

Epoch 6/30
  Train Loss: 0.1737
  Train Acc:  96.91%
  Val Loss:   1.0225
  Val Acc:    73.83%
  Val Top-5:  93.33%
  Val F1 (M): 73.13%
  Saved best model to outputs/efficientnet_b0_transfer/best_model.pth

Epoch 7/30
  Train Loss: 0.1113
  Train Acc:  98.36%
  Val Loss:   1.0333
  Val Acc:    73.00%
  Val Top-5:  93.33%
  Val F1 (M): 72.36%

Epoch 8/30
  Train Loss: 0.0823
  Train Acc:  98.66%
  Val Loss:   1.0758
  Val Acc:    73.17%
  Val Top-5:  93.00%
  Val F1 (M): 71.93%

Epoch 9/30
  Train Loss: 0.0606
  Train Acc:  99.29%
  Val Loss:   1.0321
  Val Acc:    75.50%
  Val Top-5:  93.67%
  Val F1 (M): 74.62%
  Saved best model to outputs/efficientnet_b0_transfer/best_model.pth

Epoch 10/30
  Train Loss: 0.0487
  Train Acc:  99.29%
  Val Loss:   1.0693
  Val Acc:    73.83%
  Val Top-5:  93.00%
  Val F1 (M): 72.70%

Epoch 11/30
  Train Loss: 0.0360
  Train Acc:  99.61%
  Val Loss:   1.0791
  Val Acc:    74.00%
  Val Top-5:  93.00%
  Val F1 (M): 73.29%

Epoch 12/30
  Train Loss: 0.0333
  Train Acc:  99.61%
  Val Loss:   1.0928
  Val Acc:    74.17%
  Val Top-5:  93.00%
  Val F1 (M): 73.49%

Epoch 13/30
  Train Loss: 0.0253
  Train Acc:  99.68%
  Val Loss:   1.1203
  Val Acc:    74.17%
  Val Top-5:  92.67%
  Val F1 (M): 73.19%

Epoch 14/30
  Train Loss: 0.0165
  Train Acc:  100.00%
  Val Loss:   1.0997
  Val Acc:    75.17%
  Val Top-5:  93.00%
  Val F1 (M): 74.09%

Epoch 15/30
  Train Loss: 0.0156
  Train Acc:  99.83%
  Val Loss:   1.0856
  Val Acc:    74.67%
  Val Top-5:  92.67%
  Val F1 (M): 74.03%

Epoch 16/30
  Train Loss: 0.0159
  Train Acc:  99.83%
  Val Loss:   1.0848
  Val Acc:    75.00%
  Val Top-5:  92.17%
  Val F1 (M): 73.70%

Epoch 17/30
  Train Loss: 0.0134
  Train Acc:  99.87%
  Val Loss:   1.1021
  Val Acc:    75.17%
  Val Top-5:  92.67%
  Val F1 (M): 73.82%

Epoch 18/30
  Train Loss: 0.0125
  Train Acc:  99.87%
  Val Loss:   1.0797
  Val Acc:    74.83%
  Val Top-5:  93.83%
  Val F1 (M): 73.51%

Epoch 19/30
  Train Loss: 0.0109
  Train Acc:  99.91%
  Val Loss:   1.0800
  Val Acc:    75.00%
  Val Top-5:  93.33%
  Val F1 (M): 73.91%

Epoch 20/30
  Train Loss: 0.0090
  Train Acc:  99.94%
  Val Loss:   1.0883
  Val Acc:    74.00%
  Val Top-5:  93.33%
  Val F1 (M): 72.78%

Epoch 21/30
  Train Loss: 0.0072
  Train Acc:  99.98%
  Val Loss:   1.0752
  Val Acc:    74.50%
  Val Top-5:  93.17%
  Val F1 (M): 73.55%

Epoch 22/30
  Train Loss: 0.0063
  Train Acc:  100.00%
  Val Loss:   1.0824
  Val Acc:    75.17%
  Val Top-5:  93.17%
  Val F1 (M): 74.25%

Epoch 23/30
  Train Loss: 0.0061
  Train Acc:  99.98%
  Val Loss:   1.0754
  Val Acc:    75.50%
  Val Top-5:  94.17%
  Val F1 (M): 74.37%

Epoch 24/30
  Train Loss: 0.0056
  Train Acc:  100.00%
  Val Loss:   1.0751
  Val Acc:    75.17%
  Val Top-5:  93.50%
  Val F1 (M): 73.97%

Epoch 25/30
  Train Loss: 0.0049
  Train Acc:  100.00%
  Val Loss:   1.0763
  Val Acc:    75.00%
  Val Top-5:  93.67%
  Val F1 (M): 73.67%

Epoch 26/30
  Train Loss: 0.0051
  Train Acc:  99.98%
  Val Loss:   1.0897
  Val Acc:    75.00%
  Val Top-5:  93.33%
  Val F1 (M): 73.65%

Epoch 27/30
  Train Loss: 0.0055
  Train Acc:  99.98%
  Val Loss:   1.0904
  Val Acc:    75.17%
  Val Top-5:  93.67%
  Val F1 (M): 73.91%

Epoch 28/30
  Train Loss: 0.0040
  Train Acc:  100.00%
  Val Loss:   1.0907
  Val Acc:    75.17%
  Val Top-5:  93.83%
  Val F1 (M): 73.90%

Epoch 29/30
  Train Loss: 0.0049
  Train Acc:  99.96%
  Val Loss:   1.0819
  Val Acc:    74.83%
  Val Top-5:  94.00%
  Val F1 (M): 73.60%

Epoch 30/30
  Train Loss: 0.0050
  Train Acc:  100.00%
  Val Loss:   1.0674
  Val Acc:    75.67%
  Val Top-5:  93.83%
  Val F1 (M): 74.60%
  Saved best model to outputs/efficientnet_b0_transfer/best_model.pth
  Test Acc:   76.61%
  Test Top-5: 93.06%
  Test F1 (M):76.47%

============================================================
Training completed in 348.76s
Best validation accuracy: 75.67%
============================================================


Results saved to: outputs/efficientnet_b0_transfer
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: efficientnet_b0_logit_kd
Student Architecture: efficientnet_b0
Distillation Type: logit
Device: cuda
Seed: 42

Configuration saved to: outputs/efficientnet_b0_logit_kd/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: efficientnet_b0
  Total parameters: 4,263,748
  Trainable parameters: 4,263,748

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01

Setting up knowledge distillation...
  Teacher: openai/clip-vit-base-patch32
  Distillation type: logit
  Alpha CE: 1.0
  Alpha KD: 1.0


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 7.8975
  Train Acc:  23.53%
  CE Loss:    3.6479
  KD Loss:    4.2496
  Val Loss:   1.9865
  Val Acc:    45.50%
  Val Top-5:  81.00%
  Val F1 (M): 41.16%
  Saved best model to outputs/efficientnet_b0_logit_kd/best_model.pth

Epoch 2/30
  Train Loss: 3.7933
  Train Acc:  60.71%
  CE Loss:    1.7887
  KD Loss:    2.0046
  Val Loss:   1.2952
  Val Acc:    62.83%
  Val Top-5:  92.33%
  Val F1 (M): 59.78%
  Saved best model to outputs/efficientnet_b0_logit_kd/best_model.pth

Epoch 3/30
  Train Loss: 2.9891
  Train Acc:  75.54%
  CE Loss:    1.2283
  KD Loss:    1.7608
  Val Loss:   1.0870
  Val Acc:    71.33%
  Val Top-5:  93.67%
  Val F1 (M): 69.58%
  Saved best model to outputs/efficientnet_b0_logit_kd/best_model.pth

Epoch 4/30
  Train Loss: 2.6336
  Train Acc:  83.89%
  CE Loss:    0.9602
  KD Loss:    1.6734
  Val Loss:   1.0039
  Val Acc:    72.00%
  Val Top-5:  94.50%
  Val F1 (M): 70.54%
  Saved best model to outputs/efficientnet_b0_logit_kd/best_model.pth

Epoch 5/30
  Train Loss: 2.3541
  Train Acc:  89.68%
  CE Loss:    0.7651
  KD Loss:    1.5890
  Val Loss:   0.9563
  Val Acc:    75.50%
  Val Top-5:  94.67%
  Val F1 (M): 73.69%
  Saved best model to outputs/efficientnet_b0_logit_kd/best_model.pth

Epoch 6/30
  Train Loss: 2.1861
  Train Acc:  92.93%
  CE Loss:    0.6403
  KD Loss:    1.5458
  Val Loss:   0.9492
  Val Acc:    75.83%
  Val Top-5:  95.50%
  Val F1 (M): 74.36%
  Saved best model to outputs/efficientnet_b0_logit_kd/best_model.pth

Epoch 7/30
  Train Loss: 2.0215
  Train Acc:  95.50%
  CE Loss:    0.5434
  KD Loss:    1.4781
  Val Loss:   0.9393
  Val Acc:    74.50%
  Val Top-5:  94.33%
  Val F1 (M): 73.35%

Epoch 8/30
  Train Loss: 1.9457
  Train Acc:  96.93%
  CE Loss:    0.4752
  KD Loss:    1.4704
  Val Loss:   0.9721
  Val Acc:    75.00%
  Val Top-5:  94.67%
  Val F1 (M): 73.56%

Epoch 9/30
  Train Loss: 1.8299
  Train Acc:  97.82%
  CE Loss:    0.4262
  KD Loss:    1.4037
  Val Loss:   0.9264
  Val Acc:    76.83%
  Val Top-5:  94.83%
  Val F1 (M): 75.44%
  Saved best model to outputs/efficientnet_b0_logit_kd/best_model.pth

Epoch 10/30
  Train Loss: 1.7335
  Train Acc:  98.66%
  CE Loss:    0.3727
  KD Loss:    1.3608
  Val Loss:   0.9507
  Val Acc:    76.17%
  Val Top-5:  94.17%
  Val F1 (M): 75.16%

Epoch 11/30
  Train Loss: 1.7031
  Train Acc:  99.01%
  CE Loss:    0.3535
  KD Loss:    1.3496
  Val Loss:   0.9536
  Val Acc:    76.00%
  Val Top-5:  94.50%
  Val F1 (M): 75.10%

Epoch 12/30
  Train Loss: 1.6420
  Train Acc:  99.14%
  CE Loss:    0.3262
  KD Loss:    1.3158
  Val Loss:   0.9576
  Val Acc:    74.67%
  Val Top-5:  94.17%
  Val F1 (M): 73.74%

Epoch 13/30
  Train Loss: 1.6022
  Train Acc:  99.16%
  CE Loss:    0.3140
  KD Loss:    1.2882
  Val Loss:   0.9533
  Val Acc:    76.00%
  Val Top-5:  94.33%
  Val F1 (M): 74.83%

Epoch 14/30
  Train Loss: 1.5662
  Train Acc:  99.46%
  CE Loss:    0.2928
  KD Loss:    1.2734
  Val Loss:   0.9584
  Val Acc:    75.67%
  Val Top-5:  93.83%
  Val F1 (M): 74.58%

Epoch 15/30
  Train Loss: 1.5204
  Train Acc:  99.57%
  CE Loss:    0.2838
  KD Loss:    1.2366
  Val Loss:   0.9503
  Val Acc:    78.17%
  Val Top-5:  94.67%
  Val F1 (M): 77.41%
  Saved best model to outputs/efficientnet_b0_logit_kd/best_model.pth

Epoch 16/30
  Train Loss: 1.4969
  Train Acc:  99.39%
  CE Loss:    0.2742
  KD Loss:    1.2227
  Val Loss:   0.9388
  Val Acc:    76.50%
  Val Top-5:  94.33%
  Val F1 (M): 75.31%

Epoch 17/30
  Train Loss: 1.4659
  Train Acc:  99.55%
  CE Loss:    0.2597
  KD Loss:    1.2062
  Val Loss:   0.9414
  Val Acc:    76.83%
  Val Top-5:  94.83%
  Val F1 (M): 75.68%

Epoch 18/30
  Train Loss: 1.4329
  Train Acc:  99.55%
  CE Loss:    0.2577
  KD Loss:    1.1752
  Val Loss:   0.9411
  Val Acc:    78.00%
  Val Top-5:  95.00%
  Val F1 (M): 76.70%

Epoch 19/30
  Train Loss: 1.4195
  Train Acc:  99.59%
  CE Loss:    0.2544
  KD Loss:    1.1651
  Val Loss:   0.9792
  Val Acc:    75.67%
  Val Top-5:  94.50%
  Val F1 (M): 74.76%

Epoch 20/30
  Train Loss: 1.3966
  Train Acc:  99.63%
  CE Loss:    0.2439
  KD Loss:    1.1527
  Val Loss:   0.9655
  Val Acc:    76.00%
  Val Top-5:  93.83%
  Val F1 (M): 74.93%

Epoch 21/30
  Train Loss: 1.3631
  Train Acc:  99.59%
  CE Loss:    0.2356
  KD Loss:    1.1274
  Val Loss:   0.9544
  Val Acc:    75.67%
  Val Top-5:  94.67%
  Val F1 (M): 74.66%

Epoch 22/30
  Train Loss: 1.3602
  Train Acc:  99.63%
  CE Loss:    0.2369
  KD Loss:    1.1233
  Val Loss:   0.9556
  Val Acc:    76.67%
  Val Top-5:  94.17%
  Val F1 (M): 75.87%

Epoch 23/30
  Train Loss: 1.3471
  Train Acc:  99.78%
  CE Loss:    0.2300
  KD Loss:    1.1170
  Val Loss:   0.9508
  Val Acc:    76.67%
  Val Top-5:  95.17%
  Val F1 (M): 75.44%

Epoch 24/30
  Train Loss: 1.3250
  Train Acc:  99.70%
  CE Loss:    0.2218
  KD Loss:    1.1032
  Val Loss:   0.9705
  Val Acc:    76.00%
  Val Top-5:  93.83%
  Val F1 (M): 74.47%

Epoch 25/30
  Train Loss: 1.3124
  Train Acc:  99.68%
  CE Loss:    0.2246
  KD Loss:    1.0878
  Val Loss:   0.9542
  Val Acc:    76.00%
  Val Top-5:  94.83%
  Val F1 (M): 74.80%

Epoch 26/30
  Train Loss: 1.3129
  Train Acc:  99.68%
  CE Loss:    0.2197
  KD Loss:    1.0931
  Val Loss:   0.9506
  Val Acc:    75.83%
  Val Top-5:  95.33%
  Val F1 (M): 74.76%

Epoch 27/30
  Train Loss: 1.3112
  Train Acc:  99.76%
  CE Loss:    0.2233
  KD Loss:    1.0879
  Val Loss:   0.9682
  Val Acc:    76.67%
  Val Top-5:  93.67%
  Val F1 (M): 75.44%

Epoch 28/30
  Train Loss: 1.2982
  Train Acc:  99.61%
  CE Loss:    0.2183
  KD Loss:    1.0799
  Val Loss:   0.9626
  Val Acc:    76.83%
  Val Top-5:  93.83%
  Val F1 (M): 75.86%

Epoch 29/30
  Train Loss: 1.2832
  Train Acc:  99.63%
  CE Loss:    0.2121
  KD Loss:    1.0711
  Val Loss:   0.9647
  Val Acc:    77.17%
  Val Top-5:  94.50%
  Val F1 (M): 76.10%

Epoch 30/30
  Train Loss: 1.2868
  Train Acc:  99.74%
  CE Loss:    0.2160
  KD Loss:    1.0708
  Val Loss:   0.9658
  Val Acc:    75.83%
  Val Top-5:  94.83%
  Val F1 (M): 74.90%
  Test Acc:   77.77%
  Test Top-5: 94.37%
  Test F1 (M):77.74%

============================================================
Training completed in 379.35s
Best validation accuracy: 78.17%
============================================================


Results saved to: outputs/efficientnet_b0_logit_kd
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: efficientnet_b0_attention_kd
Student Architecture: efficientnet_b0
Distillation Type: attention
Device: cuda
Seed: 42

Configuration saved to: outputs/efficientnet_b0_attention_kd/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: efficientnet_b0
  Total parameters: 4,263,748
  Trainable parameters: 4,263,748

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01

Setting up knowledge distillation...
  Teacher: openai/clip-vit-base-patch32
  Distillation type: attention
  Alpha CE: 1.0
  Alpha KD: 0.0
  Alpha Attention: 0.5
  Attention loss: mse


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 4.0970
  Train Acc:  24.27%
  CE Loss:    4.0970
  KD Loss:    6.6595
  Val Loss:   2.2713
  Val Acc:    46.83%
  Val Top-5:  79.33%
  Val F1 (M): 42.23%
  Saved best model to outputs/efficientnet_b0_attention_kd/best_model.pth

Epoch 2/30
  Train Loss: 1.6926
  Train Acc:  69.07%
  CE Loss:    1.6926
  KD Loss:    4.7479
  Val Loss:   1.3529
  Val Acc:    62.00%
  Val Top-5:  92.17%
  Val F1 (M): 58.63%
  Saved best model to outputs/efficientnet_b0_attention_kd/best_model.pth

Epoch 3/30
  Train Loss: 0.8951
  Train Acc:  86.44%
  CE Loss:    0.8951
  KD Loss:    4.6310
  Val Loss:   1.1465
  Val Acc:    67.67%
  Val Top-5:  93.50%
  Val F1 (M): 66.00%
  Saved best model to outputs/efficientnet_b0_attention_kd/best_model.pth

Epoch 4/30
  Train Loss: 0.5242
  Train Acc:  94.08%
  CE Loss:    0.5242
  KD Loss:    4.8634
  Val Loss:   1.0497
  Val Acc:    70.00%
  Val Top-5:  93.67%
  Val F1 (M): 68.49%
  Saved best model to outputs/efficientnet_b0_attention_kd/best_model.pth

Epoch 5/30
  Train Loss: 0.3024
  Train Acc:  98.16%
  CE Loss:    0.3024
  KD Loss:    5.0617
  Val Loss:   1.0474
  Val Acc:    71.50%
  Val Top-5:  92.67%
  Val F1 (M): 69.58%
  Saved best model to outputs/efficientnet_b0_attention_kd/best_model.pth

Epoch 6/30
  Train Loss: 0.1915
  Train Acc:  99.33%
  CE Loss:    0.1915
  KD Loss:    5.3434
  Val Loss:   1.0563
  Val Acc:    72.33%
  Val Top-5:  93.33%
  Val F1 (M): 70.61%
  Saved best model to outputs/efficientnet_b0_attention_kd/best_model.pth

Epoch 7/30
  Train Loss: 0.1163
  Train Acc:  99.80%
  CE Loss:    0.1163
  KD Loss:    5.5460
  Val Loss:   1.0078
  Val Acc:    74.83%
  Val Top-5:  93.17%
  Val F1 (M): 73.88%
  Saved best model to outputs/efficientnet_b0_attention_kd/best_model.pth

Epoch 8/30
  Train Loss: 0.0833
  Train Acc:  99.93%
  CE Loss:    0.0833
  KD Loss:    5.7703
  Val Loss:   1.0225
  Val Acc:    72.83%
  Val Top-5:  94.50%
  Val F1 (M): 71.64%

Epoch 9/30
  Train Loss: 0.0605
  Train Acc:  99.96%
  CE Loss:    0.0605
  KD Loss:    5.9439
  Val Loss:   1.0088
  Val Acc:    73.83%
  Val Top-5:  92.67%
  Val F1 (M): 72.32%

Epoch 10/30
  Train Loss: 0.0413
  Train Acc:  100.00%
  CE Loss:    0.0413
  KD Loss:    6.0970
  Val Loss:   1.0299
  Val Acc:    73.83%
  Val Top-5:  93.83%
  Val F1 (M): 72.54%

Epoch 11/30
  Train Loss: 0.0310
  Train Acc:  100.00%
  CE Loss:    0.0310
  KD Loss:    6.2695
  Val Loss:   1.0657
  Val Acc:    74.83%
  Val Top-5:  92.00%
  Val F1 (M): 73.56%

Epoch 12/30
  Train Loss: 0.0265
  Train Acc:  100.00%
  CE Loss:    0.0265
  KD Loss:    6.3909
  Val Loss:   1.0569
  Val Acc:    73.50%
  Val Top-5:  93.00%
  Val F1 (M): 71.88%

Epoch 13/30
  Train Loss: 0.0235
  Train Acc:  100.00%
  CE Loss:    0.0235
  KD Loss:    6.5129
  Val Loss:   1.0806
  Val Acc:    73.50%
  Val Top-5:  92.17%
  Val F1 (M): 71.64%

Epoch 14/30
  Train Loss: 0.0192
  Train Acc:  100.00%
  CE Loss:    0.0192
  KD Loss:    6.5991
  Val Loss:   1.0301
  Val Acc:    75.33%
  Val Top-5:  93.17%
  Val F1 (M): 73.75%
  Saved best model to outputs/efficientnet_b0_attention_kd/best_model.pth

Epoch 15/30
  Train Loss: 0.0176
  Train Acc:  100.00%
  CE Loss:    0.0176
  KD Loss:    6.7078
  Val Loss:   1.0512
  Val Acc:    74.50%
  Val Top-5:  92.33%
  Val F1 (M): 73.20%

Epoch 16/30
  Train Loss: 0.0144
  Train Acc:  100.00%
  CE Loss:    0.0144
  KD Loss:    6.8011
  Val Loss:   1.0590
  Val Acc:    73.50%
  Val Top-5:  92.67%
  Val F1 (M): 72.44%

Epoch 17/30
  Train Loss: 0.0110
  Train Acc:  100.00%
  CE Loss:    0.0110
  KD Loss:    6.9046
  Val Loss:   1.0440
  Val Acc:    73.17%
  Val Top-5:  92.50%
  Val F1 (M): 71.58%

Epoch 18/30
  Train Loss: 0.0091
  Train Acc:  100.00%
  CE Loss:    0.0091
  KD Loss:    7.0166
  Val Loss:   1.0444
  Val Acc:    74.33%
  Val Top-5:  92.83%
  Val F1 (M): 72.93%

Epoch 19/30
  Train Loss: 0.0081
  Train Acc:  100.00%
  CE Loss:    0.0081
  KD Loss:    7.0585
  Val Loss:   1.0511
  Val Acc:    73.67%
  Val Top-5:  93.00%
  Val F1 (M): 72.32%

Epoch 20/30
  Train Loss: 0.0091
  Train Acc:  100.00%
  CE Loss:    0.0091
  KD Loss:    7.1075
  Val Loss:   1.0588
  Val Acc:    74.83%
  Val Top-5:  92.83%
  Val F1 (M): 73.73%

Epoch 21/30
  Train Loss: 0.0089
  Train Acc:  100.00%
  CE Loss:    0.0089
  KD Loss:    7.1680
  Val Loss:   1.0328
  Val Acc:    75.00%
  Val Top-5:  93.33%
  Val F1 (M): 73.72%

Epoch 22/30
  Train Loss: 0.0069
  Train Acc:  100.00%
  CE Loss:    0.0069
  KD Loss:    7.2326
  Val Loss:   1.0499
  Val Acc:    74.17%
  Val Top-5:  92.83%
  Val F1 (M): 72.90%

Epoch 23/30
  Train Loss: 0.0066
  Train Acc:  100.00%
  CE Loss:    0.0066
  KD Loss:    7.2835
  Val Loss:   1.0733
  Val Acc:    75.00%
  Val Top-5:  92.67%
  Val F1 (M): 73.47%

Epoch 24/30
  Train Loss: 0.0066
  Train Acc:  99.98%
  CE Loss:    0.0066
  KD Loss:    7.3212
  Val Loss:   1.0689
  Val Acc:    75.50%
  Val Top-5:  92.83%
  Val F1 (M): 74.04%
  Saved best model to outputs/efficientnet_b0_attention_kd/best_model.pth

Epoch 25/30
  Train Loss: 0.0054
  Train Acc:  100.00%
  CE Loss:    0.0054
  KD Loss:    7.3399
  Val Loss:   1.0633
  Val Acc:    74.83%
  Val Top-5:  92.00%
  Val F1 (M): 73.28%

Epoch 26/30
  Train Loss: 0.0052
  Train Acc:  99.98%
  CE Loss:    0.0052
  KD Loss:    7.3826
  Val Loss:   1.0422
  Val Acc:    75.33%
  Val Top-5:  92.50%
  Val F1 (M): 73.99%

Epoch 27/30
  Train Loss: 0.0048
  Train Acc:  100.00%
  CE Loss:    0.0048
  KD Loss:    7.3746
  Val Loss:   1.0711
  Val Acc:    74.00%
  Val Top-5:  92.67%
  Val F1 (M): 72.56%

Epoch 28/30
  Train Loss: 0.0048
  Train Acc:  100.00%
  CE Loss:    0.0048
  KD Loss:    7.4421
  Val Loss:   1.0582
  Val Acc:    74.17%
  Val Top-5:  93.17%
  Val F1 (M): 72.41%

Epoch 29/30
  Train Loss: 0.0050
  Train Acc:  100.00%
  CE Loss:    0.0050
  KD Loss:    7.4034
  Val Loss:   1.0681
  Val Acc:    75.83%
  Val Top-5:  93.33%
  Val F1 (M): 74.48%
  Saved best model to outputs/efficientnet_b0_attention_kd/best_model.pth

Epoch 30/30
  Train Loss: 0.0053
  Train Acc:  99.98%
  CE Loss:    0.0053
  KD Loss:    7.4220
  Val Loss:   1.0554
  Val Acc:    75.50%
  Val Top-5:  92.67%
  Val F1 (M): 74.03%
  Test Acc:   75.25%
  Test Top-5: 93.23%
  Test F1 (M):75.17%

============================================================
Training completed in 491.83s
Best validation accuracy: 75.83%
============================================================


Results saved to: outputs/efficientnet_b0_attention_kd
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: efficientnet_b0_combined_kd
Student Architecture: efficientnet_b0
Distillation Type: combined
Device: cuda
Seed: 42

Configuration saved to: outputs/efficientnet_b0_combined_kd/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: efficientnet_b0
  Total parameters: 4,263,748
  Trainable parameters: 4,263,748

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01

Setting up knowledge distillation...
  Teacher: openai/clip-vit-base-patch32
  Distillation type: combined
  Alpha CE: 1.0
  Alpha KD: 1.0
  Alpha Attention: 0.1
  Attention loss: mse


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 7.8975
  Train Acc:  23.53%
  CE Loss:    3.6479
  KD Loss:    4.2496
  Val Loss:   1.9937
  Val Acc:    45.17%
  Val Top-5:  81.00%
  Val F1 (M): 41.40%
  Saved best model to outputs/efficientnet_b0_combined_kd/best_model.pth

Epoch 2/30
  Train Loss: 3.7933
  Train Acc:  60.71%
  CE Loss:    1.7887
  KD Loss:    2.0046
  Val Loss:   1.2965
  Val Acc:    63.00%
  Val Top-5:  92.50%
  Val F1 (M): 59.78%
  Saved best model to outputs/efficientnet_b0_combined_kd/best_model.pth

Epoch 3/30
  Train Loss: 2.9891
  Train Acc:  75.54%
  CE Loss:    1.2283
  KD Loss:    1.7608
  Val Loss:   1.0960
  Val Acc:    71.50%
  Val Top-5:  93.67%
  Val F1 (M): 69.69%
  Saved best model to outputs/efficientnet_b0_combined_kd/best_model.pth

Epoch 4/30
  Train Loss: 2.6336
  Train Acc:  83.89%
  CE Loss:    0.9602
  KD Loss:    1.6734
  Val Loss:   1.0083
  Val Acc:    71.83%
  Val Top-5:  94.33%
  Val F1 (M): 70.36%
  Saved best model to outputs/efficientnet_b0_combined_kd/best_model.pth

Epoch 5/30
  Train Loss: 2.3541
  Train Acc:  89.68%
  CE Loss:    0.7651
  KD Loss:    1.5890
  Val Loss:   0.9606
  Val Acc:    75.50%
  Val Top-5:  94.67%
  Val F1 (M): 73.82%
  Saved best model to outputs/efficientnet_b0_combined_kd/best_model.pth

Epoch 6/30
  Train Loss: 2.1861
  Train Acc:  92.93%
  CE Loss:    0.6403
  KD Loss:    1.5458
  Val Loss:   0.9537
  Val Acc:    75.67%
  Val Top-5:  95.50%
  Val F1 (M): 74.32%
  Saved best model to outputs/efficientnet_b0_combined_kd/best_model.pth

Epoch 7/30
  Train Loss: 2.0215
  Train Acc:  95.50%
  CE Loss:    0.5434
  KD Loss:    1.4781
  Val Loss:   0.9440
  Val Acc:    74.83%
  Val Top-5:  94.50%
  Val F1 (M): 73.84%

Epoch 8/30
  Train Loss: 1.9457
  Train Acc:  96.93%
  CE Loss:    0.4752
  KD Loss:    1.4704
  Val Loss:   0.9750
  Val Acc:    75.33%
  Val Top-5:  94.50%
  Val F1 (M): 73.82%

Epoch 9/30
  Train Loss: 1.8299
  Train Acc:  97.82%
  CE Loss:    0.4262
  KD Loss:    1.4037
  Val Loss:   0.9290
  Val Acc:    76.50%
  Val Top-5:  94.67%
  Val F1 (M): 75.15%
  Saved best model to outputs/efficientnet_b0_combined_kd/best_model.pth

Epoch 10/30
  Train Loss: 1.7335
  Train Acc:  98.66%
  CE Loss:    0.3727
  KD Loss:    1.3608
  Val Loss:   0.9577
  Val Acc:    76.00%
  Val Top-5:  94.17%
  Val F1 (M): 75.07%

Epoch 11/30
  Train Loss: 1.7031
  Train Acc:  99.01%
  CE Loss:    0.3535
  KD Loss:    1.3496
  Val Loss:   0.9628
  Val Acc:    76.00%
  Val Top-5:  94.33%
  Val F1 (M): 75.02%

Epoch 12/30
  Train Loss: 1.6420
  Train Acc:  99.14%
  CE Loss:    0.3262
  KD Loss:    1.3158
  Val Loss:   0.9601
  Val Acc:    74.67%
  Val Top-5:  94.50%
  Val F1 (M): 73.79%

Epoch 13/30
  Train Loss: 1.6022
  Train Acc:  99.16%
  CE Loss:    0.3140
  KD Loss:    1.2882
  Val Loss:   0.9619
  Val Acc:    76.00%
  Val Top-5:  94.33%
  Val F1 (M): 74.79%

Epoch 14/30
  Train Loss: 1.5662
  Train Acc:  99.46%
  CE Loss:    0.2928
  KD Loss:    1.2734
  Val Loss:   0.9640
  Val Acc:    75.00%
  Val Top-5:  94.17%
  Val F1 (M): 73.78%

Epoch 15/30
  Train Loss: 1.5204
  Train Acc:  99.57%
  CE Loss:    0.2838
  KD Loss:    1.2366
  Val Loss:   0.9577
  Val Acc:    77.83%
  Val Top-5:  94.33%
  Val F1 (M): 77.14%
  Saved best model to outputs/efficientnet_b0_combined_kd/best_model.pth

Epoch 16/30
  Train Loss: 1.4969
  Train Acc:  99.39%
  CE Loss:    0.2742
  KD Loss:    1.2227
  Val Loss:   0.9471
  Val Acc:    76.17%
  Val Top-5:  94.50%
  Val F1 (M): 75.04%

Epoch 17/30
  Train Loss: 1.4659
  Train Acc:  99.55%
  CE Loss:    0.2597
  KD Loss:    1.2062
  Val Loss:   0.9450
  Val Acc:    76.17%
  Val Top-5:  94.83%
  Val F1 (M): 75.06%

Epoch 18/30
  Train Loss: 1.4329
  Train Acc:  99.55%
  CE Loss:    0.2577
  KD Loss:    1.1752
  Val Loss:   0.9428
  Val Acc:    78.33%
  Val Top-5:  95.00%
  Val F1 (M): 77.02%
  Saved best model to outputs/efficientnet_b0_combined_kd/best_model.pth

Epoch 19/30
  Train Loss: 1.4195
  Train Acc:  99.59%
  CE Loss:    0.2544
  KD Loss:    1.1651
  Val Loss:   0.9866
  Val Acc:    75.00%
  Val Top-5:  94.33%
  Val F1 (M): 74.10%

Epoch 20/30
  Train Loss: 1.3966
  Train Acc:  99.63%
  CE Loss:    0.2439
  KD Loss:    1.1527
  Val Loss:   0.9698
  Val Acc:    76.33%
  Val Top-5:  94.17%
  Val F1 (M): 75.23%

Epoch 21/30
  Train Loss: 1.3631
  Train Acc:  99.59%
  CE Loss:    0.2356
  KD Loss:    1.1274
  Val Loss:   0.9599
  Val Acc:    75.50%
  Val Top-5:  94.83%
  Val F1 (M): 74.51%

Epoch 22/30
  Train Loss: 1.3602
  Train Acc:  99.63%
  CE Loss:    0.2369
  KD Loss:    1.1233
  Val Loss:   0.9609
  Val Acc:    75.83%
  Val Top-5:  93.67%
  Val F1 (M): 74.96%

Epoch 23/30
  Train Loss: 1.3471
  Train Acc:  99.78%
  CE Loss:    0.2300
  KD Loss:    1.1170
  Val Loss:   0.9548
  Val Acc:    76.50%
  Val Top-5:  94.83%
  Val F1 (M): 75.02%

Epoch 24/30
  Train Loss: 1.3250
  Train Acc:  99.70%
  CE Loss:    0.2218
  KD Loss:    1.1032
  Val Loss:   0.9760
  Val Acc:    75.83%
  Val Top-5:  94.00%
  Val F1 (M): 74.22%

Epoch 25/30
  Train Loss: 1.3124
  Train Acc:  99.68%
  CE Loss:    0.2246
  KD Loss:    1.0878
  Val Loss:   0.9576
  Val Acc:    76.00%
  Val Top-5:  94.83%
  Val F1 (M): 74.89%

Epoch 26/30
  Train Loss: 1.3129
  Train Acc:  99.68%
  CE Loss:    0.2197
  KD Loss:    1.0931
  Val Loss:   0.9526
  Val Acc:    75.83%
  Val Top-5:  94.83%
  Val F1 (M): 74.70%

Epoch 27/30
  Train Loss: 1.3112
  Train Acc:  99.76%
  CE Loss:    0.2233
  KD Loss:    1.0879
  Val Loss:   0.9750
  Val Acc:    77.00%
  Val Top-5:  93.50%
  Val F1 (M): 75.78%

Epoch 28/30
  Train Loss: 1.2982
  Train Acc:  99.61%
  CE Loss:    0.2183
  KD Loss:    1.0799
  Val Loss:   0.9678
  Val Acc:    76.67%
  Val Top-5:  93.50%
  Val F1 (M): 75.68%

Epoch 29/30
  Train Loss: 1.2832
  Train Acc:  99.63%
  CE Loss:    0.2121
  KD Loss:    1.0711
  Val Loss:   0.9698
  Val Acc:    77.00%
  Val Top-5:  94.17%
  Val F1 (M): 75.82%

Epoch 30/30
  Train Loss: 1.2868
  Train Acc:  99.74%
  CE Loss:    0.2160
  KD Loss:    1.0708
  Val Loss:   0.9703
  Val Acc:    75.83%
  Val Top-5:  94.67%
  Val F1 (M): 74.87%
  Test Acc:   77.56%
  Test Top-5: 94.29%
  Test F1 (M):77.55%

============================================================
Training completed in 489.27s
Best validation accuracy: 78.33%
============================================================


Results saved to: outputs/efficientnet_b0_combined_kd
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: efficientnet_b1_scratch
Student Architecture: efficientnet_b1
Distillation Type: none
Device: cuda
Seed: 42

Configuration saved to: outputs/efficientnet_b1_scratch/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: efficientnet_b1
  Total parameters: 6,769,384
  Trainable parameters: 6,769,384

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 5.4300
  Train Acc:  0.58%
  Val Loss:   7.1191
  Val Acc:    1.33%
  Val Top-5:  5.33%
  Val F1 (M): 0.27%
  Saved best model to outputs/efficientnet_b1_scratch/best_model.pth

Epoch 2/30
  Train Loss: 5.2852
  Train Acc:  0.84%
  Val Loss:   6.3702
  Val Acc:    1.17%
  Val Top-5:  5.67%
  Val F1 (M): 0.34%

Epoch 3/30
  Train Loss: 5.1238
  Train Acc:  1.10%
  Val Loss:   5.5001
  Val Acc:    2.33%
  Val Top-5:  10.00%
  Val F1 (M): 0.65%
  Saved best model to outputs/efficientnet_b1_scratch/best_model.pth

Epoch 4/30
  Train Loss: 4.9638
  Train Acc:  1.99%
  Val Loss:   5.0329
  Val Acc:    3.00%
  Val Top-5:  10.17%
  Val F1 (M): 0.90%
  Saved best model to outputs/efficientnet_b1_scratch/best_model.pth

Epoch 5/30
  Train Loss: 4.8358
  Train Acc:  2.53%
  Val Loss:   5.0627
  Val Acc:    2.83%
  Val Top-5:  13.33%
  Val F1 (M): 1.29%

Epoch 6/30
  Train Loss: 4.7115
  Train Acc:  3.18%
  Val Loss:   4.6714
  Val Acc:    4.67%
  Val Top-5:  16.83%
  Val F1 (M): 1.94%
  Saved best model to outputs/efficientnet_b1_scratch/best_model.pth

Epoch 7/30
  Train Loss: 4.5377
  Train Acc:  4.35%
  Val Loss:   4.6944
  Val Acc:    5.00%
  Val Top-5:  20.83%
  Val F1 (M): 3.23%
  Saved best model to outputs/efficientnet_b1_scratch/best_model.pth

Epoch 8/30
  Train Loss: 4.3543
  Train Acc:  6.55%
  Val Loss:   4.3337
  Val Acc:    6.33%
  Val Top-5:  24.33%
  Val F1 (M): 3.71%
  Saved best model to outputs/efficientnet_b1_scratch/best_model.pth

Epoch 9/30
  Train Loss: 4.1921
  Train Acc:  7.70%
  Val Loss:   4.2274
  Val Acc:    8.17%
  Val Top-5:  26.17%
  Val F1 (M): 5.43%
  Saved best model to outputs/efficientnet_b1_scratch/best_model.pth

Epoch 10/30
  Train Loss: 4.0524
  Train Acc:  9.13%
  Val Loss:   4.0921
  Val Acc:    10.17%
  Val Top-5:  30.67%
  Val F1 (M): 7.48%
  Saved best model to outputs/efficientnet_b1_scratch/best_model.pth

Epoch 11/30
  Train Loss: 3.9056
  Train Acc:  12.05%
  Val Loss:   4.0384
  Val Acc:    11.17%
  Val Top-5:  33.17%
  Val F1 (M): 8.16%
  Saved best model to outputs/efficientnet_b1_scratch/best_model.pth

Epoch 12/30
  Train Loss: 3.7714
  Train Acc:  12.70%
  Val Loss:   3.9498
  Val Acc:    12.00%
  Val Top-5:  34.83%
  Val F1 (M): 9.09%
  Saved best model to outputs/efficientnet_b1_scratch/best_model.pth

Epoch 13/30
  Train Loss: 3.6299
  Train Acc:  15.70%
  Val Loss:   3.7925
  Val Acc:    13.67%
  Val Top-5:  40.17%
  Val F1 (M): 10.86%
  Saved best model to outputs/efficientnet_b1_scratch/best_model.pth

Epoch 14/30
  Train Loss: 3.4911
  Train Acc:  17.63%
  Val Loss:   3.8156
  Val Acc:    12.83%
  Val Top-5:  38.67%
  Val F1 (M): 9.84%

Epoch 15/30
  Train Loss: 3.3583
  Train Acc:  19.96%
  Val Loss:   3.7584
  Val Acc:    16.17%
  Val Top-5:  41.83%
  Val F1 (M): 12.89%
  Saved best model to outputs/efficientnet_b1_scratch/best_model.pth

Epoch 16/30
  Train Loss: 3.1995
  Train Acc:  22.47%
  Val Loss:   3.6995
  Val Acc:    15.83%
  Val Top-5:  43.50%
  Val F1 (M): 13.96%

Epoch 17/30
  Train Loss: 3.0819
  Train Acc:  24.35%
  Val Loss:   3.6799
  Val Acc:    17.17%
  Val Top-5:  42.50%
  Val F1 (M): 14.71%
  Saved best model to outputs/efficientnet_b1_scratch/best_model.pth

Epoch 18/30
  Train Loss: 2.9438
  Train Acc:  27.27%
  Val Loss:   3.6213
  Val Acc:    17.67%
  Val Top-5:  44.00%
  Val F1 (M): 15.41%
  Saved best model to outputs/efficientnet_b1_scratch/best_model.pth

Epoch 19/30
  Train Loss: 2.8250
  Train Acc:  30.78%
  Val Loss:   3.5713
  Val Acc:    18.50%
  Val Top-5:  45.17%
  Val F1 (M): 16.70%
  Saved best model to outputs/efficientnet_b1_scratch/best_model.pth

Epoch 20/30
  Train Loss: 2.7191
  Train Acc:  32.31%
  Val Loss:   3.5635
  Val Acc:    19.33%
  Val Top-5:  46.17%
  Val F1 (M): 17.17%
  Saved best model to outputs/efficientnet_b1_scratch/best_model.pth

Epoch 21/30
  Train Loss: 2.6203
  Train Acc:  34.99%
  Val Loss:   3.4960
  Val Acc:    21.83%
  Val Top-5:  47.00%
  Val F1 (M): 19.00%
  Saved best model to outputs/efficientnet_b1_scratch/best_model.pth

Epoch 22/30
  Train Loss: 2.5194
  Train Acc:  37.30%
  Val Loss:   3.4660
  Val Acc:    22.33%
  Val Top-5:  46.17%
  Val F1 (M): 20.11%
  Saved best model to outputs/efficientnet_b1_scratch/best_model.pth

Epoch 23/30
  Train Loss: 2.4391
  Train Acc:  38.04%
  Val Loss:   3.4468
  Val Acc:    24.17%
  Val Top-5:  48.17%
  Val F1 (M): 21.87%
  Saved best model to outputs/efficientnet_b1_scratch/best_model.pth

Epoch 24/30
  Train Loss: 2.3355
  Train Acc:  41.54%
  Val Loss:   3.4370
  Val Acc:    23.83%
  Val Top-5:  47.83%
  Val F1 (M): 21.34%

Epoch 25/30
  Train Loss: 2.2949
  Train Acc:  42.69%
  Val Loss:   3.4564
  Val Acc:    23.50%
  Val Top-5:  46.17%
  Val F1 (M): 21.28%

Epoch 26/30
  Train Loss: 2.2401
  Train Acc:  44.46%
  Val Loss:   3.4615
  Val Acc:    22.17%
  Val Top-5:  46.50%
  Val F1 (M): 20.00%

Epoch 27/30
  Train Loss: 2.2253
  Train Acc:  44.96%
  Val Loss:   3.4475
  Val Acc:    23.83%
  Val Top-5:  48.50%
  Val F1 (M): 21.68%

Epoch 28/30
  Train Loss: 2.1915
  Train Acc:  45.03%
  Val Loss:   3.4476
  Val Acc:    23.67%
  Val Top-5:  47.50%
  Val F1 (M): 21.32%

Epoch 29/30
  Train Loss: 2.1847
  Train Acc:  45.00%
  Val Loss:   3.4267
  Val Acc:    23.33%
  Val Top-5:  48.50%
  Val F1 (M): 21.68%

Epoch 30/30
  Train Loss: 2.1864
  Train Acc:  45.41%
  Val Loss:   3.4327
  Val Acc:    23.17%
  Val Top-5:  48.00%
  Val F1 (M): 21.37%
  Test Acc:   22.40%
  Test Top-5: 49.67%
  Test F1 (M):21.36%

============================================================
Training completed in 364.21s
Best validation accuracy: 24.17%
============================================================


Results saved to: outputs/efficientnet_b1_scratch
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: efficientnet_b1_transfer
Student Architecture: efficientnet_b1
Distillation Type: none
Device: cuda
Seed: 42

Configuration saved to: outputs/efficientnet_b1_transfer/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: efficientnet_b1
  Total parameters: 6,769,384
  Trainable parameters: 6,769,384

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 4.1230
  Train Acc:  13.58%
  Val Loss:   2.6015
  Val Acc:    32.67%
  Val Top-5:  68.17%
  Val F1 (M): 28.48%
  Saved best model to outputs/efficientnet_b1_transfer/best_model.pth

Epoch 2/30
  Train Loss: 2.0481
  Train Acc:  45.87%
  Val Loss:   1.8794
  Val Acc:    50.50%
  Val Top-5:  77.17%
  Val F1 (M): 46.83%
  Saved best model to outputs/efficientnet_b1_transfer/best_model.pth

Epoch 3/30
  Train Loss: 1.3094
  Train Acc:  64.69%
  Val Loss:   1.6142
  Val Acc:    56.67%
  Val Top-5:  85.50%
  Val F1 (M): 55.30%
  Saved best model to outputs/efficientnet_b1_transfer/best_model.pth

Epoch 4/30
  Train Loss: 0.9393
  Train Acc:  73.85%
  Val Loss:   1.3820
  Val Acc:    62.83%
  Val Top-5:  89.83%
  Val F1 (M): 61.46%
  Saved best model to outputs/efficientnet_b1_transfer/best_model.pth

Epoch 5/30
  Train Loss: 0.6823
  Train Acc:  79.91%
  Val Loss:   1.4626
  Val Acc:    63.33%
  Val Top-5:  88.17%
  Val F1 (M): 60.67%
  Saved best model to outputs/efficientnet_b1_transfer/best_model.pth

Epoch 6/30
  Train Loss: 0.5219
  Train Acc:  84.41%
  Val Loss:   1.4501
  Val Acc:    62.50%
  Val Top-5:  87.67%
  Val F1 (M): 61.06%

Epoch 7/30
  Train Loss: 0.3797
  Train Acc:  89.04%
  Val Loss:   1.3827
  Val Acc:    66.50%
  Val Top-5:  88.33%
  Val F1 (M): 64.72%
  Saved best model to outputs/efficientnet_b1_transfer/best_model.pth

Epoch 8/30
  Train Loss: 0.2783
  Train Acc:  92.17%
  Val Loss:   1.4537
  Val Acc:    64.50%
  Val Top-5:  87.50%
  Val F1 (M): 62.65%

Epoch 9/30
  Train Loss: 0.2009
  Train Acc:  94.36%
  Val Loss:   1.3255
  Val Acc:    67.33%
  Val Top-5:  89.50%
  Val F1 (M): 66.19%
  Saved best model to outputs/efficientnet_b1_transfer/best_model.pth

Epoch 10/30
  Train Loss: 0.1518
  Train Acc:  95.91%
  Val Loss:   1.4042
  Val Acc:    66.00%
  Val Top-5:  90.67%
  Val F1 (M): 64.80%

Epoch 11/30
  Train Loss: 0.1228
  Train Acc:  96.82%
  Val Loss:   1.3425
  Val Acc:    67.33%
  Val Top-5:  90.67%
  Val F1 (M): 66.18%

Epoch 12/30
  Train Loss: 0.0931
  Train Acc:  97.67%
  Val Loss:   1.3540
  Val Acc:    66.83%
  Val Top-5:  91.33%
  Val F1 (M): 65.50%

Epoch 13/30
  Train Loss: 0.0595
  Train Acc:  98.70%
  Val Loss:   1.3760
  Val Acc:    67.33%
  Val Top-5:  91.17%
  Val F1 (M): 65.49%

Epoch 14/30
  Train Loss: 0.0550
  Train Acc:  98.55%
  Val Loss:   1.3255
  Val Acc:    69.33%
  Val Top-5:  91.33%
  Val F1 (M): 67.73%
  Saved best model to outputs/efficientnet_b1_transfer/best_model.pth

Epoch 15/30
  Train Loss: 0.0406
  Train Acc:  99.07%
  Val Loss:   1.3290
  Val Acc:    69.50%
  Val Top-5:  90.17%
  Val F1 (M): 68.51%
  Saved best model to outputs/efficientnet_b1_transfer/best_model.pth

Epoch 16/30
  Train Loss: 0.0326
  Train Acc:  99.27%
  Val Loss:   1.2967
  Val Acc:    70.83%
  Val Top-5:  90.83%
  Val F1 (M): 69.87%
  Saved best model to outputs/efficientnet_b1_transfer/best_model.pth

Epoch 17/30
  Train Loss: 0.0291
  Train Acc:  99.42%
  Val Loss:   1.2779
  Val Acc:    71.83%
  Val Top-5:  90.67%
  Val F1 (M): 70.89%
  Saved best model to outputs/efficientnet_b1_transfer/best_model.pth

Epoch 18/30
  Train Loss: 0.0172
  Train Acc:  99.72%
  Val Loss:   1.2068
  Val Acc:    74.33%
  Val Top-5:  91.17%
  Val F1 (M): 73.35%
  Saved best model to outputs/efficientnet_b1_transfer/best_model.pth

Epoch 19/30
  Train Loss: 0.0164
  Train Acc:  99.76%
  Val Loss:   1.2302
  Val Acc:    72.33%
  Val Top-5:  91.67%
  Val F1 (M): 71.10%

Epoch 20/30
  Train Loss: 0.0140
  Train Acc:  99.76%
  Val Loss:   1.2410
  Val Acc:    73.00%
  Val Top-5:  92.00%
  Val F1 (M): 72.06%

Epoch 21/30
  Train Loss: 0.0102
  Train Acc:  99.85%
  Val Loss:   1.2542
  Val Acc:    73.50%
  Val Top-5:  90.83%
  Val F1 (M): 72.61%

Epoch 22/30
  Train Loss: 0.0084
  Train Acc:  99.93%
  Val Loss:   1.2494
  Val Acc:    72.67%
  Val Top-5:  91.00%
  Val F1 (M): 72.10%

Epoch 23/30
  Train Loss: 0.0069
  Train Acc:  99.94%
  Val Loss:   1.2240
  Val Acc:    73.83%
  Val Top-5:  91.17%
  Val F1 (M): 73.14%

Epoch 24/30
  Train Loss: 0.0044
  Train Acc:  99.98%
  Val Loss:   1.2118
  Val Acc:    73.83%
  Val Top-5:  92.00%
  Val F1 (M): 73.07%

Epoch 25/30
  Train Loss: 0.0041
  Train Acc:  99.96%
  Val Loss:   1.2114
  Val Acc:    72.67%
  Val Top-5:  91.83%
  Val F1 (M): 71.80%

Epoch 26/30
  Train Loss: 0.0039
  Train Acc:  99.98%
  Val Loss:   1.2072
  Val Acc:    73.67%
  Val Top-5:  92.17%
  Val F1 (M): 72.70%

Epoch 27/30
  Train Loss: 0.0040
  Train Acc:  99.98%
  Val Loss:   1.2000
  Val Acc:    74.17%
  Val Top-5:  91.83%
  Val F1 (M): 73.41%

Epoch 28/30
  Train Loss: 0.0033
  Train Acc:  100.00%
  Val Loss:   1.1989
  Val Acc:    74.33%
  Val Top-5:  92.33%
  Val F1 (M): 73.59%

Epoch 29/30
  Train Loss: 0.0033
  Train Acc:  99.98%
  Val Loss:   1.1708
  Val Acc:    74.83%
  Val Top-5:  92.33%
  Val F1 (M): 73.98%
  Saved best model to outputs/efficientnet_b1_transfer/best_model.pth

Epoch 30/30
  Train Loss: 0.0032
  Train Acc:  99.98%
  Val Loss:   1.1866
  Val Acc:    74.67%
  Val Top-5:  92.67%
  Val F1 (M): 73.72%
  Test Acc:   74.21%
  Test Top-5: 92.18%
  Test F1 (M):74.04%

============================================================
Training completed in 362.52s
Best validation accuracy: 74.83%
============================================================


Results saved to: outputs/efficientnet_b1_transfer
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: efficientnet_b1_logit_kd
Student Architecture: efficientnet_b1
Distillation Type: logit
Device: cuda
Seed: 42

Configuration saved to: outputs/efficientnet_b1_logit_kd/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: efficientnet_b1
  Total parameters: 6,769,384
  Trainable parameters: 6,769,384

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01

Setting up knowledge distillation...
  Teacher: openai/clip-vit-base-patch32
  Distillation type: logit
  Alpha CE: 1.0
  Alpha KD: 1.0


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 7.4125
  Train Acc:  37.02%
  CE Loss:    3.4608
  KD Loss:    3.9517
  Val Loss:   2.0911
  Val Acc:    42.50%
  Val Top-5:  78.00%
  Val F1 (M): 37.50%
  Saved best model to outputs/efficientnet_b1_logit_kd/best_model.pth

Epoch 2/30
  Train Loss: 4.1229
  Train Acc:  64.04%
  CE Loss:    1.8771
  KD Loss:    2.2458
  Val Loss:   1.5240
  Val Acc:    56.67%
  Val Top-5:  86.83%
  Val F1 (M): 53.46%
  Saved best model to outputs/efficientnet_b1_logit_kd/best_model.pth

Epoch 3/30
  Train Loss: 3.3866
  Train Acc:  76.38%
  CE Loss:    1.3825
  KD Loss:    2.0041
  Val Loss:   1.2504
  Val Acc:    62.83%
  Val Top-5:  91.17%
  Val F1 (M): 61.10%
  Saved best model to outputs/efficientnet_b1_logit_kd/best_model.pth

Epoch 4/30
  Train Loss: 2.8976
  Train Acc:  84.67%
  CE Loss:    1.0652
  KD Loss:    1.8324
  Val Loss:   1.1187
  Val Acc:    69.17%
  Val Top-5:  92.83%
  Val F1 (M): 66.45%
  Saved best model to outputs/efficientnet_b1_logit_kd/best_model.pth

Epoch 5/30
  Train Loss: 2.6205
  Train Acc:  88.62%
  CE Loss:    0.8780
  KD Loss:    1.7425
  Val Loss:   1.0511
  Val Acc:    71.83%
  Val Top-5:  93.17%
  Val F1 (M): 70.22%
  Saved best model to outputs/efficientnet_b1_logit_kd/best_model.pth

Epoch 6/30
  Train Loss: 2.3955
  Train Acc:  93.06%
  CE Loss:    0.7166
  KD Loss:    1.6789
  Val Loss:   1.0551
  Val Acc:    69.00%
  Val Top-5:  93.17%
  Val F1 (M): 67.21%

Epoch 7/30
  Train Loss: 2.2586
  Train Acc:  94.90%
  CE Loss:    0.6289
  KD Loss:    1.6297
  Val Loss:   1.0410
  Val Acc:    72.00%
  Val Top-5:  92.67%
  Val F1 (M): 70.91%
  Saved best model to outputs/efficientnet_b1_logit_kd/best_model.pth

Epoch 8/30
  Train Loss: 2.1031
  Train Acc:  96.41%
  CE Loss:    0.5386
  KD Loss:    1.5645
  Val Loss:   1.0135
  Val Acc:    70.83%
  Val Top-5:  94.50%
  Val F1 (M): 69.53%

Epoch 9/30
  Train Loss: 1.9747
  Train Acc:  97.86%
  CE Loss:    0.4617
  KD Loss:    1.5130
  Val Loss:   0.9588
  Val Acc:    75.50%
  Val Top-5:  93.33%
  Val F1 (M): 74.29%
  Saved best model to outputs/efficientnet_b1_logit_kd/best_model.pth

Epoch 10/30
  Train Loss: 1.8846
  Train Acc:  98.29%
  CE Loss:    0.4152
  KD Loss:    1.4694
  Val Loss:   0.9544
  Val Acc:    77.50%
  Val Top-5:  93.33%
  Val F1 (M): 76.07%
  Saved best model to outputs/efficientnet_b1_logit_kd/best_model.pth

Epoch 11/30
  Train Loss: 1.7730
  Train Acc:  99.05%
  CE Loss:    0.3575
  KD Loss:    1.4155
  Val Loss:   0.9676
  Val Acc:    75.83%
  Val Top-5:  92.33%
  Val F1 (M): 74.97%

Epoch 12/30
  Train Loss: 1.7159
  Train Acc:  99.42%
  CE Loss:    0.3262
  KD Loss:    1.3897
  Val Loss:   0.9507
  Val Acc:    76.17%
  Val Top-5:  93.33%
  Val F1 (M): 74.97%

Epoch 13/30
  Train Loss: 1.6486
  Train Acc:  99.59%
  CE Loss:    0.3071
  KD Loss:    1.3414
  Val Loss:   0.9341
  Val Acc:    75.17%
  Val Top-5:  94.50%
  Val F1 (M): 73.76%

Epoch 14/30
  Train Loss: 1.6137
  Train Acc:  99.74%
  CE Loss:    0.2878
  KD Loss:    1.3259
  Val Loss:   0.9606
  Val Acc:    75.50%
  Val Top-5:  94.00%
  Val F1 (M): 73.86%

Epoch 15/30
  Train Loss: 1.5387
  Train Acc:  99.68%
  CE Loss:    0.2641
  KD Loss:    1.2747
  Val Loss:   0.9526
  Val Acc:    75.33%
  Val Top-5:  93.83%
  Val F1 (M): 74.05%

Epoch 16/30
  Train Loss: 1.4808
  Train Acc:  99.85%
  CE Loss:    0.2483
  KD Loss:    1.2325
  Val Loss:   0.9154
  Val Acc:    75.00%
  Val Top-5:  94.50%
  Val F1 (M): 73.97%

Epoch 17/30
  Train Loss: 1.4411
  Train Acc:  99.83%
  CE Loss:    0.2366
  KD Loss:    1.2045
  Val Loss:   0.8998
  Val Acc:    77.50%
  Val Top-5:  94.00%
  Val F1 (M): 76.38%

Epoch 18/30
  Train Loss: 1.4059
  Train Acc:  99.87%
  CE Loss:    0.2263
  KD Loss:    1.1795
  Val Loss:   0.9043
  Val Acc:    75.83%
  Val Top-5:  95.17%
  Val F1 (M): 74.98%

Epoch 19/30
  Train Loss: 1.3596
  Train Acc:  99.91%
  CE Loss:    0.2143
  KD Loss:    1.1453
  Val Loss:   0.9191
  Val Acc:    76.33%
  Val Top-5:  94.33%
  Val F1 (M): 75.40%

Epoch 20/30
  Train Loss: 1.3359
  Train Acc:  99.91%
  CE Loss:    0.2129
  KD Loss:    1.1231
  Val Loss:   0.9120
  Val Acc:    76.17%
  Val Top-5:  94.00%
  Val F1 (M): 74.99%

Epoch 21/30
  Train Loss: 1.3063
  Train Acc:  99.80%
  CE Loss:    0.2043
  KD Loss:    1.1020
  Val Loss:   0.9011
  Val Acc:    77.00%
  Val Top-5:  94.50%
  Val F1 (M): 76.04%

Epoch 22/30
  Train Loss: 1.2849
  Train Acc:  99.80%
  CE Loss:    0.1997
  KD Loss:    1.0852
  Val Loss:   0.9268
  Val Acc:    76.67%
  Val Top-5:  94.00%
  Val F1 (M): 75.77%

Epoch 23/30
  Train Loss: 1.2474
  Train Acc:  99.81%
  CE Loss:    0.1945
  KD Loss:    1.0529
  Val Loss:   0.9175
  Val Acc:    76.83%
  Val Top-5:  93.67%
  Val F1 (M): 75.84%

Epoch 24/30
  Train Loss: 1.2237
  Train Acc:  99.87%
  CE Loss:    0.1850
  KD Loss:    1.0387
  Val Loss:   0.9041
  Val Acc:    76.67%
  Val Top-5:  94.00%
  Val F1 (M): 75.48%

Epoch 25/30
  Train Loss: 1.2203
  Train Acc:  99.89%
  CE Loss:    0.1871
  KD Loss:    1.0332
  Val Loss:   0.8915
  Val Acc:    76.00%
  Val Top-5:  93.67%
  Val F1 (M): 75.17%

Epoch 26/30
  Train Loss: 1.1964
  Train Acc:  99.85%
  CE Loss:    0.1812
  KD Loss:    1.0153
  Val Loss:   0.9097
  Val Acc:    76.17%
  Val Top-5:  93.67%
  Val F1 (M): 75.47%

Epoch 27/30
  Train Loss: 1.1807
  Train Acc:  99.91%
  CE Loss:    0.1786
  KD Loss:    1.0022
  Val Loss:   0.8922
  Val Acc:    76.67%
  Val Top-5:  94.67%
  Val F1 (M): 75.44%

Epoch 28/30
  Train Loss: 1.1835
  Train Acc:  99.76%
  CE Loss:    0.1805
  KD Loss:    1.0029
  Val Loss:   0.9011
  Val Acc:    76.17%
  Val Top-5:  94.33%
  Val F1 (M): 75.11%

Epoch 29/30
  Train Loss: 1.1816
  Train Acc:  99.72%
  CE Loss:    0.1783
  KD Loss:    1.0033
  Val Loss:   0.9009
  Val Acc:    77.00%
  Val Top-5:  93.67%
  Val F1 (M): 76.10%

Epoch 30/30
  Train Loss: 1.1735
  Train Acc:  99.91%
  CE Loss:    0.1768
  KD Loss:    0.9967
  Val Loss:   0.8877
  Val Acc:    77.00%
  Val Top-5:  94.83%
  Val F1 (M): 75.85%
  Test Acc:   78.46%
  Test Top-5: 94.49%
  Test F1 (M):78.37%

============================================================
Training completed in 414.66s
Best validation accuracy: 77.50%
============================================================


Results saved to: outputs/efficientnet_b1_logit_kd
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: efficientnet_b1_attention_kd
Student Architecture: efficientnet_b1
Distillation Type: attention
Device: cuda
Seed: 42

Configuration saved to: outputs/efficientnet_b1_attention_kd/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: efficientnet_b1
  Total parameters: 6,769,384
  Trainable parameters: 6,769,384

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01

Setting up knowledge distillation...
  Teacher: openai/clip-vit-base-patch32
  Distillation type: attention
  Alpha CE: 1.0
  Alpha KD: 0.0
  Alpha Attention: 0.5
  Attention loss: mse


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 4.1127
  Train Acc:  33.52%
  CE Loss:    4.1127
  KD Loss:    6.5526
  Val Loss:   2.8225
  Val Acc:    28.33%
  Val Top-5:  64.33%
  Val F1 (M): 22.69%
  Saved best model to outputs/efficientnet_b1_attention_kd/best_model.pth

Epoch 2/30
  Train Loss: 2.1291
  Train Acc:  66.48%
  CE Loss:    2.1291
  KD Loss:    5.0771
  Val Loss:   1.7704
  Val Acc:    50.83%
  Val Top-5:  82.17%
  Val F1 (M): 46.61%
  Saved best model to outputs/efficientnet_b1_attention_kd/best_model.pth

Epoch 3/30
  Train Loss: 1.3445
  Train Acc:  83.17%
  CE Loss:    1.3445
  KD Loss:    4.9557
  Val Loss:   1.5706
  Val Acc:    57.83%
  Val Top-5:  85.83%
  Val F1 (M): 55.58%
  Saved best model to outputs/efficientnet_b1_attention_kd/best_model.pth

Epoch 4/30
  Train Loss: 0.9474
  Train Acc:  90.40%
  CE Loss:    0.9474
  KD Loss:    5.0523
  Val Loss:   1.3679
  Val Acc:    60.83%
  Val Top-5:  89.33%
  Val F1 (M): 58.72%
  Saved best model to outputs/efficientnet_b1_attention_kd/best_model.pth

Epoch 5/30
  Train Loss: 0.6878
  Train Acc:  94.79%
  CE Loss:    0.6878
  KD Loss:    5.2115
  Val Loss:   1.2928
  Val Acc:    67.00%
  Val Top-5:  90.33%
  Val F1 (M): 65.07%
  Saved best model to outputs/efficientnet_b1_attention_kd/best_model.pth

Epoch 6/30
  Train Loss: 0.5050
  Train Acc:  97.17%
  CE Loss:    0.5050
  KD Loss:    5.3989
  Val Loss:   1.3176
  Val Acc:    63.17%
  Val Top-5:  91.33%
  Val F1 (M): 60.81%

Epoch 7/30
  Train Loss: 0.3669
  Train Acc:  98.55%
  CE Loss:    0.3669
  KD Loss:    5.6113
  Val Loss:   1.3202
  Val Acc:    66.00%
  Val Top-5:  89.50%
  Val F1 (M): 63.98%

Epoch 8/30
  Train Loss: 0.2873
  Train Acc:  99.24%
  CE Loss:    0.2873
  KD Loss:    5.7662
  Val Loss:   1.4296
  Val Acc:    66.83%
  Val Top-5:  89.67%
  Val F1 (M): 66.08%

Epoch 9/30
  Train Loss: 0.1998
  Train Acc:  99.70%
  CE Loss:    0.1998
  KD Loss:    5.9531
  Val Loss:   1.3729
  Val Acc:    65.33%
  Val Top-5:  89.50%
  Val F1 (M): 63.66%

Epoch 10/30
  Train Loss: 0.1633
  Train Acc:  99.83%
  CE Loss:    0.1633
  KD Loss:    6.1171
  Val Loss:   1.3401
  Val Acc:    66.50%
  Val Top-5:  89.67%
  Val F1 (M): 65.41%

Epoch 11/30
  Train Loss: 0.1306
  Train Acc:  99.98%
  CE Loss:    0.1306
  KD Loss:    6.2322
  Val Loss:   1.2479
  Val Acc:    68.83%
  Val Top-5:  91.00%
  Val F1 (M): 67.89%
  Saved best model to outputs/efficientnet_b1_attention_kd/best_model.pth

Epoch 12/30
  Train Loss: 0.0960
  Train Acc:  99.93%
  CE Loss:    0.0960
  KD Loss:    6.4809
  Val Loss:   1.3238
  Val Acc:    67.00%
  Val Top-5:  90.83%
  Val F1 (M): 65.56%

Epoch 13/30
  Train Loss: 0.0707
  Train Acc:  100.00%
  CE Loss:    0.0707
  KD Loss:    6.6262
  Val Loss:   1.3332
  Val Acc:    68.17%
  Val Top-5:  90.83%
  Val F1 (M): 66.93%

Epoch 14/30
  Train Loss: 0.0644
  Train Acc:  99.96%
  CE Loss:    0.0644
  KD Loss:    6.7107
  Val Loss:   1.3173
  Val Acc:    68.17%
  Val Top-5:  90.83%
  Val F1 (M): 66.94%

Epoch 15/30
  Train Loss: 0.0477
  Train Acc:  99.98%
  CE Loss:    0.0477
  KD Loss:    6.8313
  Val Loss:   1.3065
  Val Acc:    70.00%
  Val Top-5:  90.33%
  Val F1 (M): 68.77%
  Saved best model to outputs/efficientnet_b1_attention_kd/best_model.pth

Epoch 16/30
  Train Loss: 0.0331
  Train Acc:  99.96%
  CE Loss:    0.0331
  KD Loss:    6.9757
  Val Loss:   1.2360
  Val Acc:    73.00%
  Val Top-5:  90.33%
  Val F1 (M): 71.85%
  Saved best model to outputs/efficientnet_b1_attention_kd/best_model.pth

Epoch 17/30
  Train Loss: 0.0225
  Train Acc:  100.00%
  CE Loss:    0.0225
  KD Loss:    7.1274
  Val Loss:   1.3099
  Val Acc:    71.33%
  Val Top-5:  90.50%
  Val F1 (M): 70.37%

Epoch 18/30
  Train Loss: 0.0148
  Train Acc:  100.00%
  CE Loss:    0.0148
  KD Loss:    7.2579
  Val Loss:   1.2087
  Val Acc:    72.83%
  Val Top-5:  92.33%
  Val F1 (M): 71.21%

Epoch 19/30
  Train Loss: 0.0123
  Train Acc:  100.00%
  CE Loss:    0.0123
  KD Loss:    7.3701
  Val Loss:   1.2226
  Val Acc:    72.33%
  Val Top-5:  91.67%
  Val F1 (M): 71.19%

Epoch 20/30
  Train Loss: 0.0095
  Train Acc:  99.98%
  CE Loss:    0.0095
  KD Loss:    7.3784
  Val Loss:   1.2275
  Val Acc:    72.33%
  Val Top-5:  90.17%
  Val F1 (M): 70.93%

Epoch 21/30
  Train Loss: 0.0094
  Train Acc:  100.00%
  CE Loss:    0.0094
  KD Loss:    7.4397
  Val Loss:   1.2076
  Val Acc:    73.17%
  Val Top-5:  92.33%
  Val F1 (M): 72.05%
  Saved best model to outputs/efficientnet_b1_attention_kd/best_model.pth

Epoch 22/30
  Train Loss: 0.0067
  Train Acc:  100.00%
  CE Loss:    0.0067
  KD Loss:    7.4662
  Val Loss:   1.1985
  Val Acc:    72.00%
  Val Top-5:  92.50%
  Val F1 (M): 70.46%

Epoch 23/30
  Train Loss: 0.0065
  Train Acc:  100.00%
  CE Loss:    0.0065
  KD Loss:    7.5697
  Val Loss:   1.2201
  Val Acc:    72.67%
  Val Top-5:  91.67%
  Val F1 (M): 71.38%

Epoch 24/30
  Train Loss: 0.0060
  Train Acc:  100.00%
  CE Loss:    0.0060
  KD Loss:    7.6265
  Val Loss:   1.2063
  Val Acc:    73.67%
  Val Top-5:  92.33%
  Val F1 (M): 72.23%
  Saved best model to outputs/efficientnet_b1_attention_kd/best_model.pth

Epoch 25/30
  Train Loss: 0.0042
  Train Acc:  100.00%
  CE Loss:    0.0042
  KD Loss:    7.6737
  Val Loss:   1.1909
  Val Acc:    73.00%
  Val Top-5:  91.50%
  Val F1 (M): 71.50%

Epoch 26/30
  Train Loss: 0.0034
  Train Acc:  100.00%
  CE Loss:    0.0034
  KD Loss:    7.7155
  Val Loss:   1.1885
  Val Acc:    72.00%
  Val Top-5:  92.17%
  Val F1 (M): 70.71%

Epoch 27/30
  Train Loss: 0.0035
  Train Acc:  100.00%
  CE Loss:    0.0035
  KD Loss:    7.6969
  Val Loss:   1.1940
  Val Acc:    73.00%
  Val Top-5:  91.50%
  Val F1 (M): 71.53%

Epoch 28/30
  Train Loss: 0.0034
  Train Acc:  100.00%
  CE Loss:    0.0034
  KD Loss:    7.7322
  Val Loss:   1.1668
  Val Acc:    72.67%
  Val Top-5:  92.33%
  Val F1 (M): 71.01%

Epoch 29/30
  Train Loss: 0.0035
  Train Acc:  99.96%
  CE Loss:    0.0035
  KD Loss:    7.7447
  Val Loss:   1.2304
  Val Acc:    73.17%
  Val Top-5:  91.67%
  Val F1 (M): 71.35%

Epoch 30/30
  Train Loss: 0.0033
  Train Acc:  99.96%
  CE Loss:    0.0033
  KD Loss:    7.7507
  Val Loss:   1.1672
  Val Acc:    74.17%
  Val Top-5:  92.33%
  Val F1 (M): 72.81%
  Saved best model to outputs/efficientnet_b1_attention_kd/best_model.pth
  Test Acc:   74.53%
  Test Top-5: 91.94%
  Test F1 (M):74.33%

============================================================
Training completed in 566.60s
Best validation accuracy: 74.17%
============================================================


Results saved to: outputs/efficientnet_b1_attention_kd
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: efficientnet_b1_combined_kd
Student Architecture: efficientnet_b1
Distillation Type: combined
Device: cuda
Seed: 42

Configuration saved to: outputs/efficientnet_b1_combined_kd/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: efficientnet_b1
  Total parameters: 6,769,384
  Trainable parameters: 6,769,384

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01

Setting up knowledge distillation...
  Teacher: openai/clip-vit-base-patch32
  Distillation type: combined
  Alpha CE: 1.0
  Alpha KD: 1.0
  Alpha Attention: 0.1
  Attention loss: mse


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 7.4125
  Train Acc:  37.02%
  CE Loss:    3.4608
  KD Loss:    3.9517
  Val Loss:   2.0734
  Val Acc:    43.50%
  Val Top-5:  78.83%
  Val F1 (M): 38.52%
  Saved best model to outputs/efficientnet_b1_combined_kd/best_model.pth

Epoch 2/30
  Train Loss: 4.1229
  Train Acc:  64.04%
  CE Loss:    1.8771
  KD Loss:    2.2458
  Val Loss:   1.5249
  Val Acc:    56.83%
  Val Top-5:  86.50%
  Val F1 (M): 54.20%
  Saved best model to outputs/efficientnet_b1_combined_kd/best_model.pth

Epoch 3/30
  Train Loss: 3.3866
  Train Acc:  76.38%
  CE Loss:    1.3825
  KD Loss:    2.0041
  Val Loss:   1.2549
  Val Acc:    64.00%
  Val Top-5:  91.67%
  Val F1 (M): 62.66%
  Saved best model to outputs/efficientnet_b1_combined_kd/best_model.pth

Epoch 4/30
  Train Loss: 2.8976
  Train Acc:  84.67%
  CE Loss:    1.0652
  KD Loss:    1.8324
  Val Loss:   1.1207
  Val Acc:    69.00%
  Val Top-5:  93.00%
  Val F1 (M): 66.40%
  Saved best model to outputs/efficientnet_b1_combined_kd/best_model.pth

Epoch 5/30
  Train Loss: 2.6205
  Train Acc:  88.62%
  CE Loss:    0.8780
  KD Loss:    1.7425
  Val Loss:   1.0499
  Val Acc:    72.00%
  Val Top-5:  93.50%
  Val F1 (M): 70.57%
  Saved best model to outputs/efficientnet_b1_combined_kd/best_model.pth

Epoch 6/30
  Train Loss: 2.3955
  Train Acc:  93.06%
  CE Loss:    0.7166
  KD Loss:    1.6789
  Val Loss:   1.0532
  Val Acc:    68.33%
  Val Top-5:  92.83%
  Val F1 (M): 66.71%

Epoch 7/30
  Train Loss: 2.2586
  Train Acc:  94.90%
  CE Loss:    0.6289
  KD Loss:    1.6297
  Val Loss:   1.0405
  Val Acc:    72.17%
  Val Top-5:  92.50%
  Val F1 (M): 71.08%
  Saved best model to outputs/efficientnet_b1_combined_kd/best_model.pth

Epoch 8/30
  Train Loss: 2.1031
  Train Acc:  96.41%
  CE Loss:    0.5386
  KD Loss:    1.5645
  Val Loss:   1.0122
  Val Acc:    71.83%
  Val Top-5:  95.00%
  Val F1 (M): 70.61%

Epoch 9/30
  Train Loss: 1.9747
  Train Acc:  97.86%
  CE Loss:    0.4617
  KD Loss:    1.5130
  Val Loss:   0.9566
  Val Acc:    75.50%
  Val Top-5:  92.67%
  Val F1 (M): 74.33%
  Saved best model to outputs/efficientnet_b1_combined_kd/best_model.pth

Epoch 10/30
  Train Loss: 1.8846
  Train Acc:  98.29%
  CE Loss:    0.4152
  KD Loss:    1.4694
  Val Loss:   0.9568
  Val Acc:    77.67%
  Val Top-5:  93.33%
  Val F1 (M): 76.15%
  Saved best model to outputs/efficientnet_b1_combined_kd/best_model.pth

Epoch 11/30
  Train Loss: 1.7730
  Train Acc:  99.05%
  CE Loss:    0.3575
  KD Loss:    1.4155
  Val Loss:   0.9714
  Val Acc:    75.50%
  Val Top-5:  92.17%
  Val F1 (M): 74.65%

Epoch 12/30
  Train Loss: 1.7159
  Train Acc:  99.42%
  CE Loss:    0.3262
  KD Loss:    1.3897
  Val Loss:   0.9500
  Val Acc:    76.33%
  Val Top-5:  93.33%
  Val F1 (M): 74.99%

Epoch 13/30
  Train Loss: 1.6486
  Train Acc:  99.59%
  CE Loss:    0.3071
  KD Loss:    1.3414
  Val Loss:   0.9368
  Val Acc:    75.33%
  Val Top-5:  94.00%
  Val F1 (M): 73.99%

Epoch 14/30
  Train Loss: 1.6137
  Train Acc:  99.74%
  CE Loss:    0.2878
  KD Loss:    1.3259
  Val Loss:   0.9653
  Val Acc:    75.83%
  Val Top-5:  94.00%
  Val F1 (M): 74.16%

Epoch 15/30
  Train Loss: 1.5387
  Train Acc:  99.68%
  CE Loss:    0.2641
  KD Loss:    1.2747
  Val Loss:   0.9506
  Val Acc:    75.00%
  Val Top-5:  93.67%
  Val F1 (M): 73.77%

Epoch 16/30
  Train Loss: 1.4808
  Train Acc:  99.85%
  CE Loss:    0.2483
  KD Loss:    1.2325
  Val Loss:   0.9183
  Val Acc:    76.00%
  Val Top-5:  94.67%
  Val F1 (M): 74.71%

Epoch 17/30
  Train Loss: 1.4411
  Train Acc:  99.83%
  CE Loss:    0.2366
  KD Loss:    1.2045
  Val Loss:   0.9058
  Val Acc:    77.17%
  Val Top-5:  94.17%
  Val F1 (M): 75.99%

Epoch 18/30
  Train Loss: 1.4059
  Train Acc:  99.87%
  CE Loss:    0.2263
  KD Loss:    1.1795
  Val Loss:   0.9033
  Val Acc:    75.67%
  Val Top-5:  95.17%
  Val F1 (M): 74.77%

Epoch 19/30
  Train Loss: 1.3596
  Train Acc:  99.91%
  CE Loss:    0.2143
  KD Loss:    1.1453
  Val Loss:   0.9257
  Val Acc:    76.67%
  Val Top-5:  94.00%
  Val F1 (M): 75.58%

Epoch 20/30
  Train Loss: 1.3359
  Train Acc:  99.91%
  CE Loss:    0.2129
  KD Loss:    1.1231
  Val Loss:   0.9183
  Val Acc:    76.00%
  Val Top-5:  94.17%
  Val F1 (M): 74.96%

Epoch 21/30
  Train Loss: 1.3063
  Train Acc:  99.80%
  CE Loss:    0.2043
  KD Loss:    1.1020
  Val Loss:   0.9091
  Val Acc:    76.83%
  Val Top-5:  94.33%
  Val F1 (M): 75.90%

Epoch 22/30
  Train Loss: 1.2849
  Train Acc:  99.80%
  CE Loss:    0.1997
  KD Loss:    1.0852
  Val Loss:   0.9371
  Val Acc:    76.50%
  Val Top-5:  93.83%
  Val F1 (M): 75.37%

Epoch 23/30
  Train Loss: 1.2474
  Train Acc:  99.81%
  CE Loss:    0.1945
  KD Loss:    1.0529
  Val Loss:   0.9193
  Val Acc:    76.50%
  Val Top-5:  93.83%
  Val F1 (M): 75.61%

Epoch 24/30
  Train Loss: 1.2237
  Train Acc:  99.87%
  CE Loss:    0.1850
  KD Loss:    1.0387
  Val Loss:   0.9133
  Val Acc:    76.67%
  Val Top-5:  94.17%
  Val F1 (M): 75.52%

Epoch 25/30
  Train Loss: 1.2203
  Train Acc:  99.89%
  CE Loss:    0.1871
  KD Loss:    1.0332
  Val Loss:   0.8974
  Val Acc:    76.33%
  Val Top-5:  93.83%
  Val F1 (M): 75.42%

Epoch 26/30
  Train Loss: 1.1964
  Train Acc:  99.85%
  CE Loss:    0.1812
  KD Loss:    1.0153
  Val Loss:   0.9145
  Val Acc:    76.00%
  Val Top-5:  94.00%
  Val F1 (M): 75.17%

Epoch 27/30
  Train Loss: 1.1807
  Train Acc:  99.91%
  CE Loss:    0.1786
  KD Loss:    1.0022
  Val Loss:   0.8973
  Val Acc:    76.83%
  Val Top-5:  94.67%
  Val F1 (M): 75.53%

Epoch 28/30
  Train Loss: 1.1835
  Train Acc:  99.76%
  CE Loss:    0.1805
  KD Loss:    1.0029
  Val Loss:   0.9083
  Val Acc:    76.50%
  Val Top-5:  94.33%
  Val F1 (M): 75.42%

Epoch 29/30
  Train Loss: 1.1816
  Train Acc:  99.72%
  CE Loss:    0.1783
  KD Loss:    1.0033
  Val Loss:   0.9077
  Val Acc:    76.83%
  Val Top-5:  93.67%
  Val F1 (M): 75.94%

Epoch 30/30
  Train Loss: 1.1735
  Train Acc:  99.91%
  CE Loss:    0.1768
  KD Loss:    0.9967
  Val Loss:   0.8926
  Val Acc:    77.33%
  Val Top-5:  94.67%
  Val F1 (M): 76.18%
  Test Acc:   78.39%
  Test Top-5: 94.48%
  Test F1 (M):78.29%

============================================================
Training completed in 566.03s
Best validation accuracy: 77.67%
============================================================


Results saved to: outputs/efficientnet_b1_combined_kd
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: densenet121_scratch
Student Architecture: densenet121
Distillation Type: none
Device: cuda
Seed: 42

Configuration saved to: outputs/densenet121_scratch/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: densenet121
  Total parameters: 7,158,856
  Trainable parameters: 7,158,856

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 5.2933
  Train Acc:  1.10%
  Val Loss:   5.1546
  Val Acc:    1.67%
  Val Top-5:  8.33%
  Val F1 (M): 0.62%
  Saved best model to outputs/densenet121_scratch/best_model.pth

Epoch 2/30
  Train Loss: 5.0197
  Train Acc:  1.99%
  Val Loss:   4.8627
  Val Acc:    3.33%
  Val Top-5:  14.50%
  Val F1 (M): 1.36%
  Saved best model to outputs/densenet121_scratch/best_model.pth

Epoch 3/30
  Train Loss: 4.7973
  Train Acc:  3.22%
  Val Loss:   4.6480
  Val Acc:    4.33%
  Val Top-5:  15.33%
  Val F1 (M): 2.01%
  Saved best model to outputs/densenet121_scratch/best_model.pth

Epoch 4/30
  Train Loss: 4.6037
  Train Acc:  4.11%
  Val Loss:   4.5845
  Val Acc:    5.50%
  Val Top-5:  19.83%
  Val F1 (M): 3.03%
  Saved best model to outputs/densenet121_scratch/best_model.pth

Epoch 5/30
  Train Loss: 4.4022
  Train Acc:  5.67%
  Val Loss:   4.3115
  Val Acc:    6.83%
  Val Top-5:  25.33%
  Val F1 (M): 4.81%
  Saved best model to outputs/densenet121_scratch/best_model.pth

Epoch 6/30
  Train Loss: 4.2551
  Train Acc:  7.40%
  Val Loss:   4.1988
  Val Acc:    6.83%
  Val Top-5:  27.50%
  Val F1 (M): 3.78%

Epoch 7/30
  Train Loss: 4.0516
  Train Acc:  10.08%
  Val Loss:   4.0059
  Val Acc:    11.33%
  Val Top-5:  32.17%
  Val F1 (M): 8.15%
  Saved best model to outputs/densenet121_scratch/best_model.pth

Epoch 8/30
  Train Loss: 3.8839
  Train Acc:  11.90%
  Val Loss:   3.9659
  Val Acc:    11.50%
  Val Top-5:  32.17%
  Val F1 (M): 9.21%
  Saved best model to outputs/densenet121_scratch/best_model.pth

Epoch 9/30
  Train Loss: 3.6993
  Train Acc:  13.69%
  Val Loss:   3.9195
  Val Acc:    12.00%
  Val Top-5:  37.83%
  Val F1 (M): 8.78%
  Saved best model to outputs/densenet121_scratch/best_model.pth

Epoch 10/30
  Train Loss: 3.4974
  Train Acc:  16.78%
  Val Loss:   3.5520
  Val Acc:    15.83%
  Val Top-5:  43.17%
  Val F1 (M): 12.77%
  Saved best model to outputs/densenet121_scratch/best_model.pth

Epoch 11/30
  Train Loss: 3.3466
  Train Acc:  19.68%
  Val Loss:   3.3580
  Val Acc:    18.00%
  Val Top-5:  48.17%
  Val F1 (M): 15.41%
  Saved best model to outputs/densenet121_scratch/best_model.pth

Epoch 12/30
  Train Loss: 3.1769
  Train Acc:  22.58%
  Val Loss:   3.3886
  Val Acc:    20.17%
  Val Top-5:  47.83%
  Val F1 (M): 15.73%
  Saved best model to outputs/densenet121_scratch/best_model.pth

Epoch 13/30
  Train Loss: 3.0344
  Train Acc:  24.85%
  Val Loss:   3.3070
  Val Acc:    19.17%
  Val Top-5:  48.17%
  Val F1 (M): 16.05%

Epoch 14/30
  Train Loss: 2.8734
  Train Acc:  27.86%
  Val Loss:   3.1399
  Val Acc:    21.83%
  Val Top-5:  53.33%
  Val F1 (M): 19.55%
  Saved best model to outputs/densenet121_scratch/best_model.pth

Epoch 15/30
  Train Loss: 2.7356
  Train Acc:  32.14%
  Val Loss:   3.1387
  Val Acc:    22.83%
  Val Top-5:  52.83%
  Val F1 (M): 20.49%
  Saved best model to outputs/densenet121_scratch/best_model.pth

Epoch 16/30
  Train Loss: 2.5879
  Train Acc:  34.82%
  Val Loss:   3.0070
  Val Acc:    25.83%
  Val Top-5:  54.50%
  Val F1 (M): 22.05%
  Saved best model to outputs/densenet121_scratch/best_model.pth

Epoch 17/30
  Train Loss: 2.4583
  Train Acc:  38.49%
  Val Loss:   2.9154
  Val Acc:    27.17%
  Val Top-5:  58.17%
  Val F1 (M): 24.64%
  Saved best model to outputs/densenet121_scratch/best_model.pth

Epoch 18/30
  Train Loss: 2.3418
  Train Acc:  41.03%
  Val Loss:   2.8065
  Val Acc:    28.67%
  Val Top-5:  60.67%
  Val F1 (M): 26.58%
  Saved best model to outputs/densenet121_scratch/best_model.pth

Epoch 19/30
  Train Loss: 2.2140
  Train Acc:  43.97%
  Val Loss:   2.8226
  Val Acc:    27.83%
  Val Top-5:  61.33%
  Val F1 (M): 25.19%

Epoch 20/30
  Train Loss: 2.1038
  Train Acc:  46.74%
  Val Loss:   2.6810
  Val Acc:    31.17%
  Val Top-5:  63.17%
  Val F1 (M): 29.28%
  Saved best model to outputs/densenet121_scratch/best_model.pth

Epoch 21/30
  Train Loss: 2.0093
  Train Acc:  48.94%
  Val Loss:   2.6429
  Val Acc:    33.17%
  Val Top-5:  64.17%
  Val F1 (M): 31.41%
  Saved best model to outputs/densenet121_scratch/best_model.pth

Epoch 22/30
  Train Loss: 1.9005
  Train Acc:  52.88%
  Val Loss:   2.6444
  Val Acc:    32.50%
  Val Top-5:  62.00%
  Val F1 (M): 30.17%

Epoch 23/30
  Train Loss: 1.8373
  Train Acc:  53.63%
  Val Loss:   2.6257
  Val Acc:    33.33%
  Val Top-5:  64.00%
  Val F1 (M): 31.09%
  Saved best model to outputs/densenet121_scratch/best_model.pth

Epoch 24/30
  Train Loss: 1.7639
  Train Acc:  56.49%
  Val Loss:   2.5839
  Val Acc:    36.67%
  Val Top-5:  65.33%
  Val F1 (M): 34.87%
  Saved best model to outputs/densenet121_scratch/best_model.pth

Epoch 25/30
  Train Loss: 1.7300
  Train Acc:  56.99%
  Val Loss:   2.5629
  Val Acc:    36.83%
  Val Top-5:  65.33%
  Val F1 (M): 34.50%
  Saved best model to outputs/densenet121_scratch/best_model.pth

Epoch 26/30
  Train Loss: 1.6628
  Train Acc:  59.65%
  Val Loss:   2.5508
  Val Acc:    35.17%
  Val Top-5:  64.33%
  Val F1 (M): 33.15%

Epoch 27/30
  Train Loss: 1.6288
  Train Acc:  60.25%
  Val Loss:   2.5291
  Val Acc:    36.50%
  Val Top-5:  66.17%
  Val F1 (M): 35.00%

Epoch 28/30
  Train Loss: 1.5974
  Train Acc:  61.07%
  Val Loss:   2.5096
  Val Acc:    36.17%
  Val Top-5:  65.33%
  Val F1 (M): 34.01%

Epoch 29/30
  Train Loss: 1.5817
  Train Acc:  62.13%
  Val Loss:   2.5317
  Val Acc:    35.33%
  Val Top-5:  65.83%
  Val F1 (M): 33.30%

Epoch 30/30
  Train Loss: 1.5824
  Train Acc:  62.61%
  Val Loss:   2.5201
  Val Acc:    36.50%
  Val Top-5:  65.17%
  Val F1 (M): 34.78%
  Test Acc:   35.88%
  Test Top-5: 67.74%
  Test F1 (M):35.14%

============================================================
Training completed in 379.85s
Best validation accuracy: 36.83%
============================================================


Results saved to: outputs/densenet121_scratch
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: densenet121_transfer
Student Architecture: densenet121
Distillation Type: none
Device: cuda
Seed: 42

Configuration saved to: outputs/densenet121_transfer/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: densenet121
  Total parameters: 7,158,856
  Trainable parameters: 7,158,856

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 4.3153
  Train Acc:  15.18%
  Val Loss:   2.7299
  Val Acc:    37.67%
  Val Top-5:  73.00%
  Val F1 (M): 31.63%
  Saved best model to outputs/densenet121_transfer/best_model.pth

Epoch 2/30
  Train Loss: 2.1868
  Train Acc:  52.51%
  Val Loss:   1.7475
  Val Acc:    53.17%
  Val Top-5:  84.50%
  Val F1 (M): 51.33%
  Saved best model to outputs/densenet121_transfer/best_model.pth

Epoch 3/30
  Train Loss: 1.2749
  Train Acc:  71.43%
  Val Loss:   1.3765
  Val Acc:    63.67%
  Val Top-5:  90.67%
  Val F1 (M): 62.37%
  Saved best model to outputs/densenet121_transfer/best_model.pth

Epoch 4/30
  Train Loss: 0.8489
  Train Acc:  80.65%
  Val Loss:   1.2454
  Val Acc:    66.83%
  Val Top-5:  91.00%
  Val F1 (M): 64.80%
  Saved best model to outputs/densenet121_transfer/best_model.pth

Epoch 5/30
  Train Loss: 0.5752
  Train Acc:  87.39%
  Val Loss:   1.1162
  Val Acc:    69.33%
  Val Top-5:  92.83%
  Val F1 (M): 68.39%
  Saved best model to outputs/densenet121_transfer/best_model.pth

Epoch 6/30
  Train Loss: 0.4033
  Train Acc:  91.98%
  Val Loss:   1.1529
  Val Acc:    69.50%
  Val Top-5:  92.17%
  Val F1 (M): 68.09%
  Saved best model to outputs/densenet121_transfer/best_model.pth

Epoch 7/30
  Train Loss: 0.3000
  Train Acc:  94.16%
  Val Loss:   1.1231
  Val Acc:    69.00%
  Val Top-5:  91.83%
  Val F1 (M): 68.13%

Epoch 8/30
  Train Loss: 0.2219
  Train Acc:  95.96%
  Val Loss:   1.0233
  Val Acc:    74.33%
  Val Top-5:  93.17%
  Val F1 (M): 73.31%
  Saved best model to outputs/densenet121_transfer/best_model.pth

Epoch 9/30
  Train Loss: 0.1518
  Train Acc:  97.77%
  Val Loss:   1.0829
  Val Acc:    70.67%
  Val Top-5:  93.00%
  Val F1 (M): 69.61%

Epoch 10/30
  Train Loss: 0.1129
  Train Acc:  98.47%
  Val Loss:   1.0843
  Val Acc:    71.83%
  Val Top-5:  93.00%
  Val F1 (M): 71.22%

Epoch 11/30
  Train Loss: 0.0925
  Train Acc:  98.55%
  Val Loss:   1.0755
  Val Acc:    72.17%
  Val Top-5:  92.17%
  Val F1 (M): 70.83%

Epoch 12/30
  Train Loss: 0.0707
  Train Acc:  99.22%
  Val Loss:   1.0741
  Val Acc:    72.00%
  Val Top-5:  92.00%
  Val F1 (M): 70.96%

Epoch 13/30
  Train Loss: 0.0560
  Train Acc:  99.31%
  Val Loss:   1.0846
  Val Acc:    73.67%
  Val Top-5:  92.50%
  Val F1 (M): 72.70%

Epoch 14/30
  Train Loss: 0.0414
  Train Acc:  99.70%
  Val Loss:   1.0248
  Val Acc:    74.67%
  Val Top-5:  93.17%
  Val F1 (M): 73.49%
  Saved best model to outputs/densenet121_transfer/best_model.pth

Epoch 15/30
  Train Loss: 0.0345
  Train Acc:  99.70%
  Val Loss:   1.0583
  Val Acc:    73.50%
  Val Top-5:  93.67%
  Val F1 (M): 72.39%

Epoch 16/30
  Train Loss: 0.0285
  Train Acc:  99.76%
  Val Loss:   1.0694
  Val Acc:    73.67%
  Val Top-5:  92.83%
  Val F1 (M): 73.04%

Epoch 17/30
  Train Loss: 0.0241
  Train Acc:  99.81%
  Val Loss:   1.0417
  Val Acc:    74.50%
  Val Top-5:  93.50%
  Val F1 (M): 73.58%

Epoch 18/30
  Train Loss: 0.0211
  Train Acc:  99.81%
  Val Loss:   1.0464
  Val Acc:    75.33%
  Val Top-5:  93.33%
  Val F1 (M): 74.43%
  Saved best model to outputs/densenet121_transfer/best_model.pth

Epoch 19/30
  Train Loss: 0.0178
  Train Acc:  99.89%
  Val Loss:   1.0490
  Val Acc:    74.17%
  Val Top-5:  93.67%
  Val F1 (M): 73.22%

Epoch 20/30
  Train Loss: 0.0140
  Train Acc:  99.91%
  Val Loss:   1.0395
  Val Acc:    74.50%
  Val Top-5:  93.50%
  Val F1 (M): 73.04%

Epoch 21/30
  Train Loss: 0.0119
  Train Acc:  99.98%
  Val Loss:   1.0683
  Val Acc:    73.17%
  Val Top-5:  93.17%
  Val F1 (M): 72.19%

Epoch 22/30
  Train Loss: 0.0115
  Train Acc:  99.91%
  Val Loss:   1.0544
  Val Acc:    74.17%
  Val Top-5:  93.50%
  Val F1 (M): 72.92%

Epoch 23/30
  Train Loss: 0.0103
  Train Acc:  99.94%
  Val Loss:   1.0480
  Val Acc:    75.00%
  Val Top-5:  93.17%
  Val F1 (M): 73.87%

Epoch 24/30
  Train Loss: 0.0097
  Train Acc:  99.98%
  Val Loss:   1.0483
  Val Acc:    74.33%
  Val Top-5:  93.50%
  Val F1 (M): 73.08%

Epoch 25/30
  Train Loss: 0.0097
  Train Acc:  99.98%
  Val Loss:   1.0414
  Val Acc:    75.00%
  Val Top-5:  93.17%
  Val F1 (M): 73.78%

Epoch 26/30
  Train Loss: 0.0074
  Train Acc:  100.00%
  Val Loss:   1.0587
  Val Acc:    74.83%
  Val Top-5:  92.33%
  Val F1 (M): 73.58%

Epoch 27/30
  Train Loss: 0.0086
  Train Acc:  99.94%
  Val Loss:   1.0309
  Val Acc:    75.67%
  Val Top-5:  93.00%
  Val F1 (M): 74.52%
  Saved best model to outputs/densenet121_transfer/best_model.pth

Epoch 28/30
  Train Loss: 0.0071
  Train Acc:  99.98%
  Val Loss:   1.0376
  Val Acc:    74.67%
  Val Top-5:  93.00%
  Val F1 (M): 73.49%

Epoch 29/30
  Train Loss: 0.0069
  Train Acc:  100.00%
  Val Loss:   1.0348
  Val Acc:    75.17%
  Val Top-5:  93.17%
  Val F1 (M): 74.01%

Epoch 30/30
  Train Loss: 0.0075
  Train Acc:  99.98%
  Val Loss:   1.0374
  Val Acc:    75.50%
  Val Top-5:  93.50%
  Val F1 (M): 74.56%
  Test Acc:   76.37%
  Test Top-5: 93.56%
  Test F1 (M):76.24%

============================================================
Training completed in 376.82s
Best validation accuracy: 75.67%
============================================================


Results saved to: outputs/densenet121_transfer
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: densenet121_logit_kd
Student Architecture: densenet121
Distillation Type: logit
Device: cuda
Seed: 42

Configuration saved to: outputs/densenet121_logit_kd/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: densenet121
  Total parameters: 7,158,856
  Trainable parameters: 7,158,856

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01

Setting up knowledge distillation...
  Teacher: openai/clip-vit-base-patch32
  Distillation type: logit
  Alpha CE: 1.0
  Alpha KD: 1.0


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 8.6027
  Train Acc:  18.90%
  CE Loss:    3.9810
  KD Loss:    4.6218
  Val Loss:   2.4349
  Val Acc:    35.33%
  Val Top-5:  74.17%
  Val F1 (M): 30.01%
  Saved best model to outputs/densenet121_logit_kd/best_model.pth

Epoch 2/30
  Train Loss: 4.4655
  Train Acc:  54.30%
  CE Loss:    2.1837
  KD Loss:    2.2818
  Val Loss:   1.6587
  Val Acc:    54.50%
  Val Top-5:  87.50%
  Val F1 (M): 51.56%
  Saved best model to outputs/densenet121_logit_kd/best_model.pth

Epoch 3/30
  Train Loss: 3.4186
  Train Acc:  71.13%
  CE Loss:    1.5329
  KD Loss:    1.8858
  Val Loss:   1.2800
  Val Acc:    63.67%
  Val Top-5:  92.17%
  Val F1 (M): 61.54%
  Saved best model to outputs/densenet121_logit_kd/best_model.pth

Epoch 4/30
  Train Loss: 2.9246
  Train Acc:  80.38%
  CE Loss:    1.1902
  KD Loss:    1.7344
  Val Loss:   1.1433
  Val Acc:    68.17%
  Val Top-5:  93.33%
  Val F1 (M): 66.37%
  Saved best model to outputs/densenet121_logit_kd/best_model.pth

Epoch 5/30
  Train Loss: 2.6141
  Train Acc:  85.45%
  CE Loss:    0.9801
  KD Loss:    1.6340
  Val Loss:   1.1025
  Val Acc:    68.83%
  Val Top-5:  93.50%
  Val F1 (M): 67.21%
  Saved best model to outputs/densenet121_logit_kd/best_model.pth

Epoch 6/30
  Train Loss: 2.3692
  Train Acc:  90.01%
  CE Loss:    0.8165
  KD Loss:    1.5526
  Val Loss:   1.0556
  Val Acc:    71.50%
  Val Top-5:  93.33%
  Val F1 (M): 69.85%
  Saved best model to outputs/densenet121_logit_kd/best_model.pth

Epoch 7/30
  Train Loss: 2.2428
  Train Acc:  92.13%
  CE Loss:    0.7187
  KD Loss:    1.5241
  Val Loss:   1.0246
  Val Acc:    71.67%
  Val Top-5:  94.17%
  Val F1 (M): 69.93%
  Saved best model to outputs/densenet121_logit_kd/best_model.pth

Epoch 8/30
  Train Loss: 2.0549
  Train Acc:  95.26%
  CE Loss:    0.5949
  KD Loss:    1.4600
  Val Loss:   0.9831
  Val Acc:    74.50%
  Val Top-5:  93.67%
  Val F1 (M): 73.47%
  Saved best model to outputs/densenet121_logit_kd/best_model.pth

Epoch 9/30
  Train Loss: 2.0089
  Train Acc:  96.32%
  CE Loss:    0.5546
  KD Loss:    1.4543
  Val Loss:   0.9561
  Val Acc:    77.00%
  Val Top-5:  93.83%
  Val F1 (M): 75.80%
  Saved best model to outputs/densenet121_logit_kd/best_model.pth

Epoch 10/30
  Train Loss: 1.8983
  Train Acc:  97.56%
  CE Loss:    0.4810
  KD Loss:    1.4173
  Val Loss:   0.9125
  Val Acc:    75.83%
  Val Top-5:  94.17%
  Val F1 (M): 75.47%

Epoch 11/30
  Train Loss: 1.8258
  Train Acc:  97.79%
  CE Loss:    0.4420
  KD Loss:    1.3838
  Val Loss:   0.9463
  Val Acc:    76.00%
  Val Top-5:  93.83%
  Val F1 (M): 74.94%

Epoch 12/30
  Train Loss: 1.7528
  Train Acc:  98.40%
  CE Loss:    0.4053
  KD Loss:    1.3476
  Val Loss:   0.9738
  Val Acc:    75.33%
  Val Top-5:  92.83%
  Val F1 (M): 74.36%

Epoch 13/30
  Train Loss: 1.6758
  Train Acc:  99.03%
  CE Loss:    0.3660
  KD Loss:    1.3098
  Val Loss:   0.9559
  Val Acc:    75.33%
  Val Top-5:  93.33%
  Val F1 (M): 74.19%

Epoch 14/30
  Train Loss: 1.6465
  Train Acc:  98.96%
  CE Loss:    0.3453
  KD Loss:    1.3012
  Val Loss:   0.9539
  Val Acc:    76.33%
  Val Top-5:  93.33%
  Val F1 (M): 75.32%

Epoch 15/30
  Train Loss: 1.6038
  Train Acc:  99.27%
  CE Loss:    0.3300
  KD Loss:    1.2739
  Val Loss:   0.9467
  Val Acc:    76.50%
  Val Top-5:  92.83%
  Val F1 (M): 75.74%

Epoch 16/30
  Train Loss: 1.5466
  Train Acc:  99.40%
  CE Loss:    0.3042
  KD Loss:    1.2424
  Val Loss:   0.9740
  Val Acc:    74.83%
  Val Top-5:  93.17%
  Val F1 (M): 74.12%

Epoch 17/30
  Train Loss: 1.5212
  Train Acc:  99.48%
  CE Loss:    0.2927
  KD Loss:    1.2285
  Val Loss:   0.9594
  Val Acc:    76.50%
  Val Top-5:  93.33%
  Val F1 (M): 75.54%

Epoch 18/30
  Train Loss: 1.4573
  Train Acc:  99.65%
  CE Loss:    0.2690
  KD Loss:    1.1883
  Val Loss:   0.9418
  Val Acc:    76.00%
  Val Top-5:  93.67%
  Val F1 (M): 74.95%

Epoch 19/30
  Train Loss: 1.4336
  Train Acc:  99.63%
  CE Loss:    0.2652
  KD Loss:    1.1684
  Val Loss:   0.9515
  Val Acc:    76.17%
  Val Top-5:  93.67%
  Val F1 (M): 75.34%

Epoch 20/30
  Train Loss: 1.4035
  Train Acc:  99.57%
  CE Loss:    0.2554
  KD Loss:    1.1481
  Val Loss:   0.9372
  Val Acc:    75.83%
  Val Top-5:  94.00%
  Val F1 (M): 74.62%

Epoch 21/30
  Train Loss: 1.3881
  Train Acc:  99.65%
  CE Loss:    0.2479
  KD Loss:    1.1402
  Val Loss:   0.9512
  Val Acc:    74.33%
  Val Top-5:  93.33%
  Val F1 (M): 73.14%

Epoch 22/30
  Train Loss: 1.3615
  Train Acc:  99.68%
  CE Loss:    0.2378
  KD Loss:    1.1237
  Val Loss:   0.9443
  Val Acc:    76.17%
  Val Top-5:  93.83%
  Val F1 (M): 75.36%

Epoch 23/30
  Train Loss: 1.3395
  Train Acc:  99.74%
  CE Loss:    0.2303
  KD Loss:    1.1092
  Val Loss:   0.9358
  Val Acc:    77.00%
  Val Top-5:  93.17%
  Val F1 (M): 76.03%

Epoch 24/30
  Train Loss: 1.3428
  Train Acc:  99.70%
  CE Loss:    0.2315
  KD Loss:    1.1112
  Val Loss:   0.9482
  Val Acc:    76.17%
  Val Top-5:  93.00%
  Val F1 (M): 75.19%

Epoch 25/30
  Train Loss: 1.3242
  Train Acc:  99.67%
  CE Loss:    0.2296
  KD Loss:    1.0946
  Val Loss:   0.9548
  Val Acc:    76.00%
  Val Top-5:  93.33%
  Val F1 (M): 75.13%

Epoch 26/30
  Train Loss: 1.2980
  Train Acc:  99.76%
  CE Loss:    0.2210
  KD Loss:    1.0769
  Val Loss:   0.9573
  Val Acc:    75.50%
  Val Top-5:  93.17%
  Val F1 (M): 74.64%

Epoch 27/30
  Train Loss: 1.2939
  Train Acc:  99.74%
  CE Loss:    0.2204
  KD Loss:    1.0735
  Val Loss:   0.9576
  Val Acc:    75.67%
  Val Top-5:  93.33%
  Val F1 (M): 74.73%

Epoch 28/30
  Train Loss: 1.2959
  Train Acc:  99.65%
  CE Loss:    0.2207
  KD Loss:    1.0751
  Val Loss:   0.9459
  Val Acc:    76.17%
  Val Top-5:  94.00%
  Val F1 (M): 75.19%

Epoch 29/30
  Train Loss: 1.2969
  Train Acc:  99.61%
  CE Loss:    0.2182
  KD Loss:    1.0787
  Val Loss:   0.9361
  Val Acc:    76.67%
  Val Top-5:  93.67%
  Val F1 (M): 75.59%

Epoch 30/30
  Train Loss: 1.2939
  Train Acc:  99.59%
  CE Loss:    0.2198
  KD Loss:    1.0741
  Val Loss:   0.9442
  Val Acc:    75.83%
  Val Top-5:  93.83%
  Val F1 (M): 74.98%
  Test Acc:   78.44%
  Test Top-5: 94.43%
  Test F1 (M):78.48%

============================================================
Training completed in 491.39s
Best validation accuracy: 77.00%
============================================================


Results saved to: outputs/densenet121_logit_kd
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: densenet121_attention_kd
Student Architecture: densenet121
Distillation Type: attention
Device: cuda
Seed: 42

Configuration saved to: outputs/densenet121_attention_kd/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: densenet121
  Total parameters: 7,158,856
  Trainable parameters: 7,158,856

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01

Setting up knowledge distillation...
  Teacher: openai/clip-vit-base-patch32
  Distillation type: attention
  Alpha CE: 1.0
  Alpha KD: 0.0
  Alpha Attention: 0.5
  Attention loss: mse


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 4.3499
  Train Acc:  22.54%
  CE Loss:    4.3499
  KD Loss:    6.8993
  Val Loss:   2.8172
  Val Acc:    36.33%
  Val Top-5:  73.00%
  Val F1 (M): 30.84%
  Saved best model to outputs/densenet121_attention_kd/best_model.pth

Epoch 2/30
  Train Loss: 2.2269
  Train Acc:  62.76%
  CE Loss:    2.2269
  KD Loss:    4.9971
  Val Loss:   1.6921
  Val Acc:    55.67%
  Val Top-5:  89.00%
  Val F1 (M): 52.87%
  Saved best model to outputs/densenet121_attention_kd/best_model.pth

Epoch 3/30
  Train Loss: 1.3026
  Train Acc:  82.12%
  CE Loss:    1.3026
  KD Loss:    4.5786
  Val Loss:   1.3406
  Val Acc:    64.67%
  Val Top-5:  92.50%
  Val F1 (M): 62.33%
  Saved best model to outputs/densenet121_attention_kd/best_model.pth

Epoch 4/30
  Train Loss: 0.8526
  Train Acc:  90.35%
  CE Loss:    0.8526
  KD Loss:    4.5666
  Val Loss:   1.2326
  Val Acc:    66.33%
  Val Top-5:  91.17%
  Val F1 (M): 65.39%
  Saved best model to outputs/densenet121_attention_kd/best_model.pth

Epoch 5/30
  Train Loss: 0.5911
  Train Acc:  94.72%
  CE Loss:    0.5911
  KD Loss:    4.6091
  Val Loss:   1.1961
  Val Acc:    67.50%
  Val Top-5:  91.83%
  Val F1 (M): 66.50%
  Saved best model to outputs/densenet121_attention_kd/best_model.pth

Epoch 6/30
  Train Loss: 0.4084
  Train Acc:  97.67%
  CE Loss:    0.4084
  KD Loss:    4.7362
  Val Loss:   1.1424
  Val Acc:    69.67%
  Val Top-5:  91.83%
  Val F1 (M): 68.53%
  Saved best model to outputs/densenet121_attention_kd/best_model.pth

Epoch 7/30
  Train Loss: 0.3026
  Train Acc:  98.57%
  CE Loss:    0.3026
  KD Loss:    4.8949
  Val Loss:   1.1224
  Val Acc:    69.67%
  Val Top-5:  92.33%
  Val F1 (M): 68.32%

Epoch 8/30
  Train Loss: 0.2052
  Train Acc:  99.61%
  CE Loss:    0.2052
  KD Loss:    5.0386
  Val Loss:   1.1233
  Val Acc:    70.67%
  Val Top-5:  92.33%
  Val F1 (M): 70.20%
  Saved best model to outputs/densenet121_attention_kd/best_model.pth

Epoch 9/30
  Train Loss: 0.1542
  Train Acc:  99.78%
  CE Loss:    0.1542
  KD Loss:    5.1953
  Val Loss:   1.1457
  Val Acc:    69.83%
  Val Top-5:  91.17%
  Val F1 (M): 68.23%

Epoch 10/30
  Train Loss: 0.1117
  Train Acc:  99.91%
  CE Loss:    0.1117
  KD Loss:    5.3332
  Val Loss:   1.1306
  Val Acc:    71.33%
  Val Top-5:  92.17%
  Val F1 (M): 69.99%
  Saved best model to outputs/densenet121_attention_kd/best_model.pth

Epoch 11/30
  Train Loss: 0.1037
  Train Acc:  100.00%
  CE Loss:    0.1037
  KD Loss:    5.3817
  Val Loss:   1.1679
  Val Acc:    70.17%
  Val Top-5:  91.17%
  Val F1 (M): 68.86%

Epoch 12/30
  Train Loss: 0.0799
  Train Acc:  100.00%
  CE Loss:    0.0799
  KD Loss:    5.5075
  Val Loss:   1.1399
  Val Acc:    72.00%
  Val Top-5:  91.83%
  Val F1 (M): 71.08%
  Saved best model to outputs/densenet121_attention_kd/best_model.pth

Epoch 13/30
  Train Loss: 0.0499
  Train Acc:  100.00%
  CE Loss:    0.0499
  KD Loss:    5.5830
  Val Loss:   1.1120
  Val Acc:    72.33%
  Val Top-5:  93.17%
  Val F1 (M): 71.97%
  Saved best model to outputs/densenet121_attention_kd/best_model.pth

Epoch 14/30
  Train Loss: 0.0363
  Train Acc:  100.00%
  CE Loss:    0.0363
  KD Loss:    5.7475
  Val Loss:   1.1217
  Val Acc:    71.50%
  Val Top-5:  92.67%
  Val F1 (M): 70.68%

Epoch 15/30
  Train Loss: 0.0293
  Train Acc:  100.00%
  CE Loss:    0.0293
  KD Loss:    5.8380
  Val Loss:   1.1174
  Val Acc:    73.67%
  Val Top-5:  93.00%
  Val F1 (M): 73.03%
  Saved best model to outputs/densenet121_attention_kd/best_model.pth

Epoch 16/30
  Train Loss: 0.0252
  Train Acc:  100.00%
  CE Loss:    0.0252
  KD Loss:    5.8913
  Val Loss:   1.1243
  Val Acc:    74.00%
  Val Top-5:  92.00%
  Val F1 (M): 73.33%
  Saved best model to outputs/densenet121_attention_kd/best_model.pth

Epoch 17/30
  Train Loss: 0.0237
  Train Acc:  100.00%
  CE Loss:    0.0237
  KD Loss:    5.9503
  Val Loss:   1.0999
  Val Acc:    73.67%
  Val Top-5:  93.00%
  Val F1 (M): 73.09%

Epoch 18/30
  Train Loss: 0.0183
  Train Acc:  100.00%
  CE Loss:    0.0183
  KD Loss:    5.9759
  Val Loss:   1.1114
  Val Acc:    73.83%
  Val Top-5:  93.33%
  Val F1 (M): 72.89%

Epoch 19/30
  Train Loss: 0.0175
  Train Acc:  100.00%
  CE Loss:    0.0175
  KD Loss:    6.0581
  Val Loss:   1.1180
  Val Acc:    71.83%
  Val Top-5:  93.00%
  Val F1 (M): 71.53%

Epoch 20/30
  Train Loss: 0.0124
  Train Acc:  100.00%
  CE Loss:    0.0124
  KD Loss:    6.1044
  Val Loss:   1.1195
  Val Acc:    72.50%
  Val Top-5:  92.83%
  Val F1 (M): 72.08%

Epoch 21/30
  Train Loss: 0.0122
  Train Acc:  100.00%
  CE Loss:    0.0122
  KD Loss:    6.1405
  Val Loss:   1.0840
  Val Acc:    74.33%
  Val Top-5:  93.00%
  Val F1 (M): 74.20%
  Saved best model to outputs/densenet121_attention_kd/best_model.pth

Epoch 22/30
  Train Loss: 0.0110
  Train Acc:  100.00%
  CE Loss:    0.0110
  KD Loss:    6.2217
  Val Loss:   1.0931
  Val Acc:    74.50%
  Val Top-5:  92.67%
  Val F1 (M): 74.21%
  Saved best model to outputs/densenet121_attention_kd/best_model.pth

Epoch 23/30
  Train Loss: 0.0103
  Train Acc:  100.00%
  CE Loss:    0.0103
  KD Loss:    6.2591
  Val Loss:   1.0959
  Val Acc:    73.83%
  Val Top-5:  93.17%
  Val F1 (M): 73.27%

Epoch 24/30
  Train Loss: 0.0111
  Train Acc:  100.00%
  CE Loss:    0.0111
  KD Loss:    6.2669
  Val Loss:   1.1175
  Val Acc:    73.00%
  Val Top-5:  92.67%
  Val F1 (M): 72.46%

Epoch 25/30
  Train Loss: 0.0093
  Train Acc:  100.00%
  CE Loss:    0.0093
  KD Loss:    6.2927
  Val Loss:   1.1031
  Val Acc:    73.33%
  Val Top-5:  93.00%
  Val F1 (M): 72.53%

Epoch 26/30
  Train Loss: 0.0079
  Train Acc:  100.00%
  CE Loss:    0.0079
  KD Loss:    6.3206
  Val Loss:   1.1046
  Val Acc:    73.67%
  Val Top-5:  92.83%
  Val F1 (M): 72.94%

Epoch 27/30
  Train Loss: 0.0078
  Train Acc:  100.00%
  CE Loss:    0.0078
  KD Loss:    6.3369
  Val Loss:   1.1122
  Val Acc:    73.50%
  Val Top-5:  93.33%
  Val F1 (M): 72.81%

Epoch 28/30
  Train Loss: 0.0075
  Train Acc:  99.98%
  CE Loss:    0.0075
  KD Loss:    6.3561
  Val Loss:   1.1028
  Val Acc:    74.00%
  Val Top-5:  93.00%
  Val F1 (M): 73.28%

Epoch 29/30
  Train Loss: 0.0076
  Train Acc:  100.00%
  CE Loss:    0.0076
  KD Loss:    6.3805
  Val Loss:   1.0964
  Val Acc:    74.33%
  Val Top-5:  92.83%
  Val F1 (M): 73.56%

Epoch 30/30
  Train Loss: 0.0075
  Train Acc:  99.98%
  CE Loss:    0.0075
  KD Loss:    6.3564
  Val Loss:   1.0903
  Val Acc:    73.17%
  Val Top-5:  92.67%
  Val F1 (M): 72.25%
  Test Acc:   75.82%
  Test Top-5: 93.87%
  Test F1 (M):75.75%

============================================================
Training completed in 685.67s
Best validation accuracy: 74.50%
============================================================


Results saved to: outputs/densenet121_attention_kd
Training completed successfully!


================================================================================
CUB-200-2011 Knowledge Distillation Training
================================================================================

Experiment: densenet121_combined_kd
Student Architecture: densenet121
Distillation Type: combined
Device: cuda
Seed: 42

Configuration saved to: outputs/densenet121_combined_kd/config.yaml

Loading CUB-200-2011 dataset...
  Train: 5394 samples
  Val:   600 samples
  Test:  5794 samples

Building student model: densenet121
  Total parameters: 7,158,856
  Trainable parameters: 7,158,856

Optimizer: ADAMW
  Learning rate: 0.0003
  Weight decay: 0.01

Setting up knowledge distillation...
  Teacher: openai/clip-vit-base-patch32
  Distillation type: combined
  Alpha CE: 1.0
  Alpha KD: 1.0
  Alpha Attention: 0.1
  Attention loss: mse


============================================================
Starting training for 30 epochs
Device: cuda
Training samples: 5394
Validation samples: 600
============================================================


Epoch 1/30
  Train Loss: 8.6027
  Train Acc:  18.90%
  CE Loss:    3.9810
  KD Loss:    4.6218
  Val Loss:   2.4469
  Val Acc:    35.17%
  Val Top-5:  73.50%
  Val F1 (M): 29.96%
  Saved best model to outputs/densenet121_combined_kd/best_model.pth

Epoch 2/30
  Train Loss: 4.4655
  Train Acc:  54.30%
  CE Loss:    2.1837
  KD Loss:    2.2818
  Val Loss:   1.6452
  Val Acc:    54.50%
  Val Top-5:  87.17%
  Val F1 (M): 51.44%
  Saved best model to outputs/densenet121_combined_kd/best_model.pth

Epoch 3/30
  Train Loss: 3.4186
  Train Acc:  71.13%
  CE Loss:    1.5329
  KD Loss:    1.8858
  Val Loss:   1.2730
  Val Acc:    63.67%
  Val Top-5:  92.33%
  Val F1 (M): 61.38%
  Saved best model to outputs/densenet121_combined_kd/best_model.pth

Epoch 4/30
  Train Loss: 2.9246
  Train Acc:  80.38%
  CE Loss:    1.1902
  KD Loss:    1.7344
  Val Loss:   1.1463
  Val Acc:    68.00%
  Val Top-5:  93.50%
  Val F1 (M): 66.25%
  Saved best model to outputs/densenet121_combined_kd/best_model.pth

Epoch 5/30
  Train Loss: 2.6141
  Train Acc:  85.45%
  CE Loss:    0.9801
  KD Loss:    1.6340
  Val Loss:   1.1057
  Val Acc:    68.33%
  Val Top-5:  93.00%
  Val F1 (M): 66.35%
  Saved best model to outputs/densenet121_combined_kd/best_model.pth

Epoch 6/30
  Train Loss: 2.3692
  Train Acc:  90.01%
  CE Loss:    0.8165
  KD Loss:    1.5526
  Val Loss:   1.0519
  Val Acc:    71.83%
  Val Top-5:  93.00%
  Val F1 (M): 70.07%
  Saved best model to outputs/densenet121_combined_kd/best_model.pth

Epoch 7/30
  Train Loss: 2.2428
  Train Acc:  92.13%
  CE Loss:    0.7187
  KD Loss:    1.5241
  Val Loss:   1.0260
  Val Acc:    72.00%
  Val Top-5:  94.17%
  Val F1 (M): 70.18%
  Saved best model to outputs/densenet121_combined_kd/best_model.pth

Epoch 8/30
  Train Loss: 2.0549
  Train Acc:  95.26%
  CE Loss:    0.5949
  KD Loss:    1.4600
  Val Loss:   0.9853
  Val Acc:    74.00%
  Val Top-5:  93.83%
  Val F1 (M): 72.94%
  Saved best model to outputs/densenet121_combined_kd/best_model.pth

Epoch 9/30
  Train Loss: 2.0089
  Train Acc:  96.32%
  CE Loss:    0.5546
  KD Loss:    1.4543
  Val Loss:   0.9559
  Val Acc:    76.67%
  Val Top-5:  93.83%
  Val F1 (M): 75.40%
  Saved best model to outputs/densenet121_combined_kd/best_model.pth

Epoch 10/30
  Train Loss: 1.8983
  Train Acc:  97.56%
  CE Loss:    0.4810
  KD Loss:    1.4173
  Val Loss:   0.9164
  Val Acc:    75.33%
  Val Top-5:  93.83%
  Val F1 (M): 74.79%

Epoch 11/30
  Train Loss: 1.8258
  Train Acc:  97.79%
  CE Loss:    0.4420
  KD Loss:    1.3838
  Val Loss:   0.9459
  Val Acc:    75.83%
  Val Top-5:  93.50%
  Val F1 (M): 74.68%

Epoch 12/30
  Train Loss: 1.7528
  Train Acc:  98.40%
  CE Loss:    0.4053
  KD Loss:    1.3476
  Val Loss:   0.9741
  Val Acc:    75.17%
  Val Top-5:  92.83%
  Val F1 (M): 74.12%

Epoch 13/30
  Train Loss: 1.6758
  Train Acc:  99.03%
  CE Loss:    0.3660
  KD Loss:    1.3098
  Val Loss:   0.9578
  Val Acc:    75.50%
  Val Top-5:  93.67%
  Val F1 (M): 74.27%

Epoch 14/30
  Train Loss: 1.6465
  Train Acc:  98.96%
  CE Loss:    0.3453
  KD Loss:    1.3012
  Val Loss:   0.9564
  Val Acc:    76.67%
  Val Top-5:  93.33%
  Val F1 (M): 75.77%

Epoch 15/30
  Train Loss: 1.6038
  Train Acc:  99.27%
  CE Loss:    0.3300
  KD Loss:    1.2739
  Val Loss:   0.9477
  Val Acc:    76.33%
  Val Top-5:  92.83%
  Val F1 (M): 75.80%

Epoch 16/30
  Train Loss: 1.5466
  Train Acc:  99.40%
  CE Loss:    0.3042
  KD Loss:    1.2424
  Val Loss:   0.9774
  Val Acc:    74.33%
  Val Top-5:  93.33%
  Val F1 (M): 73.59%

Epoch 17/30
  Train Loss: 1.5212
  Train Acc:  99.48%
  CE Loss:    0.2927
  KD Loss:    1.2285
  Val Loss:   0.9643
  Val Acc:    75.67%
  Val Top-5:  93.33%
  Val F1 (M): 74.75%

Epoch 18/30
  Train Loss: 1.4573
  Train Acc:  99.65%
  CE Loss:    0.2690
  KD Loss:    1.1883
  Val Loss:   0.9473
  Val Acc:    75.33%
  Val Top-5:  93.67%
  Val F1 (M): 74.35%

Epoch 19/30
  Train Loss: 1.4336
  Train Acc:  99.63%
  CE Loss:    0.2652
  KD Loss:    1.1684
  Val Loss:   0.9555
  Val Acc:    75.50%
  Val Top-5:  93.67%
  Val F1 (M): 74.70%

Epoch 20/30
  Train Loss: 1.4035
  Train Acc:  99.57%
  CE Loss:    0.2554
  KD Loss:    1.1481
  Val Loss:   0.9406
  Val Acc:    75.83%
  Val Top-5:  94.00%
  Val F1 (M): 74.45%

Epoch 21/30
  Train Loss: 1.3881
  Train Acc:  99.65%
  CE Loss:    0.2479
  KD Loss:    1.1402
  Val Loss:   0.9559
  Val Acc:    74.33%
  Val Top-5:  93.17%
  Val F1 (M): 73.08%

Epoch 22/30
  Train Loss: 1.3615
  Train Acc:  99.68%
  CE Loss:    0.2378
  KD Loss:    1.1237
  Val Loss:   0.9472
  Val Acc:    76.00%
  Val Top-5:  93.50%
  Val F1 (M): 75.14%

Epoch 23/30
  Train Loss: 1.3395
  Train Acc:  99.74%
  CE Loss:    0.2303
  KD Loss:    1.1092
  Val Loss:   0.9382
  Val Acc:    77.83%
  Val Top-5:  93.00%
  Val F1 (M): 76.94%
  Saved best model to outputs/densenet121_combined_kd/best_model.pth

Epoch 24/30
  Train Loss: 1.3428
  Train Acc:  99.70%
  CE Loss:    0.2315
  KD Loss:    1.1112
  Val Loss:   0.9531
  Val Acc:    75.83%
  Val Top-5:  93.33%
  Val F1 (M): 74.92%

Epoch 25/30
  Train Loss: 1.3242
  Train Acc:  99.67%
  CE Loss:    0.2296
  KD Loss:    1.0946
  Val Loss:   0.9551
  Val Acc:    76.00%
  Val Top-5:  93.17%
  Val F1 (M): 75.08%

Epoch 26/30
  Train Loss: 1.2980
  Train Acc:  99.76%
  CE Loss:    0.2210
  KD Loss:    1.0769
  Val Loss:   0.9630
  Val Acc:    75.17%
  Val Top-5:  92.83%
  Val F1 (M): 74.27%

Epoch 27/30
  Train Loss: 1.2939
  Train Acc:  99.74%
  CE Loss:    0.2204
  KD Loss:    1.0735
  Val Loss:   0.9630
  Val Acc:    75.67%
  Val Top-5:  93.33%
  Val F1 (M): 74.77%

Epoch 28/30
  Train Loss: 1.2959
  Train Acc:  99.65%
  CE Loss:    0.2207
  KD Loss:    1.0751
  Val Loss:   0.9503
  Val Acc:    76.17%
  Val Top-5:  93.50%
  Val F1 (M): 75.14%

Epoch 29/30
  Train Loss: 1.2969
  Train Acc:  99.61%
  CE Loss:    0.2182
  KD Loss:    1.0787
  Val Loss:   0.9380
  Val Acc:    76.50%
  Val Top-5:  93.67%
  Val F1 (M): 75.44%

Epoch 30/30
  Train Loss: 1.2939
  Train Acc:  99.59%
  CE Loss:    0.2198
  KD Loss:    1.0741
  Val Loss:   0.9487
  Val Acc:    75.67%
  Val Top-5:  93.50%
  Val F1 (M): 74.83%
  Test Acc:   78.15%
  Test Top-5: 94.46%
  Test F1 (M):78.19%

============================================================
Training completed in 676.04s
Best validation accuracy: 77.83%
============================================================


Results saved to: outputs/densenet121_combined_kd
Training completed successfully!

All experiments completed!
